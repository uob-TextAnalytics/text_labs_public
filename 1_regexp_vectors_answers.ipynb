{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics Lab 1: Regular Expressions and Vector Representations\n",
    "\n",
    "### Learning Outcomes\n",
    "* Be able to set up a Python and Jupyter notebook environment for text analytics.\n",
    "* Understand how to use regular expressions to preprocess text.\n",
    "* Know how to carry out text normalisation including lemmatisation.\n",
    "* Know how to obtain bigram and TF-IDF vector representations of documents and term-document matrices.\n",
    "* Be able to compute cosine similarity to compare vector representations. \n",
    "\n",
    "### Outline\n",
    "\n",
    "1. Getting started: how to set up your environment, Jupyter notebooks introduction\n",
    "1. Acquiring raw text data\n",
    "1. Regular expressions\n",
    "1. Text normalisation \n",
    "1. Term-document matrices\n",
    "1. Cosine Similarity\n",
    "1. TF-IDF and bigram vectors\n",
    "\n",
    "### How To Complete This Lab\n",
    "\n",
    "Read the text and the code then look for 'TODOs' that instruct you to complete some missing code. Look out for 'QUESTIONS' which you should try to answer before moving on to the next cell. Aim to work through the lab during the scheduled lab hours. To get help, you can talk to TAs or the lecturer during the labs, post questions to the Blackboard discussion board or on Teams, or ask a question in the lectures. \n",
    "\n",
    "The labs *will not be marked*. However, they will prepare you for the coursework, so try to keep up with the weekly labs and have fun with the exercises! Check the textbook (Jurafsky and Martin) for more information on the methods implemented here.\n",
    "\n",
    "### Copilot and other AI tools\n",
    "\n",
    "If you are using an IDE like Visual Studio, we recommend switching off AI tools like Copilot while you are doing the lab. This is because the AI assistant will attempt to generate the answers for you -- sometimes it will be right, and you won't learn anything, and sometimes it will be wrong, and you'll just be confused!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting Started\n",
    "\n",
    "### Setting up your environment\n",
    "\n",
    "We recommend using ```conda``` to create an environment with the correct versions of all the packages you need for these labs. You can install either Anaconda or Miniconda, which will include the ```conda``` program. \n",
    "\n",
    "We provide a .yml file that lists all the packages you will need, and the versions that we have tested the labs with. You can use this file to create your environment as follows.\n",
    "\n",
    "1. Open a terminal. Use the command line to navigate to the directory containing this notebook and the file ```crossplatform_environment.yml```. You can use the command ```cd``` to change directory on the command line.\n",
    "\n",
    "1. For Lab machines only (e.g., in MVB 2.11 and QB 1.80): Load the Anaconda module: ```module load anaconda/3-2024```.\n",
    "\n",
    "1. Run the conda program by typing ```conda env create -f crossplatform_environment.yml```, then answer any questions that appear on the command line.\n",
    "\n",
    "1. Activate the environment by running the command ```conda activate text_analytics```.\n",
    "\n",
    "1. Install some libraries that are not available through Conda: ```pip install bertopic umap-learn```.\n",
    "\n",
    "1. Make kernel available in Jupyter: ```python -m ipykernel install --user --name=text_analytics```.\n",
    "\n",
    "1. Relaunch Jupyter: shutdown any running instances, and then type ```jupyter lab``` into your command line.\n",
    "\n",
    "1. Find this notebook and open it up again.\n",
    "\n",
    "1. Go to the top menu and change the kernel: click on 'Kernel'--> 'Change kernel' --> text_analytics.\n",
    "\n",
    "You should now be ready to go!\n",
    "\n",
    "The core libraries we will be using in this unit are:\n",
    "\n",
    "- [Datasets](https://huggingface.co/docs/datasets/), produced by HuggingFace, is a hub for lots of interesting text datasets.\n",
    "- [NLTK](https://www.nltk.org), a comprehensive NLP library.\n",
    "- [Scikit-learn](https://scikit-learn.org/stable/user_guide.html), for machine learning and classifier evaluation.\n",
    "- [Gensim](https://radimrehurek.com/gensim/), for topic modelling.\n",
    "- [Transformers](https://huggingface.co/docs/transformers/en/index), for state-of-the-art NLP models. \n",
    "- [PyTorch](https://pytorch.org/), a framework for deep learning. \n",
    "- [BERTopic](https://maartengr.github.io/BERTopic/getting_started/quickstart/quickstart.html) for clustering documents into topics.\n",
    "\n",
    "The libraries above have good documentation, which is available either online (links above) or via Python itself, e.g. `help(numpy.array)` in the Python interpreter. \n",
    "\n",
    "### Refreshers for Python and Jupyter\n",
    "\n",
    "If you need a refresher on Python, see the [Introduction to Python lab](https://github.com/UoB-COMS21202/lab_sheets_public/tree/master/lab_1) or the University of Bristol [Beginning Python](https://milliams.gitlab.io/beginning_python/) course. If you are a beginner with Python, you might also like to look at Chapter 1 in the NLTK book, which also provides a guide for \"getting started with Python\": https://www.nltk.org/book/. \n",
    "\n",
    "The labs will be run on [Jupyter Notebook](http://jupyter.org/), an interactive coding environment embedded in a webpage supporting various programing languages (Python, R, Lua, etc.) through the concept of kernels. The code in a notebook is arranged in _cells_. To edit an already existing cell simply double-click on it. Cells can be run by hitting `shift+enter` when editing a cell or by clicking on the `Run` button at the top. Create new cells with the keyboard shortcut `esc` followed by `A` or `B`.\n",
    "\n",
    "**Note**: when you run a code cell, all the created variables, implemented functions and imported libraries will be then available to every other code cell. It is commonly assumed that cells will be run in the correct sequence and running them repeatedly or out-of-order may sometimes cause errors. To reset all variables and functions (for debugging) simply click `Kernel > Restart` from the Jupyter menu.\n",
    "\n",
    "#### Markdown \n",
    "\n",
    "Markdown cells (like this one) allow you to write fancy comments in Markdown format - double click on this cell to see the source. An introduction to Markdown syntax can be found [here](https://daringfireball.net/projects/markdown/syntax). You can also display simple $\\LaTeX$ equations in Markdown thanks to `MathJax` support: for inline equations wrap your equation between `$` symbols; for display mode equations use `$$`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Acquiring Raw Text Data\n",
    "\n",
    "Now, let's get some text data! [HuggingFace's datasets hub](https://huggingface.co/datasets) is a repository of many different text datasets: they are useful for experimenting with NLP tasks and training models. For this lab, we'll start with the IMDB dataset, which contains movie reviews along with their classification into \"positive\" or \"negative\" sentiment. Run the code below to download the data from [HuggingFace's datasets hub](https://huggingface.co/datasets/imdb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 25000 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "# The data is already divided into training and test sets.\n",
    "# Load the training set:\n",
    "train_dataset = load_dataset(\n",
    "    \"imdb\", # name of the dataset collection\n",
    "    split=\"train\",  # train or test\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset)} instances loaded\")\n",
    "\n",
    "train_dataset = np.random.choice(train_dataset, 100, replace=False)  # we'll only use a subset of the data in this lab so that the code runs quicker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the documents in the dataset like elements in a list. For example, the document with index 3 looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'It is hard to describe this film and one wants to tried hard not to dismiss it too quickly because you have a feeling that this might just be the perfect film for some 12 years old girl...<br /><br />This film has a nice concept-the modern version of Sleeping Beauty with a twist. It has some rather dreamy shots and some nice sketches of the young boy relationship with his single working mother and his schoolmate... a nice start you might say, but then it got a bit greedy, very greedy, it tries to be a science fiction, a drama, a thriller, a possible romantic love story, fairy tale, a comedy and everything under the sun. The result just left the audience feeling rather inadequate. For example, the scene when the girl(played by Risa Goto) finally woken by his(Yuki Kohara) kiss, instead of being romantic, it try\\'s to be scary in order to make us laugh afterwards... it is a cheap trick, because it ruin all the anticipation and emotion which it was trying to build for the better half of the film.<br /><br />I have not read the original story the film is base on (it is the well-known work by the comic-book artist Osamu Tezuka is famous with his intriguing and intricate stories) I wonder if all the problems exsist in the original story or did it occur in the adaption? It is rather illogical even for someone who is used to the \"fussy logic\" of those japanese comic-book. For instance, how did Yuki Kohara\\'s character manage to get to the hospital in an instant(when its suppose to be a long bus-ride away)to run away Risa Goto\\'s character in front of the tv cameras right after he saw her live interview on the television?<br /><br />There are also some scenes that is directly copied(very uncreative!) from other films and they all seem rather pointlessly annoying ie. the famous \"the Lion mouth has caugh my hand\" scene from \"the \"Roman Holiday\"<br /><br />The film tries to be everything but ends up being nothing... it fails to be a fairy tale and it did not have enough jokes to be a comedy... and strangely there are some scenes that even seem like an unintentional \"ghost\" movie. Nevertheless, one should give it credit that it has managed to caputured some of the sentiment of the japanese teenager.<br /><br />It is by watching this film I have a feeling that there might be some films that should have come with a warning label that said \"this film might only be suitable for person under the 18 of age\", it would have definitly been on the poster of this film.<br /><br />',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DO 1:** Print the label for document 31. What does the value mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#*** WRITE YOUR ANSWER HERE ***\n",
    "print(train_dataset[31]['label'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regular Expressions\n",
    "\n",
    "In text analytics, we aim to retrieve or extract information from text documents, or classify or summarise documents to better understand a large amount of text. Typically, we are not just looking for a single word or phrase: that can be useful for retrieving documents given a keyword query, but there are many cases where we want to recognise more complex and variable patterns. For example, if we want to find dates, we cannot list all the possible combinations of digits we want to search for, but we can look for patterns of numbers in date format. To do this, we need a way to represent the patterns we are looking for inside a piece of text. The most direct way to represent text patterns is to use regular expressions. Regular expressions provide a standard language for writing text patterns, which we will learn about below. \n",
    "\n",
    "## 2.1 Search\n",
    "\n",
    "We'll start by trying out some simple regular expressions. Suppose we want to identify tweets where people discuss really loved about certain movies. We could start by looking for tweets that contain the word 'love'. Before we try to look for more general patterns, a first step is just to look for all occurrences of the word 'love'. Review the code below to see how we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "36\n",
      "love\n"
     ]
    }
   ],
   "source": [
    "import re  # Python regular expressions library\n",
    "\n",
    "all_matches = []\n",
    "\n",
    "for review in train_dataset:\n",
    "    matches = re.findall('love', review['text'])\n",
    "    if len(matches) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        all_matches.extend(matches)\n",
    "    \n",
    "print(len(all_matches))  # length of the list of matches\n",
    "print(len(all_matches))  # length of the list of matches\n",
    "for match in set(all_matches):  # Use a set to get a list of the unique matches\n",
    "    print(match) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has given us a list of matches in the variable `all_matches`, which all contain the string 'love', but not the sentences themselves.\n",
    "This isn't very useful, but we can do better if we define the right regular expression!\n",
    "\n",
    "Regular expressions represent patterns, rather than specific strings, allowing us to generalise our search and retrieve a many different strings that match the pattern.\n",
    "In Python, we differentiate a regular expression from a normal string by putting an 'r' character in front of the string.\n",
    "\n",
    "We can generalise our search by using a _disjunction_, which will match against any one of a set of characters. The disjunction is written inside square brackets. \n",
    "\n",
    "Let's try to retrieve instances of the word \"love\" followed by any letter. We can write a disjunction that matches any lower case letter as `[a-z]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n",
      "love y\n",
      "love t\n",
      "love s\n",
      "love l\n",
      "love i\n",
      "love a\n",
      "love c\n",
      "love h\n",
      "love w\n",
      "love b\n",
      "love m\n"
     ]
    }
   ],
   "source": [
    "all_matches = []\n",
    "\n",
    "for review in train_dataset:\n",
    "    matches = re.findall(r'love [a-z]', review['text'])\n",
    "    if len(matches) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        all_matches.extend(matches)\n",
    "    \n",
    "print(len(all_matches))  # length of the list of matches\n",
    "print(len(all_matches))  # length of the list of matches\n",
    "for match in set(all_matches):  # Use a set to get a list of the unique matches\n",
    "    print(match) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current search only matches a single letter of the word after 'love'. The length of that following word is variable, so how can we write an expression to match the whole word? \n",
    "\n",
    "Here, we can use a special character, '\\*', which will match against zero or more repetitions of the preceding regular expression. Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "love you\n",
      "love anyone\n",
      "love to\n",
      "love slowly\n",
      "love with\n",
      "love without\n",
      "love creepy\n",
      "love interest\n",
      "love me\n",
      "love it\n",
      "love story\n",
      "love listening\n",
      "love \n",
      "love her\n",
      "love them\n",
      "love interests\n",
      "love and\n",
      "love the\n",
      "love bed\n",
      "love subplot\n"
     ]
    }
   ],
   "source": [
    "all_matches = []\n",
    "\n",
    "for review in train_dataset:\n",
    "    matches = re.findall(r'love [a-z]*', review['text'])\n",
    "    if len(matches) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        all_matches.extend(matches)\n",
    "    \n",
    "print(len(all_matches))  # length of the list of matches\n",
    "print(len(all_matches))  # length of the list of matches\n",
    "for match in set(all_matches):  # Use a set to get a list of the unique matches\n",
    "    print(match) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we only want to retrieve the word following 'love', not the string containing 'love ' itself. \n",
    "We can do this using parentheses to create _groups_ of characters, such as this: `([a-z]*)`. The resulting matches will be returned as tuples of groups, and any characters not inside parentheses will not be returned as part of any group. Try out the code below to see this, and note that the space character after 'love' is not returned in the matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "('love', 'it')\n",
      "('love', 'bed')\n",
      "('love', 'the')\n",
      "('love', 'subplot')\n",
      "('love', 'me')\n",
      "('love', 'interests')\n",
      "('love', 'and')\n",
      "('love', 'listening')\n",
      "('love', 'interest')\n",
      "('love', 'her')\n",
      "('love', 'story')\n",
      "('love', '')\n",
      "('love', 'slowly')\n",
      "('love', 'with')\n",
      "('love', 'you')\n",
      "('love', 'anyone')\n",
      "('love', 'creepy')\n",
      "('love', 'to')\n",
      "('love', 'them')\n",
      "('love', 'without')\n",
      "it\n",
      "bed\n",
      "the\n",
      "subplot\n",
      "me\n",
      "interests\n",
      "and\n",
      "listening\n",
      "interest\n",
      "her\n",
      "story\n",
      "\n",
      "slowly\n",
      "with\n",
      "you\n",
      "anyone\n",
      "creepy\n",
      "to\n",
      "them\n",
      "without\n"
     ]
    }
   ],
   "source": [
    "all_matches = []\n",
    "\n",
    "for review in train_dataset:\n",
    "    matches = re.findall(r'(love) ([a-z]*)', review['text'])\n",
    "    if len(matches) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        all_matches.extend(matches)\n",
    "    \n",
    "print(len(all_matches))  # length of the list of matches\n",
    "print(len(all_matches))  # length of the list of matches\n",
    "for match in set(all_matches):  # Use a set to get a list of the unique matches\n",
    "    print(match) \n",
    "\n",
    "for match in set(all_matches):  # just print the following\n",
    "    print(match[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to retrieve the preceding words as well. It would be better to match capital letters as well as lower case, which we can do with the disjunction `[a-zA-Z]`. \n",
    "\n",
    "**TO-DO 2:** complete the code below to retrieve only the words that precede and follow 'love', including capitalised and lower case words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "('i', 'it')\n",
      "('in', 'with')\n",
      "('and', 'slowly')\n",
      "('i', 'bed')\n",
      "('I', 'it')\n",
      "('a', 'subplot')\n",
      "('I', 'the')\n",
      "('you', 'creepy')\n",
      "('the', 'interest')\n",
      "('the', 'her')\n",
      "('s', 'interests')\n",
      "('his', 'without')\n",
      "('just', 'listening')\n",
      "('', 'me')\n",
      "('d', 'to')\n",
      "('and', 'to')\n",
      "('I', 'Pride')\n",
      "('romantic', 'story')\n",
      "('i', 'you')\n",
      "('also', 'anyone')\n",
      "('i', 'them')\n",
      "('The', 'and')\n"
     ]
    }
   ],
   "source": [
    "all_matches = []\n",
    "\n",
    "for review in train_dataset:\n",
    "    \n",
    "    ### WRITE YOUR CODE HERE\n",
    "    matches = re.findall(r'([a-zA-Z]*) love ([a-zA-Z]*)', review['text'])\n",
    "    ########\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        all_matches.extend(matches)\n",
    "    \n",
    "print(len(all_matches))  # length of the list of matches\n",
    "print(len(all_matches))  # length of the list of matches\n",
    "for match in set(all_matches):  # Use a set to get a list of the unique matches\n",
    "    print(match) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is starting to look more useful, but we still want to retrieve whole sentences. \n",
    "\n",
    "Sentences in English are usually demarcated by punctuation (this is not the same for languages in other scripts, such as Chinese, Hindi and Thai). As we're working with English text only at the moment, let's use the following punctuation marks to identify sentence boundaries: '.', '!', '?'. In the regular expression language, those punctuation marks are special characters that do not literally represent the symbols '.', '!', or '?'. To force Python to interpret them literally, we need to put the escape character '\\\\' in front of them. \n",
    "\n",
    "Now, we can write a disjunction that matches against the punctuation like this: `[\\.\\!\\?]`.\n",
    "\n",
    "So far, we have assumed the text consists only of letters. Can you think of any characters we have excluded here? \n",
    "\n",
    "It can be hard to list every character we want to match. A better way to find all matches could be to use _negation_ to match against any character _except_ the punctuation marks that bound the sentences. A negation will match any character except those specified, which we can write like this: `[^\\.\\!\\?]`, where the '^' indicates the negation.\n",
    "\n",
    "\n",
    "**TO-DO 3:** Retrieve whole sentences containing 'love'. To do this, modify our previous expression by using negation to match all of the characters except '.', '!', and '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " I love Pride and Prejudice and Sense and Sensibility books and movies, and I'm half way through Mansfield Park\n",
      "But I love it\n",
      " The way the film is narrated: Humanity and love slowly developing between these two outsiders, and contrasted to the simultaneously & continuously ongoing inhumane marching pace of the fascist radio announcer (who happens to be a colleague of Mastroianni's part)and the adherents \"going to and coming from the show\"\n",
      " I love the moment Mr\n",
      " a nice start you might say, but then it got a bit greedy, very greedy, it tries to be a science fiction, a drama, a thriller, a possible romantic love story, fairy tale, a comedy and everything under the sun\n",
      " Gus, a man besotted and passionately in love, is prepared to give up his love without complaint\n",
      "<br /><br />The scene that is totally wasted is when both of Cooper's love interests and their respective fathers are cooped up in the same hotel room together\n",
      "i love bed knobs and broomsticks so much that it makes me cry a thousand tears of joy every time i have the magnificent pleasure of seeing it\n",
      " i love you\n",
      " The love and friendship between the proprietor and his retarded son is deep and moving\n",
      " This one's quite hard to find anymore; I'd love to see it again to compare it to other international horrors of the day, but don't remember particularly impressed way back when\n",
      " Even though the movie contains a love subplot it's never carried that far and doesn't derail the movie like say, Batman Forever\n",
      " It is as if the director was so in love with his work that instead of cutting the movie down to a pace that kept your attention, he added all of the footage he had shot together\n",
      " A sweet romantic comedy with a very young Gina Lollobrigida as the love interest\n",
      " A brilliant movie, superbly acted out indeed and one I will treasure forever and love to continue watching\n",
      " If you love creepy, horrible and mysterious films, with lots of surprises, this is the FILM FOR YOU\n",
      " love me (liz)\n",
      " i have 27 copies on video and i love them all equally\n",
      " There's this man who's everywhere around the woman and obviously in love with her, but in his own way\n",
      " i would also like to reiterate the simple fact that i love it so much\n",
      " Loveday has changed from the young woman totally in love with Gus to a sensible farmer's wife who can give up the love her life with barely a tear (less emotional than Brief Encounter)\n",
      " i also love anyone else who loves it\n",
      " In the end I just love listening to people who think they are so smart that they are qualified to judge the almighty\n"
     ]
    }
   ],
   "source": [
    "all_matches = []\n",
    "\n",
    "for review in train_dataset:\n",
    "    \n",
    "    ### WRITE YOUR CODE HERE\n",
    "    matches = re.findall(r'[^\\.\\!\\?]* love [^\\.\\!\\?]*', review['text'])  \n",
    "\n",
    "    ########\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        all_matches.extend(matches)\n",
    "    \n",
    "print(len(all_matches))  # length of the list of matches\n",
    "for match in set(all_matches):  # Use a set to get a list of the unique matches\n",
    "    print(match)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the results -- does the regular expression correctly return sentences containing 'love'?\n",
    "\n",
    "There are lots more special characters that you can use to form really powerful regular expressions for segmenting, retrieving and substituting text. For your reference, you can find a complete list [here](https://docs.python.org/3/library/re.html#regular-expression-syntax). You can take a look at this list and try to rewrite the expressions above in different ways using the special characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Substitution\n",
    "\n",
    "Besides matching and retrieving pieces of text, regular expressions can also be used to alter text by substituting one string for another. There are many potential uses, for example, to fill in templates by replacing placeholders with dates, filenames or other information. For example, imagine a system for sending automated reminders of doctor's appointments. It may contain a sentence \"This is to remind you of your appointment on DATE at TIME.\". Substitution can be used to replace the strings 'DATE' and 'TIME' with specifica values. \n",
    "\n",
    "Regular expression _substitution_ finds a matching string within a larger piece of text, and replaces it with another string.\n",
    "\n",
    "Let's use this to clean up the text by removing the line break characters.\n",
    "\n",
    "In Python, we can use the re.sub() function, which takes three arguments:\n",
    "1. The expression to match. \n",
    "2. The pattern we should replace it with\n",
    "3. The text to apply the subtitution to. \n",
    "\n",
    "Some of the reviews contain some HTML formatting code, `<br />`, which we can try to remove to clean up the text. We can do this by writing an expression for the first argument of re.sub() that matches '<br />'. Take a look at how this works by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT: \n",
      "It is hard to describe this film and one wants to tried hard not to dismiss it too quickly because you have a feeling that this might just be the perfect film for some 12 years old girl...<br /><br />This film has a nice concept-the modern version of Sleeping Beauty with a twist. It has some rather dreamy shots and some nice sketches of the young boy relationship with his single working mother and his schoolmate... a nice start you might say, but then it got a bit greedy, very greedy, it tries to be a science fiction, a drama, a thriller, a possible romantic love story, fairy tale, a comedy and everything under the sun. The result just left the audience feeling rather inadequate. For example, the scene when the girl(played by Risa Goto) finally woken by his(Yuki Kohara) kiss, instead of being romantic, it try's to be scary in order to make us laugh afterwards... it is a cheap trick, because it ruin all the anticipation and emotion which it was trying to build for the better half of the film.<br /><br />I have not read the original story the film is base on (it is the well-known work by the comic-book artist Osamu Tezuka is famous with his intriguing and intricate stories) I wonder if all the problems exsist in the original story or did it occur in the adaption? It is rather illogical even for someone who is used to the \"fussy logic\" of those japanese comic-book. For instance, how did Yuki Kohara's character manage to get to the hospital in an instant(when its suppose to be a long bus-ride away)to run away Risa Goto's character in front of the tv cameras right after he saw her live interview on the television?<br /><br />There are also some scenes that is directly copied(very uncreative!) from other films and they all seem rather pointlessly annoying ie. the famous \"the Lion mouth has caugh my hand\" scene from \"the \"Roman Holiday\"<br /><br />The film tries to be everything but ends up being nothing... it fails to be a fairy tale and it did not have enough jokes to be a comedy... and strangely there are some scenes that even seem like an unintentional \"ghost\" movie. Nevertheless, one should give it credit that it has managed to caputured some of the sentiment of the japanese teenager.<br /><br />It is by watching this film I have a feeling that there might be some films that should have come with a warning label that said \"this film might only be suitable for person under the 18 of age\", it would have definitly been on the poster of this film.<br /><br />\n",
      "CLEANER TEXT: \n",
      "It is hard to describe this film and one wants to tried hard not to dismiss it too quickly because you have a feeling that this might just be the perfect film for some 12 years old girl...  This film has a nice concept-the modern version of Sleeping Beauty with a twist. It has some rather dreamy shots and some nice sketches of the young boy relationship with his single working mother and his schoolmate... a nice start you might say, but then it got a bit greedy, very greedy, it tries to be a science fiction, a drama, a thriller, a possible romantic love story, fairy tale, a comedy and everything under the sun. The result just left the audience feeling rather inadequate. For example, the scene when the girl(played by Risa Goto) finally woken by his(Yuki Kohara) kiss, instead of being romantic, it try's to be scary in order to make us laugh afterwards... it is a cheap trick, because it ruin all the anticipation and emotion which it was trying to build for the better half of the film.  I have not read the original story the film is base on (it is the well-known work by the comic-book artist Osamu Tezuka is famous with his intriguing and intricate stories) I wonder if all the problems exsist in the original story or did it occur in the adaption? It is rather illogical even for someone who is used to the \"fussy logic\" of those japanese comic-book. For instance, how did Yuki Kohara's character manage to get to the hospital in an instant(when its suppose to be a long bus-ride away)to run away Risa Goto's character in front of the tv cameras right after he saw her live interview on the television?  There are also some scenes that is directly copied(very uncreative!) from other films and they all seem rather pointlessly annoying ie. the famous \"the Lion mouth has caugh my hand\" scene from \"the \"Roman Holiday\"  The film tries to be everything but ends up being nothing... it fails to be a fairy tale and it did not have enough jokes to be a comedy... and strangely there are some scenes that even seem like an unintentional \"ghost\" movie. Nevertheless, one should give it credit that it has managed to caputured some of the sentiment of the japanese teenager.  It is by watching this film I have a feeling that there might be some films that should have come with a warning label that said \"this film might only be suitable for person under the 18 of age\", it would have definitly been on the poster of this film.  \n"
     ]
    }
   ],
   "source": [
    "print('ORIGINAL TEXT: ')\n",
    "print(train_dataset[5]['text'])\n",
    "    \n",
    "clean_article = re.sub(r'<br />', r' ', train_dataset[5]['text'])  # replace HTML breaks with a space\n",
    "    \n",
    "print('CLEANER TEXT: ')\n",
    "print(clean_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Normalisation \n",
    "\n",
    "For most text analytics tasks, such as document classification, we will first need to transform the raw text to a suitable format for input to method such as a classifier. This process is called _text normalisation_ and is part of the _preprocessing_ stage. There are three common steps:\n",
    "\n",
    "1. Sentence segmentation: this is needed when we want to process each sentence separately, e.g., to classify its sentiment. We have already tried out a basic approach to obtaining complete sentences using regular expressions. This would need to be modified to return a list of all sentences in a document. \n",
    "2. Tokenisation, in which the sentences are split into a sequence of tokens, which include words, numbers and punctuation marks.\n",
    "3. Word normalisation, in which different forms of a word are replaced by a root form. Many text analytics models, such as document classifiers, can benefit from words being _normalised_ to consistent word forms (e.g., \"dog\", \"Dog\" and \"dogs\" could all normalised to \"dog\"), as this can reduce the diversity of the vocabulary make it easier to find meaningful patterns in the data. \n",
    "\n",
    "We are now going to see how to perform these steps using the NLTK library.\n",
    "\n",
    "## 3.1 Sentence Segmentation\n",
    "\n",
    "Let's start by using NLTK to split a document into sentences. This should give better results than our regular expressions above.\n",
    "\n",
    "You may get some errors from NLTK when you try to use sent_tokenize or word_tokenize further down. This is usually because you need to download and install some NLTK data. Please check the error message to find out which package is required. You probably need to install packages called 'punkt' and 'wordnet'. You can install these packages by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/es1595/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/es1595/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/es1595/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SENTENCE>\n",
      "It is hard to describe this film and one wants to tried hard not to dismiss it too quickly because you have a feeling that this might just be the perfect film for some 12 years old girl...<br /><br />This film has a nice concept-the modern version of Sleeping Beauty with a twist.\n",
      "<SENTENCE>\n",
      "It has some rather dreamy shots and some nice sketches of the young boy relationship with his single working mother and his schoolmate... a nice start you might say, but then it got a bit greedy, very greedy, it tries to be a science fiction, a drama, a thriller, a possible romantic love story, fairy tale, a comedy and everything under the sun.\n",
      "<SENTENCE>\n",
      "The result just left the audience feeling rather inadequate.\n",
      "<SENTENCE>\n",
      "For example, the scene when the girl(played by Risa Goto) finally woken by his(Yuki Kohara) kiss, instead of being romantic, it try's to be scary in order to make us laugh afterwards... it is a cheap trick, because it ruin all the anticipation and emotion which it was trying to build for the better half of the film.<br /><br />I have not read the original story the film is base on (it is the well-known work by the comic-book artist Osamu Tezuka is famous with his intriguing and intricate stories) I wonder if all the problems exsist in the original story or did it occur in the adaption?\n",
      "<SENTENCE>\n",
      "It is rather illogical even for someone who is used to the \"fussy logic\" of those japanese comic-book.\n",
      "<SENTENCE>\n",
      "For instance, how did Yuki Kohara's character manage to get to the hospital in an instant(when its suppose to be a long bus-ride away)to run away Risa Goto's character in front of the tv cameras right after he saw her live interview on the television?<br /><br />There are also some scenes that is directly copied(very uncreative!)\n",
      "<SENTENCE>\n",
      "from other films and they all seem rather pointlessly annoying ie.\n",
      "<SENTENCE>\n",
      "the famous \"the Lion mouth has caugh my hand\" scene from \"the \"Roman Holiday\"<br /><br />The film tries to be everything but ends up being nothing... it fails to be a fairy tale and it did not have enough jokes to be a comedy... and strangely there are some scenes that even seem like an unintentional \"ghost\" movie.\n",
      "<SENTENCE>\n",
      "Nevertheless, one should give it credit that it has managed to caputured some of the sentiment of the japanese teenager.<br /><br />It is by watching this film I have a feeling that there might be some films that should have come with a warning label that said \"this film might only be suitable for person under the 18 of age\", it would have definitly been on the poster of this film.<br /><br />\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "review = train_dataset[5]['text']\n",
    "\n",
    "sents = nltk.sent_tokenize(review)\n",
    "\n",
    "for sent in sents:\n",
    "    print(\"<SENTENCE>\")\n",
    "    print(sent)  # print the sentences of this document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DO 4:** Use the regular expression substitution code from section 2.2 to remove the '\\<br /\\>' tags from the sentences displayed above and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SENTENCE>\n",
      "It is hard to describe this film and one wants to tried hard not to dismiss it too quickly because you have a feeling that this might just be the perfect film for some 12 years old girl...  This film has a nice concept-the modern version of Sleeping Beauty with a twist.\n",
      "<SENTENCE>\n",
      "It has some rather dreamy shots and some nice sketches of the young boy relationship with his single working mother and his schoolmate... a nice start you might say, but then it got a bit greedy, very greedy, it tries to be a science fiction, a drama, a thriller, a possible romantic love story, fairy tale, a comedy and everything under the sun.\n",
      "<SENTENCE>\n",
      "The result just left the audience feeling rather inadequate.\n",
      "<SENTENCE>\n",
      "For example, the scene when the girl(played by Risa Goto) finally woken by his(Yuki Kohara) kiss, instead of being romantic, it try's to be scary in order to make us laugh afterwards... it is a cheap trick, because it ruin all the anticipation and emotion which it was trying to build for the better half of the film.  I have not read the original story the film is base on (it is the well-known work by the comic-book artist Osamu Tezuka is famous with his intriguing and intricate stories) I wonder if all the problems exsist in the original story or did it occur in the adaption?\n",
      "<SENTENCE>\n",
      "It is rather illogical even for someone who is used to the \"fussy logic\" of those japanese comic-book.\n",
      "<SENTENCE>\n",
      "For instance, how did Yuki Kohara's character manage to get to the hospital in an instant(when its suppose to be a long bus-ride away)to run away Risa Goto's character in front of the tv cameras right after he saw her live interview on the television?  There are also some scenes that is directly copied(very uncreative!)\n",
      "<SENTENCE>\n",
      "from other films and they all seem rather pointlessly annoying ie.\n",
      "<SENTENCE>\n",
      "the famous \"the Lion mouth has caugh my hand\" scene from \"the \"Roman Holiday\"  The film tries to be everything but ends up being nothing... it fails to be a fairy tale and it did not have enough jokes to be a comedy... and strangely there are some scenes that even seem like an unintentional \"ghost\" movie.\n",
      "<SENTENCE>\n",
      "Nevertheless, one should give it credit that it has managed to caputured some of the sentiment of the japanese teenager.  It is by watching this film I have a feeling that there might be some films that should have come with a warning label that said \"this film might only be suitable for person under the 18 of age\", it would have definitly been on the poster of this film.  \n"
     ]
    }
   ],
   "source": [
    "clean_sents = []\n",
    "\n",
    "for sent in sents:\n",
    "    \n",
    "    ### WRITE YOUR OWN CODE HERE\n",
    "    sent = re.sub(r'<br />', r' ', sent)\n",
    "    #######\n",
    "    \n",
    "    print(\"<SENTENCE>\")\n",
    "    print(sent)  # print the sentences of this document\n",
    "    \n",
    "    clean_sents.append(sent)  # save the cleaned sentences for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Tokenisation\n",
    "\n",
    "NLTK provides a similar function for tokenizing the text at the word level. You can find the documentation [here](https://www.nltk.org/api/nltk.tokenize.html). Most tokenizers use either regular expressions or a machine learning model that was trained on a large dataset to learn token-splitting rules. \n",
    "\n",
    "**TO-DO 5:** Use word_tokenize() to tokenize each of the sentences from the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TOKENS>\n",
      "['It', 'is', 'hard', 'to', 'describe', 'this', 'film', 'and', 'one', 'wants', 'to', 'tried', 'hard', 'not', 'to', 'dismiss', 'it', 'too', 'quickly', 'because', 'you', 'have', 'a', 'feeling', 'that', 'this', 'might', 'just', 'be', 'the', 'perfect', 'film', 'for', 'some', '12', 'years', 'old', 'girl', '...', 'This', 'film', 'has', 'a', 'nice', 'concept-the', 'modern', 'version', 'of', 'Sleeping', 'Beauty', 'with', 'a', 'twist', '.']\n",
      "<TOKENS>\n",
      "['It', 'has', 'some', 'rather', 'dreamy', 'shots', 'and', 'some', 'nice', 'sketches', 'of', 'the', 'young', 'boy', 'relationship', 'with', 'his', 'single', 'working', 'mother', 'and', 'his', 'schoolmate', '...', 'a', 'nice', 'start', 'you', 'might', 'say', ',', 'but', 'then', 'it', 'got', 'a', 'bit', 'greedy', ',', 'very', 'greedy', ',', 'it', 'tries', 'to', 'be', 'a', 'science', 'fiction', ',', 'a', 'drama', ',', 'a', 'thriller', ',', 'a', 'possible', 'romantic', 'love', 'story', ',', 'fairy', 'tale', ',', 'a', 'comedy', 'and', 'everything', 'under', 'the', 'sun', '.']\n",
      "<TOKENS>\n",
      "['The', 'result', 'just', 'left', 'the', 'audience', 'feeling', 'rather', 'inadequate', '.']\n",
      "<TOKENS>\n",
      "['For', 'example', ',', 'the', 'scene', 'when', 'the', 'girl', '(', 'played', 'by', 'Risa', 'Goto', ')', 'finally', 'woken', 'by', 'his', '(', 'Yuki', 'Kohara', ')', 'kiss', ',', 'instead', 'of', 'being', 'romantic', ',', 'it', 'try', \"'s\", 'to', 'be', 'scary', 'in', 'order', 'to', 'make', 'us', 'laugh', 'afterwards', '...', 'it', 'is', 'a', 'cheap', 'trick', ',', 'because', 'it', 'ruin', 'all', 'the', 'anticipation', 'and', 'emotion', 'which', 'it', 'was', 'trying', 'to', 'build', 'for', 'the', 'better', 'half', 'of', 'the', 'film', '.', 'I', 'have', 'not', 'read', 'the', 'original', 'story', 'the', 'film', 'is', 'base', 'on', '(', 'it', 'is', 'the', 'well-known', 'work', 'by', 'the', 'comic-book', 'artist', 'Osamu', 'Tezuka', 'is', 'famous', 'with', 'his', 'intriguing', 'and', 'intricate', 'stories', ')', 'I', 'wonder', 'if', 'all', 'the', 'problems', 'exsist', 'in', 'the', 'original', 'story', 'or', 'did', 'it', 'occur', 'in', 'the', 'adaption', '?']\n",
      "<TOKENS>\n",
      "['It', 'is', 'rather', 'illogical', 'even', 'for', 'someone', 'who', 'is', 'used', 'to', 'the', '``', 'fussy', 'logic', \"''\", 'of', 'those', 'japanese', 'comic-book', '.']\n",
      "<TOKENS>\n",
      "['For', 'instance', ',', 'how', 'did', 'Yuki', 'Kohara', \"'s\", 'character', 'manage', 'to', 'get', 'to', 'the', 'hospital', 'in', 'an', 'instant', '(', 'when', 'its', 'suppose', 'to', 'be', 'a', 'long', 'bus-ride', 'away', ')', 'to', 'run', 'away', 'Risa', 'Goto', \"'s\", 'character', 'in', 'front', 'of', 'the', 'tv', 'cameras', 'right', 'after', 'he', 'saw', 'her', 'live', 'interview', 'on', 'the', 'television', '?', 'There', 'are', 'also', 'some', 'scenes', 'that', 'is', 'directly', 'copied', '(', 'very', 'uncreative', '!', ')']\n",
      "<TOKENS>\n",
      "['from', 'other', 'films', 'and', 'they', 'all', 'seem', 'rather', 'pointlessly', 'annoying', 'ie', '.']\n",
      "<TOKENS>\n",
      "['the', 'famous', '``', 'the', 'Lion', 'mouth', 'has', 'caugh', 'my', 'hand', \"''\", 'scene', 'from', '``', 'the', '``', 'Roman', 'Holiday', \"''\", 'The', 'film', 'tries', 'to', 'be', 'everything', 'but', 'ends', 'up', 'being', 'nothing', '...', 'it', 'fails', 'to', 'be', 'a', 'fairy', 'tale', 'and', 'it', 'did', 'not', 'have', 'enough', 'jokes', 'to', 'be', 'a', 'comedy', '...', 'and', 'strangely', 'there', 'are', 'some', 'scenes', 'that', 'even', 'seem', 'like', 'an', 'unintentional', '``', 'ghost', \"''\", 'movie', '.']\n",
      "<TOKENS>\n",
      "['Nevertheless', ',', 'one', 'should', 'give', 'it', 'credit', 'that', 'it', 'has', 'managed', 'to', 'caputured', 'some', 'of', 'the', 'sentiment', 'of', 'the', 'japanese', 'teenager', '.', 'It', 'is', 'by', 'watching', 'this', 'film', 'I', 'have', 'a', 'feeling', 'that', 'there', 'might', 'be', 'some', 'films', 'that', 'should', 'have', 'come', 'with', 'a', 'warning', 'label', 'that', 'said', '``', 'this', 'film', 'might', 'only', 'be', 'suitable', 'for', 'person', 'under', 'the', '18', 'of', 'age', \"''\", ',', 'it', 'would', 'have', 'definitly', 'been', 'on', 'the', 'poster', 'of', 'this', 'film', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sents = []\n",
    "\n",
    "for sent in clean_sents:\n",
    "    ### WRITE YOUR OWN CODE HERE\n",
    "    tokens = nltk.word_tokenize(sent)\n",
    "    #######\n",
    "    \n",
    "    print(\"<TOKENS>\")\n",
    "    print(tokens)\n",
    "    \n",
    "    tokenized_sents.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to see how NLTK has handled the non-letter characters. \n",
    "* What does it do with most punctuation marks? \n",
    "* When does it not split tokens based on punctuation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "concept-the\n",
      ".\n",
      "...\n",
      ",\n",
      ",\n",
      ",\n",
      ",\n",
      ",\n",
      ",\n",
      ",\n",
      ",\n",
      ".\n",
      ".\n",
      ",\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ",\n",
      ",\n",
      "'s\n",
      "...\n",
      ",\n",
      ".\n",
      "(\n",
      "well-known\n",
      "comic-book\n",
      ")\n",
      "?\n",
      "``\n",
      "''\n",
      "comic-book\n",
      ".\n",
      ",\n",
      "'s\n",
      "(\n",
      "bus-ride\n",
      ")\n",
      "'s\n",
      "?\n",
      "(\n",
      "!\n",
      ")\n",
      ".\n",
      "``\n",
      "''\n",
      "``\n",
      "``\n",
      "''\n",
      "...\n",
      "...\n",
      "``\n",
      "''\n",
      ".\n",
      ",\n",
      ".\n",
      "``\n",
      "''\n",
      ",\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for sent in tokenized_sents:\n",
    "    for tok in sent:\n",
    "        if re.search(r'[^a-zA-Z0-9]', tok):  # find the non-letter and non-digit characters\n",
    "            print(tok)  # print the entire token containing the non-letter/non-digit character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Word Normalisation\n",
    "\n",
    "Many words can appear in different forms, including: \n",
    "* Conjugated verbs like \"think\", \"thinks\" and \"thought\",\n",
    "* Plural and singular nouns like \"dog\" and \"dogs\",\n",
    "* Common abbrevations and synonyms like \"USA\" and \"US\". \n",
    "\n",
    "Mapping all of these surface forms to a single root form reduces the size of the vocabulary that we have to deal with and can therefore improve the performance of text classifiers or topic models.\n",
    "\n",
    "The two most widely used tools for this task in English are the Porter Stemmer and WordNet Lemmatizer. These tools apply a series of regular expression substitutions to tokenised text to convert words to a standard format. \n",
    "* The Porter stemmer is much faster but just removes word prefixes and endings, which leads to some errors. It is often used when real-time or high-volume text processing is needed.\n",
    "* As well as applying regular expressions, lemmatizers look words up in a dictionary to find their root forms, so are more accurate but much slower. \n",
    "\n",
    "Let's start by applying the [Porter Stemmer class](https://www.nltk.org/_modules/nltk/stem/porter.html) to our tokenised text by calling the stem() method. The output may look a bit strange, but note that the aim of the stemmer is *not* to produce readable text, but to quickly and efficiently reduce variations of words to a single form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<STEMMED TOKENS>\n",
      "['it', 'is', 'hard', 'to', 'describ', 'thi', 'film', 'and', 'one', 'want', 'to', 'tri', 'hard', 'not', 'to', 'dismiss', 'it', 'too', 'quickli', 'becaus', 'you', 'have', 'a', 'feel', 'that', 'thi', 'might', 'just', 'be', 'the', 'perfect', 'film', 'for', 'some', '12', 'year', 'old', 'girl', '...', 'thi', 'film', 'ha', 'a', 'nice', 'concept-th', 'modern', 'version', 'of', 'sleep', 'beauti', 'with', 'a', 'twist', '.']\n",
      "<STEMMED TOKENS>\n",
      "['it', 'ha', 'some', 'rather', 'dreami', 'shot', 'and', 'some', 'nice', 'sketch', 'of', 'the', 'young', 'boy', 'relationship', 'with', 'hi', 'singl', 'work', 'mother', 'and', 'hi', 'schoolmat', '...', 'a', 'nice', 'start', 'you', 'might', 'say', ',', 'but', 'then', 'it', 'got', 'a', 'bit', 'greedi', ',', 'veri', 'greedi', ',', 'it', 'tri', 'to', 'be', 'a', 'scienc', 'fiction', ',', 'a', 'drama', ',', 'a', 'thriller', ',', 'a', 'possibl', 'romant', 'love', 'stori', ',', 'fairi', 'tale', ',', 'a', 'comedi', 'and', 'everyth', 'under', 'the', 'sun', '.']\n",
      "<STEMMED TOKENS>\n",
      "['the', 'result', 'just', 'left', 'the', 'audienc', 'feel', 'rather', 'inadequ', '.']\n",
      "<STEMMED TOKENS>\n",
      "['for', 'exampl', ',', 'the', 'scene', 'when', 'the', 'girl', '(', 'play', 'by', 'risa', 'goto', ')', 'final', 'woken', 'by', 'hi', '(', 'yuki', 'kohara', ')', 'kiss', ',', 'instead', 'of', 'be', 'romant', ',', 'it', 'tri', \"'s\", 'to', 'be', 'scari', 'in', 'order', 'to', 'make', 'us', 'laugh', 'afterward', '...', 'it', 'is', 'a', 'cheap', 'trick', ',', 'becaus', 'it', 'ruin', 'all', 'the', 'anticip', 'and', 'emot', 'which', 'it', 'wa', 'tri', 'to', 'build', 'for', 'the', 'better', 'half', 'of', 'the', 'film', '.', 'i', 'have', 'not', 'read', 'the', 'origin', 'stori', 'the', 'film', 'is', 'base', 'on', '(', 'it', 'is', 'the', 'well-known', 'work', 'by', 'the', 'comic-book', 'artist', 'osamu', 'tezuka', 'is', 'famou', 'with', 'hi', 'intrigu', 'and', 'intric', 'stori', ')', 'i', 'wonder', 'if', 'all', 'the', 'problem', 'exsist', 'in', 'the', 'origin', 'stori', 'or', 'did', 'it', 'occur', 'in', 'the', 'adapt', '?']\n",
      "<STEMMED TOKENS>\n",
      "['it', 'is', 'rather', 'illog', 'even', 'for', 'someon', 'who', 'is', 'use', 'to', 'the', '``', 'fussi', 'logic', \"''\", 'of', 'those', 'japanes', 'comic-book', '.']\n",
      "<STEMMED TOKENS>\n",
      "['for', 'instanc', ',', 'how', 'did', 'yuki', 'kohara', \"'s\", 'charact', 'manag', 'to', 'get', 'to', 'the', 'hospit', 'in', 'an', 'instant', '(', 'when', 'it', 'suppos', 'to', 'be', 'a', 'long', 'bus-rid', 'away', ')', 'to', 'run', 'away', 'risa', 'goto', \"'s\", 'charact', 'in', 'front', 'of', 'the', 'tv', 'camera', 'right', 'after', 'he', 'saw', 'her', 'live', 'interview', 'on', 'the', 'televis', '?', 'there', 'are', 'also', 'some', 'scene', 'that', 'is', 'directli', 'copi', '(', 'veri', 'uncr', '!', ')']\n",
      "<STEMMED TOKENS>\n",
      "['from', 'other', 'film', 'and', 'they', 'all', 'seem', 'rather', 'pointlessli', 'annoy', 'ie', '.']\n",
      "<STEMMED TOKENS>\n",
      "['the', 'famou', '``', 'the', 'lion', 'mouth', 'ha', 'caugh', 'my', 'hand', \"''\", 'scene', 'from', '``', 'the', '``', 'roman', 'holiday', \"''\", 'the', 'film', 'tri', 'to', 'be', 'everyth', 'but', 'end', 'up', 'be', 'noth', '...', 'it', 'fail', 'to', 'be', 'a', 'fairi', 'tale', 'and', 'it', 'did', 'not', 'have', 'enough', 'joke', 'to', 'be', 'a', 'comedi', '...', 'and', 'strang', 'there', 'are', 'some', 'scene', 'that', 'even', 'seem', 'like', 'an', 'unintent', '``', 'ghost', \"''\", 'movi', '.']\n",
      "<STEMMED TOKENS>\n",
      "['nevertheless', ',', 'one', 'should', 'give', 'it', 'credit', 'that', 'it', 'ha', 'manag', 'to', 'caputur', 'some', 'of', 'the', 'sentiment', 'of', 'the', 'japanes', 'teenag', '.', 'it', 'is', 'by', 'watch', 'thi', 'film', 'i', 'have', 'a', 'feel', 'that', 'there', 'might', 'be', 'some', 'film', 'that', 'should', 'have', 'come', 'with', 'a', 'warn', 'label', 'that', 'said', '``', 'thi', 'film', 'might', 'onli', 'be', 'suitabl', 'for', 'person', 'under', 'the', '18', 'of', 'age', \"''\", ',', 'it', 'would', 'have', 'definitli', 'been', 'on', 'the', 'poster', 'of', 'thi', 'film', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.PorterStemmer() \n",
    "stemmed_sents = []\n",
    "\n",
    "for sent in tokenized_sents:\n",
    "    stemmed_sent = [stemmer.stem(tok) for tok in sent]\n",
    "    \n",
    "    stemmed_sents.append(stemmed_sent)\n",
    "    \n",
    "    print(\"<STEMMED TOKENS>\")\n",
    "    print(stemmed_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the stemming results to lemmatisation. For this task, NLTK provides the [class WordNetLemmatizer](https://www.nltk.org/_modules/nltk/stem/wordnet.html) with the method lemmatize(). This method takes an argument, `pos`, that determines whether the lemmatizer is applied to nouns, verbs, adjectives or adverbs.\n",
    "\n",
    "**TO-DO 6:** Use the WordNetLemmatizer to lemmatize the nouns in the tokenized sentences. Set the `pos` argument to 'n'. \n",
    "\n",
    "**TO-DO 7:** Add a second call to lemmatize() to lemmatize the verbs in the sentences as well. Set the `pos` argument to 'v'. \n",
    "\n",
    "How do the results compare with the Porter stemmer? \n",
    "\n",
    "How have the verbs in the sentences changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LEMMATIZED TOKENS>\n",
      "['It', 'be', 'hard', 'to', 'describe', 'this', 'film', 'and', 'one', 'want', 'to', 'try', 'hard', 'not', 'to', 'dismiss', 'it', 'too', 'quickly', 'because', 'you', 'have', 'a', 'feel', 'that', 'this', 'might', 'just', 'be', 'the', 'perfect', 'film', 'for', 'some', '12', 'year', 'old', 'girl', '...', 'This', 'film', 'have', 'a', 'nice', 'concept-the', 'modern', 'version', 'of', 'Sleeping', 'Beauty', 'with', 'a', 'twist', '.']\n",
      "<LEMMATIZED TOKENS>\n",
      "['It', 'have', 'some', 'rather', 'dreamy', 'shot', 'and', 'some', 'nice', 'sketch', 'of', 'the', 'young', 'boy', 'relationship', 'with', 'his', 'single', 'work', 'mother', 'and', 'his', 'schoolmate', '...', 'a', 'nice', 'start', 'you', 'might', 'say', ',', 'but', 'then', 'it', 'get', 'a', 'bite', 'greedy', ',', 'very', 'greedy', ',', 'it', 'try', 'to', 'be', 'a', 'science', 'fiction', ',', 'a', 'drama', ',', 'a', 'thriller', ',', 'a', 'possible', 'romantic', 'love', 'story', ',', 'fairy', 'tale', ',', 'a', 'comedy', 'and', 'everything', 'under', 'the', 'sun', '.']\n",
      "<LEMMATIZED TOKENS>\n",
      "['The', 'result', 'just', 'leave', 'the', 'audience', 'feel', 'rather', 'inadequate', '.']\n",
      "<LEMMATIZED TOKENS>\n",
      "['For', 'example', ',', 'the', 'scene', 'when', 'the', 'girl', '(', 'play', 'by', 'Risa', 'Goto', ')', 'finally', 'wake', 'by', 'his', '(', 'Yuki', 'Kohara', ')', 'kiss', ',', 'instead', 'of', 'be', 'romantic', ',', 'it', 'try', \"'s\", 'to', 'be', 'scary', 'in', 'order', 'to', 'make', 'u', 'laugh', 'afterwards', '...', 'it', 'be', 'a', 'cheap', 'trick', ',', 'because', 'it', 'ruin', 'all', 'the', 'anticipation', 'and', 'emotion', 'which', 'it', 'be', 'try', 'to', 'build', 'for', 'the', 'better', 'half', 'of', 'the', 'film', '.', 'I', 'have', 'not', 'read', 'the', 'original', 'story', 'the', 'film', 'be', 'base', 'on', '(', 'it', 'be', 'the', 'well-known', 'work', 'by', 'the', 'comic-book', 'artist', 'Osamu', 'Tezuka', 'be', 'famous', 'with', 'his', 'intrigue', 'and', 'intricate', 'story', ')', 'I', 'wonder', 'if', 'all', 'the', 'problem', 'exsist', 'in', 'the', 'original', 'story', 'or', 'do', 'it', 'occur', 'in', 'the', 'adaption', '?']\n",
      "<LEMMATIZED TOKENS>\n",
      "['It', 'be', 'rather', 'illogical', 'even', 'for', 'someone', 'who', 'be', 'use', 'to', 'the', '``', 'fussy', 'logic', \"''\", 'of', 'those', 'japanese', 'comic-book', '.']\n",
      "<LEMMATIZED TOKENS>\n",
      "['For', 'instance', ',', 'how', 'do', 'Yuki', 'Kohara', \"'s\", 'character', 'manage', 'to', 'get', 'to', 'the', 'hospital', 'in', 'an', 'instant', '(', 'when', 'it', 'suppose', 'to', 'be', 'a', 'long', 'bus-ride', 'away', ')', 'to', 'run', 'away', 'Risa', 'Goto', \"'s\", 'character', 'in', 'front', 'of', 'the', 'tv', 'camera', 'right', 'after', 'he', 'saw', 'her', 'live', 'interview', 'on', 'the', 'television', '?', 'There', 'be', 'also', 'some', 'scene', 'that', 'be', 'directly', 'copy', '(', 'very', 'uncreative', '!', ')']\n",
      "<LEMMATIZED TOKENS>\n",
      "['from', 'other', 'film', 'and', 'they', 'all', 'seem', 'rather', 'pointlessly', 'annoy', 'ie', '.']\n",
      "<LEMMATIZED TOKENS>\n",
      "['the', 'famous', '``', 'the', 'Lion', 'mouth', 'have', 'caugh', 'my', 'hand', \"''\", 'scene', 'from', '``', 'the', '``', 'Roman', 'Holiday', \"''\", 'The', 'film', 'try', 'to', 'be', 'everything', 'but', 'end', 'up', 'be', 'nothing', '...', 'it', 'fail', 'to', 'be', 'a', 'fairy', 'tale', 'and', 'it', 'do', 'not', 'have', 'enough', 'joke', 'to', 'be', 'a', 'comedy', '...', 'and', 'strangely', 'there', 'be', 'some', 'scene', 'that', 'even', 'seem', 'like', 'an', 'unintentional', '``', 'ghost', \"''\", 'movie', '.']\n",
      "<LEMMATIZED TOKENS>\n",
      "['Nevertheless', ',', 'one', 'should', 'give', 'it', 'credit', 'that', 'it', 'have', 'manage', 'to', 'caputured', 'some', 'of', 'the', 'sentiment', 'of', 'the', 'japanese', 'teenager', '.', 'It', 'be', 'by', 'watch', 'this', 'film', 'I', 'have', 'a', 'feel', 'that', 'there', 'might', 'be', 'some', 'film', 'that', 'should', 'have', 'come', 'with', 'a', 'warn', 'label', 'that', 'say', '``', 'this', 'film', 'might', 'only', 'be', 'suitable', 'for', 'person', 'under', 'the', '18', 'of', 'age', \"''\", ',', 'it', 'would', 'have', 'definitly', 'be', 'on', 'the', 'poster', 'of', 'this', 'film', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer() \n",
    "lemma_sents = []\n",
    "for sent in tokenized_sents:\n",
    "    \n",
    "    ### WRITE YOUR OWN CODE HERE\n",
    "    lemma_sent = [lemmatizer.lemmatize(lemmatizer.lemmatize(tok, pos='v'), pos='n') for tok in sent]\n",
    "    #######\n",
    "    \n",
    "    lemma_sents.append(lemma_sent)\n",
    "    \n",
    "    print(\"<LEMMATIZED TOKENS>\")\n",
    "    print(lemma_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Vector Representations of Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions are great for tasks such as finding specific patterns in text. However, it is not always possible to write a regular expression that captures all the patterns we want to find. For example, suppose we want to classify social media posts into positive and negative sentiment to see if they are favourable towards a particular famous person. We can't write down a pattern to capture all the ways of saying favourable things about that person -- it's way too diverse. \n",
    "\n",
    "Instead, we can use machine learning to learn to recognise a wide range of patterns from a set of examples. To classify a new example, a machine learning classifier requires a *representation* of each piece of text that it can compare against the patterns it has learned. Raw text is not usually a suitable representation, and we usually need a way to turn text data into vectors -- essentially, lists of numbers. Vector representations have several advantages: for example, they map words, sentences and documents to points in a high-dimensional space, so we can learn to separate the space into different regions corresponding to classes; they allow us to compute the similarity between pieces of text by computing distances. \n",
    "\n",
    "In this section, we'll loook at the simplest way to obtain vector representations of words and documents by constructing a *term-document matrix*. A term-document matrix has rows referring to terms, and columns referring to documents. Each element contains a count of how many times a particular term occurred in a particular document. We can treat rows as vector representations of terms, and columns as vector representations of documents.\n",
    "\n",
    "To compute term-document matrices, we need to use the text normalisation steps above. Most importantly, we need to tokenise the text into words (and other types of token) so we can count their occurrences. Normalising the words is often helpful too, as it reduces the number of rows in the matrix and makes it less sparse.\n",
    "\n",
    "We can compute a term-document matrix using the CountVectorizer class from Scikit-learn. By default, this class takes raw text sequences and applies an English tokenizer automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=input,-%7B%27filename%27%2C%20%27file%27%2C%20%27content%27%7D%2C%20default%3D%27content%27\">\n",
       "            input\n",
       "            <span class=\"param-doc-description\">input: {'filename', 'file', 'content'}, default='content'<br><br>- If `'filename'`, the sequence passed as an argument to fit is<br>  expected to be a list of filenames that need reading to fetch<br>  the raw content to analyze.<br><br>- If `'file'`, the sequence items must have a 'read' method (file-like<br>  object) that is called to fetch the bytes in memory.<br><br>- If `'content'`, the input is expected to be a sequence of items that<br>  can be of type string or byte.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=encoding,-str%2C%20default%3D%27utf-8%27\">\n",
       "            encoding\n",
       "            <span class=\"param-doc-description\">encoding: str, default='utf-8'<br><br>If bytes or files are given to analyze, this encoding is used to<br>decode.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=decode_error,-%7B%27strict%27%2C%20%27ignore%27%2C%20%27replace%27%7D%2C%20default%3D%27strict%27\">\n",
       "            decode_error\n",
       "            <span class=\"param-doc-description\">decode_error: {'strict', 'ignore', 'replace'}, default='strict'<br><br>Instruction on what to do if a byte sequence is given to analyze that<br>contains characters not of the given `encoding`. By default, it is<br>'strict', meaning that a UnicodeDecodeError will be raised. Other<br>values are 'ignore' and 'replace'.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=strip_accents,-%7B%27ascii%27%2C%20%27unicode%27%7D%20or%20callable%2C%20default%3DNone\">\n",
       "            strip_accents\n",
       "            <span class=\"param-doc-description\">strip_accents: {'ascii', 'unicode'} or callable, default=None<br><br>Remove accents and perform other character normalization<br>during the preprocessing step.<br>'ascii' is a fast method that only works on characters that have<br>a direct ASCII mapping.<br>'unicode' is a slightly slower method that works on any characters.<br>None (default) means no character normalization is performed.<br><br>Both 'ascii' and 'unicode' use NFKD normalization from<br>:func:`unicodedata.normalize`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=lowercase,-bool%2C%20default%3DTrue\">\n",
       "            lowercase\n",
       "            <span class=\"param-doc-description\">lowercase: bool, default=True<br><br>Convert all characters to lowercase before tokenizing.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=preprocessor,-callable%2C%20default%3DNone\">\n",
       "            preprocessor\n",
       "            <span class=\"param-doc-description\">preprocessor: callable, default=None<br><br>Override the preprocessing (strip_accents and lowercase) stage while<br>preserving the tokenizing and n-grams generation steps.<br>Only applies if ``analyzer`` is not callable.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=tokenizer,-callable%2C%20default%3DNone\">\n",
       "            tokenizer\n",
       "            <span class=\"param-doc-description\">tokenizer: callable, default=None<br><br>Override the string tokenization step while preserving the<br>preprocessing and n-grams generation steps.<br>Only applies if ``analyzer == 'word'``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=stop_words,-%7B%27english%27%7D%2C%20list%2C%20default%3DNone\">\n",
       "            stop_words\n",
       "            <span class=\"param-doc-description\">stop_words: {'english'}, list, default=None<br><br>If 'english', a built-in stop word list for English is used.<br>There are several known issues with 'english' and you should<br>consider an alternative (see :ref:`stop_words`).<br><br>If a list, that list is assumed to contain stop words, all of which<br>will be removed from the resulting tokens.<br>Only applies if ``analyzer == 'word'``.<br><br>If None, no stop words will be used. In this case, setting `max_df`<br>to a higher value, such as in the range (0.7, 1.0), can automatically detect<br>and filter stop words based on intra corpus document frequency of terms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=token_pattern,-str%20or%20None%2C%20default%3Dr%22%28%3Fu%29%5C%5Cb%5C%5Cw%5C%5Cw%2B%5C%5Cb%22\">\n",
       "            token_pattern\n",
       "            <span class=\"param-doc-description\">token_pattern: str or None, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"<br><br>Regular expression denoting what constitutes a \"token\", only used<br>if ``analyzer == 'word'``. The default regexp select tokens of 2<br>or more alphanumeric characters (punctuation is completely ignored<br>and always treated as a token separator).<br><br>If there is a capturing group in token_pattern then the<br>captured group content, not the entire match, becomes the token.<br>At most one capturing group is permitted.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=ngram_range,-tuple%20%28min_n%2C%20max_n%29%2C%20default%3D%281%2C%201%29\">\n",
       "            ngram_range\n",
       "            <span class=\"param-doc-description\">ngram_range: tuple (min_n, max_n), default=(1, 1)<br><br>The lower and upper boundary of the range of n-values for different<br>word n-grams or char n-grams to be extracted. All values of n such<br>such that min_n <= n <= max_n will be used. For example an<br>``ngram_range`` of ``(1, 1)`` means only unigrams, ``(1, 2)`` means<br>unigrams and bigrams, and ``(2, 2)`` means only bigrams.<br>Only applies if ``analyzer`` is not callable.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=analyzer,-%7B%27word%27%2C%20%27char%27%2C%20%27char_wb%27%7D%20or%20callable%2C%20default%3D%27word%27\">\n",
       "            analyzer\n",
       "            <span class=\"param-doc-description\">analyzer: {'word', 'char', 'char_wb'} or callable, default='word'<br><br>Whether the feature should be made of word n-gram or character<br>n-grams.<br>Option 'char_wb' creates character n-grams only from text inside<br>word boundaries; n-grams at the edges of words are padded with space.<br><br>If a callable is passed it is used to extract the sequence of features<br>out of the raw, unprocessed input.<br><br>.. versionchanged:: 0.21<br><br>Since v0.21, if ``input`` is ``filename`` or ``file``, the data is<br>first read from the file and then passed to the given callable<br>analyzer.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=max_df,-float%20in%20range%20%5B0.0%2C%201.0%5D%20or%20int%2C%20default%3D1.0\">\n",
       "            max_df\n",
       "            <span class=\"param-doc-description\">max_df: float in range [0.0, 1.0] or int, default=1.0<br><br>When building the vocabulary ignore terms that have a document<br>frequency strictly higher than the given threshold (corpus-specific<br>stop words).<br>If float, the parameter represents a proportion of documents, integer<br>absolute counts.<br>This parameter is ignored if vocabulary is not None.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=min_df,-float%20in%20range%20%5B0.0%2C%201.0%5D%20or%20int%2C%20default%3D1\">\n",
       "            min_df\n",
       "            <span class=\"param-doc-description\">min_df: float in range [0.0, 1.0] or int, default=1<br><br>When building the vocabulary ignore terms that have a document<br>frequency strictly lower than the given threshold. This value is also<br>called cut-off in the literature.<br>If float, the parameter represents a proportion of documents, integer<br>absolute counts.<br>This parameter is ignored if vocabulary is not None.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=max_features,-int%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, default=None<br><br>If not None, build a vocabulary that only consider the top<br>`max_features` ordered by term frequency across the corpus.<br>Otherwise, all features are used.<br><br>This parameter is ignored if vocabulary is not None.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=vocabulary,-Mapping%20or%20iterable%2C%20default%3DNone\">\n",
       "            vocabulary\n",
       "            <span class=\"param-doc-description\">vocabulary: Mapping or iterable, default=None<br><br>Either a Mapping (e.g., a dict) where keys are terms and values are<br>indices in the feature matrix, or an iterable over terms. If not<br>given, a vocabulary is determined from the input documents. Indices<br>in the mapping should not be repeated and should not have any gap<br>between 0 and the largest index.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=binary,-bool%2C%20default%3DFalse\">\n",
       "            binary\n",
       "            <span class=\"param-doc-description\">binary: bool, default=False<br><br>If True, all non zero counts are set to 1. This is useful for discrete<br>probabilistic models that model binary events rather than integer<br>counts.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#:~:text=dtype,-dtype%2C%20default%3Dnp.int64\">\n",
       "            dtype\n",
       "            <span class=\"param-doc-description\">dtype: dtype, default=np.int64<br><br>Type of the matrix returned by fit_transform() or transform().</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.int64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "input_text = [review['text'] for review in train_dataset]  # use a list of sentences as an example. \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(input_text)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you seen the method \"fit()\" before with other Scikit-learn classes? What do you think it does for the CountVectorizer?\n",
    "\n",
    "Looking inside the vectorizer, we can see the vocabulary it has created from the input text: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thought': 4409,\n",
       " 'this': 4404,\n",
       " 'movie': 2888,\n",
       " 'was': 4765,\n",
       " 'really': 3535,\n",
       " 'great': 1939,\n",
       " 'helena': 2050,\n",
       " 'did': 1198,\n",
       " 'an': 197,\n",
       " 'amazing': 180,\n",
       " 'job': 2359,\n",
       " 'in': 2207,\n",
       " 'it': 2325,\n",
       " 'she': 3910,\n",
       " 'played': 3285,\n",
       " 'her': 2060,\n",
       " 'character': 707,\n",
       " 'very': 4693,\n",
       " 'well': 4796,\n",
       " 'awesome': 350,\n",
       " 'actress': 97,\n",
       " 'br': 538,\n",
       " 'the': 4380,\n",
       " 'also': 173,\n",
       " 'funny': 1807,\n",
       " 'too': 4458,\n",
       " 'jokes': 2370,\n",
       " 'were': 4798,\n",
       " 'couldnt': 973,\n",
       " 'stop': 4156,\n",
       " 'laughing': 2490,\n",
       " 'think': 4400,\n",
       " 'everyone': 1498,\n",
       " 'should': 3930,\n",
       " 'see': 3828,\n",
       " 'dynasty': 1358,\n",
       " 'revisited': 3660,\n",
       " 'hawaii': 2024,\n",
       " 'full': 1803,\n",
       " 'of': 3053,\n",
       " 'clichs': 783,\n",
       " 'highly': 2079,\n",
       " 'predictable': 3364,\n",
       " 'unrealistic': 4623,\n",
       " 'and': 202,\n",
       " 'sometimes': 4040,\n",
       " 'even': 1489,\n",
       " 'stupid': 4206,\n",
       " 'if': 2172,\n",
       " 'you': 4924,\n",
       " 'have': 2021,\n",
       " 'nothing': 3013,\n",
       " 'better': 451,\n",
       " 'to': 4445,\n",
       " 'do': 1268,\n",
       " 'however': 2137,\n",
       " 'does': 1275,\n",
       " 'provide': 3443,\n",
       " '40': 42,\n",
       " 'minutes': 2808,\n",
       " 'simple': 3962,\n",
       " 'unpretensive': 4620,\n",
       " 'entertainment': 1457,\n",
       " 'endless': 1431,\n",
       " 'looks': 2605,\n",
       " 'at': 309,\n",
       " 'male': 2674,\n",
       " 'female': 1642,\n",
       " 'muscles': 2909,\n",
       " 'good': 1906,\n",
       " 'photography': 3258,\n",
       " 'spectacular': 4074,\n",
       " 'hawaiian': 2025,\n",
       " 'scenery': 3784,\n",
       " 'on': 3072,\n",
       " 'other': 3110,\n",
       " 'hand': 1992,\n",
       " 'are': 265,\n",
       " 'looking': 2604,\n",
       " 'for': 1741,\n",
       " 'anything': 232,\n",
       " 'more': 2859,\n",
       " 'than': 4375,\n",
       " 'that': 4379,\n",
       " 'stay': 4130,\n",
       " 'away': 347,\n",
       " 'oh': 3064,\n",
       " 'by': 620,\n",
       " 'way': 4775,\n",
       " 'ever': 1494,\n",
       " 'worked': 4882,\n",
       " 'hotel': 2129,\n",
       " 'or': 3093,\n",
       " 'know': 2440,\n",
       " 'about': 61,\n",
       " 'running': 3739,\n",
       " 'one': 3074,\n",
       " 'two': 4550,\n",
       " 'options': 3092,\n",
       " 'will': 4833,\n",
       " 'feel': 1635,\n",
       " 'sick': 3944,\n",
       " 'every': 1495,\n",
       " 'sheer': 3911,\n",
       " 'stupidity': 4207,\n",
       " 'silliness': 3954,\n",
       " 'how': 2136,\n",
       " 'show': 3933,\n",
       " 'presents': 3378,\n",
       " 'business': 614,\n",
       " 'look': 2602,\n",
       " 'as': 281,\n",
       " 'science': 3793,\n",
       " 'fiction': 1655,\n",
       " 'comedy': 832,\n",
       " 'lie': 2545,\n",
       " 'back': 358,\n",
       " 'relax': 3585,\n",
       " 'laugh': 2487,\n",
       " 'entire': 1459,\n",
       " 'weissmuller': 4795,\n",
       " 'tarzan': 4328,\n",
       " 'series': 3868,\n",
       " 'dvd': 1353,\n",
       " 'fully': 1804,\n",
       " 'restored': 3640,\n",
       " 'editions': 1373,\n",
       " 'never': 2966,\n",
       " 'tire': 4440,\n",
       " 'watching': 4772,\n",
       " 'them': 4386,\n",
       " 'my': 2916,\n",
       " 'personal': 3242,\n",
       " 'favorite': 1627,\n",
       " 'is': 2318,\n",
       " 'his': 2093,\n",
       " 'mate': 2720,\n",
       " 'due': 1340,\n",
       " 'entirely': 1460,\n",
       " 'almost': 167,\n",
       " 'maureen': 2728,\n",
       " 'sullivan': 4246,\n",
       " 'costume': 969,\n",
       " 'occasional': 3043,\n",
       " 'flashes': 1704,\n",
       " 'genital': 1851,\n",
       " 'area': 266,\n",
       " 'beneath': 441,\n",
       " 'leather': 2512,\n",
       " 'flap': 1701,\n",
       " 'hanging': 2001,\n",
       " 'front': 1798,\n",
       " 'before': 424,\n",
       " 'anyone': 231,\n",
       " 'claims': 767,\n",
       " 'wasn': 4767,\n",
       " 'what': 4804,\n",
       " 'like': 2553,\n",
       " 'let': 2536,\n",
       " 'me': 2735,\n",
       " 'say': 3775,\n",
       " 'watched': 4771,\n",
       " 'numerous': 3029,\n",
       " 'time': 4432,\n",
       " 'high': 2075,\n",
       " 'zoom': 4943,\n",
       " 'mode': 2834,\n",
       " 'trust': 4531,\n",
       " 'completely': 861,\n",
       " 'naked': 2924,\n",
       " 'underneath': 4577,\n",
       " 'several': 3880,\n",
       " 'times': 4434,\n",
       " 'especially': 1477,\n",
       " 'during': 1350,\n",
       " 'lion': 2563,\n",
       " 'attack': 313,\n",
       " 'end': 1427,\n",
       " 'careful': 658,\n",
       " 'viewing': 4708,\n",
       " 'slow': 4003,\n",
       " 'motion': 2873,\n",
       " 'maximum': 2729,\n",
       " 'reveal': 3651,\n",
       " 'shaved': 3907,\n",
       " 'except': 1514,\n",
       " 'tiny': 4439,\n",
       " 'patch': 3189,\n",
       " 'dark': 1080,\n",
       " 'hair': 1986,\n",
       " 'covering': 991,\n",
       " 'labia': 2456,\n",
       " 'there': 4393,\n",
       " 'no': 2990,\n",
       " 'mistake': 2824,\n",
       " 'all': 161,\n",
       " 'swimming': 4297,\n",
       " 'scene': 3783,\n",
       " 'being': 433,\n",
       " 'body': 505,\n",
       " 'double': 1291,\n",
       " 'skin': 3986,\n",
       " 'suit': 4242,\n",
       " 'yes': 4918,\n",
       " 'but': 616,\n",
       " 'not': 3008,\n",
       " 'wearing': 4785,\n",
       " 'any': 228,\n",
       " 'else': 1407,\n",
       " 'again': 133,\n",
       " 'shows': 3938,\n",
       " 'everything': 1499,\n",
       " 'those': 4407,\n",
       " 'who': 4821,\n",
       " 'want': 4751,\n",
       " 'now': 3020,\n",
       " 'controversy': 939,\n",
       " 'out': 3115,\n",
       " 'move': 2884,\n",
       " 'actual': 98,\n",
       " 'script': 3809,\n",
       " 'written': 4906,\n",
       " 'tightly': 4429,\n",
       " 'action': 91,\n",
       " 'sequences': 3862,\n",
       " 'simply': 3964,\n",
       " 'although': 177,\n",
       " 'obviously': 3042,\n",
       " 'stuntman': 4204,\n",
       " 'riding': 3675,\n",
       " 'rhino': 3665,\n",
       " 'actually': 99,\n",
       " 'wrestles': 4899,\n",
       " 'big': 460,\n",
       " 'use': 4653,\n",
       " 'background': 360,\n",
       " 'shots': 3929,\n",
       " 'second': 3820,\n",
       " 'unit': 4605,\n",
       " 'stuff': 4202,\n",
       " 'from': 1797,\n",
       " 'africa': 129,\n",
       " 'blended': 481,\n",
       " 'with': 4853,\n",
       " 'studio': 4201,\n",
       " 'us': 4651,\n",
       " 'locations': 2592,\n",
       " 'making': 2672,\n",
       " 'hard': 2011,\n",
       " 'tell': 4352,\n",
       " 'which': 4814,\n",
       " 'don': 1281,\n",
       " 'complain': 855,\n",
       " 'much': 2894,\n",
       " 'though': 4408,\n",
       " 'remember': 3596,\n",
       " '90': 53,\n",
       " 'films': 1675,\n",
       " 'phony': 3257,\n",
       " 'anyway': 234,\n",
       " 'so': 4023,\n",
       " 'just': 2384,\n",
       " 'enjoy': 1444,\n",
       " 'damned': 1064,\n",
       " 'thing': 4398,\n",
       " 'bowl': 533,\n",
       " 'popcorn': 3323,\n",
       " 'some': 4035,\n",
       " 'cold': 809,\n",
       " 'beer': 422,\n",
       " 'fresh': 1785,\n",
       " 'pack': 3142,\n",
       " 'smokes': 4013,\n",
       " 'sexy': 3889,\n",
       " 'willing': 4836,\n",
       " 'girlfriend': 1876,\n",
       " 'wife': 4826,\n",
       " 'isn': 2322,\n",
       " 'line': 2561,\n",
       " 'either': 1390,\n",
       " 'lol': 2594,\n",
       " 'final': 1677,\n",
       " 'word': 4875,\n",
       " 'nudity': 3025,\n",
       " 'beginning': 428,\n",
       " 'while': 4816,\n",
       " 'white': 4819,\n",
       " 'hunters': 2152,\n",
       " 'speaking': 4067,\n",
       " 'dialogue': 1195,\n",
       " 'keep': 2394,\n",
       " 'your': 4926,\n",
       " 'eyes': 1566,\n",
       " 'extras': 1560,\n",
       " 'nude': 3024,\n",
       " 'african': 130,\n",
       " 'girls': 1877,\n",
       " 'shot': 3928,\n",
       " 'location': 2591,\n",
       " 'behind': 432,\n",
       " 'racist': 3492,\n",
       " 'standards': 4110,\n",
       " '1930': 12,\n",
       " 'until': 4634,\n",
       " '1960': 18,\n",
       " 'colored': 823,\n",
       " 'people': 3217,\n",
       " 'portrayed': 3330,\n",
       " 'then': 4390,\n",
       " 'shaft': 3892,\n",
       " 'hadn': 1983,\n",
       " 'been': 421,\n",
       " 'nor': 3001,\n",
       " 'would': 4894,\n",
       " 'audiences': 328,\n",
       " 'accepted': 75,\n",
       " 'portrayals': 3329,\n",
       " 'history': 2096,\n",
       " 'safaris': 3752,\n",
       " 'natives': 2939,\n",
       " 'carrying': 665,\n",
       " 'luggage': 2634,\n",
       " 'their': 4385,\n",
       " 'heads': 2031,\n",
       " 'die': 1200,\n",
       " 'heroic': 2067,\n",
       " 'death': 1102,\n",
       " 'trying': 4535,\n",
       " 'save': 3773,\n",
       " 'jane': 2337,\n",
       " 'matter': 2724,\n",
       " 'fact': 1571,\n",
       " 'gene': 1845,\n",
       " 'autry': 338,\n",
       " 'treated': 4505,\n",
       " 'native': 2938,\n",
       " 'americans': 190,\n",
       " 'westerns': 4803,\n",
       " 'real': 3526,\n",
       " 'human': 2144,\n",
       " 'beings': 434,\n",
       " 'hollywood': 2106,\n",
       " 'began': 426,\n",
       " 'okay': 3065,\n",
       " 'wanted': 4752,\n",
       " 'read': 3524,\n",
       " 'comments': 841,\n",
       " 'leaving': 2515,\n",
       " 'review': 3657,\n",
       " 'majority': 2667,\n",
       " 'definately': 1118,\n",
       " 'rules': 3737,\n",
       " 'aweful': 349,\n",
       " 'acting': 90,\n",
       " 'non': 2997,\n",
       " 'realistic': 3528,\n",
       " 'animation': 212,\n",
       " 'countless': 977,\n",
       " 'errors': 1473,\n",
       " 'hoping': 2118,\n",
       " 'flaps': 1702,\n",
       " 'extended': 1555,\n",
       " 'stretch': 4182,\n",
       " 'imagination': 2187,\n",
       " 'can': 639,\n",
       " 'extend': 1554,\n",
       " 'without': 4856,\n",
       " 'engines': 1440,\n",
       " 'landing': 2470,\n",
       " 'gear': 1840,\n",
       " 'cannot': 645,\n",
       " 'be': 401,\n",
       " 'lowered': 2629,\n",
       " 'unless': 4610,\n",
       " 'electricity': 1396,\n",
       " 'little': 2578,\n",
       " 'fan': 1598,\n",
       " 'going': 1899,\n",
       " 'sufficient': 4236,\n",
       " 'lower': 2628,\n",
       " 'quite': 3489,\n",
       " 'peculiar': 3205,\n",
       " 'when': 4809,\n",
       " 'they': 4396,\n",
       " 'landed': 2469,\n",
       " 'wheels': 4808,\n",
       " 'touched': 4469,\n",
       " 'down': 1295,\n",
       " 'nose': 3006,\n",
       " 'broke': 572,\n",
       " 'off': 3054,\n",
       " 'thus': 4422,\n",
       " 'suspending': 4281,\n",
       " 'plane': 3280,\n",
       " 'both': 524,\n",
       " 'tires': 4442,\n",
       " 'air': 149,\n",
       " 'captain': 650,\n",
       " 'apply': 252,\n",
       " 'left': 2519,\n",
       " 'right': 3676,\n",
       " 'brakes': 542,\n",
       " 'weren': 4799,\n",
       " 'touching': 4471,\n",
       " 'ground': 1951,\n",
       " 'forget': 1752,\n",
       " 'spoilers': 4086,\n",
       " 'director': 1223,\n",
       " 'find': 1681,\n",
       " 'planes': 3281,\n",
       " 'attempting': 316,\n",
       " 'sorry': 4052,\n",
       " 'technical': 4337,\n",
       " 'rant': 3506,\n",
       " 'give': 1878,\n",
       " '10': 0,\n",
       " 'where': 4810,\n",
       " 'sidewalk': 3948,\n",
       " 'ends': 1432,\n",
       " 'otto': 3113,\n",
       " 'preminger': 3370,\n",
       " 'reunites': 3649,\n",
       " 'dana': 1066,\n",
       " 'andrews': 203,\n",
       " 'tierney': 4425,\n",
       " 'surely': 4267,\n",
       " 'hopes': 2117,\n",
       " 'recapturing': 3543,\n",
       " 'magic': 2658,\n",
       " 'laura': 2494,\n",
       " 're': 3519,\n",
       " 'wildly': 4831,\n",
       " 'dissimilar': 1255,\n",
       " 'set': 3873,\n",
       " 'different': 1203,\n",
       " 'strata': 4178,\n",
       " 'new': 2969,\n",
       " 'york': 4922,\n",
       " 'mention': 2759,\n",
       " 'opposite': 3088,\n",
       " 'poles': 3309,\n",
       " 'noir': 2993,\n",
       " 'universe': 4606,\n",
       " 'fine': 1685,\n",
       " 'mist': 2823,\n",
       " 'gothic': 1919,\n",
       " 'hovers': 2135,\n",
       " 'over': 3126,\n",
       " 'upscale': 4646,\n",
       " 'manhattan': 2682,\n",
       " 'its': 2328,\n",
       " 'erotic': 1472,\n",
       " 'obsession': 3037,\n",
       " 'faint': 1580,\n",
       " 'whiff': 4815,\n",
       " 'necrophilia': 2949,\n",
       " 'pure': 3464,\n",
       " 'urban': 4648,\n",
       " 'soot': 4047,\n",
       " 'grit': 1948,\n",
       " 'befouling': 425,\n",
       " 'town': 4478,\n",
       " 'basement': 388,\n",
       " 'apartments': 237,\n",
       " 'steam': 4135,\n",
       " 'rooms': 3715,\n",
       " 'parking': 3168,\n",
       " 'garages': 1830,\n",
       " 'bit': 469,\n",
       " 'revered': 3655,\n",
       " 'forerunner': 1749,\n",
       " 'dyed': 1355,\n",
       " 'wool': 4874,\n",
       " 'contrast': 930,\n",
       " 'clutch': 799,\n",
       " '1944': 14,\n",
       " 'french': 1784,\n",
       " 'first': 1691,\n",
       " 'dubbed': 1337,\n",
       " 'still': 4153,\n",
       " 'sophisticated': 4048,\n",
       " 'murder': 2903,\n",
       " 'mystery': 2919,\n",
       " 'daylight': 1093,\n",
       " 'enters': 1454,\n",
       " 'only': 3077,\n",
       " 'temporary': 4356,\n",
       " 'sufferance': 4231,\n",
       " 'joseph': 2372,\n",
       " 'lashelle': 2477,\n",
       " 'makes': 2670,\n",
       " 'most': 2870,\n",
       " 'alleys': 163,\n",
       " 'brownstones': 581,\n",
       " 'docks': 1271,\n",
       " 'el': 1392,\n",
       " 'quintessential': 3487,\n",
       " 'city': 762,\n",
       " 'specifically': 4073,\n",
       " 'apple': 249,\n",
       " 'others': 3111,\n",
       " 'bumper': 604,\n",
       " 'crop': 1026,\n",
       " '1950': 15,\n",
       " 'side': 3945,\n",
       " 'street': 4180,\n",
       " 'sleeping': 3992,\n",
       " 'tattooed': 4332,\n",
       " 'stranger': 4174,\n",
       " 'edge': 1370,\n",
       " 'doom': 1286,\n",
       " 'opens': 3083,\n",
       " 'police': 3311,\n",
       " 'detective': 1185,\n",
       " 'carpet': 662,\n",
       " 'brutal': 583,\n",
       " 'ways': 4777,\n",
       " 'particularly': 3173,\n",
       " 'vendetta': 4684,\n",
       " 'towards': 4475,\n",
       " 'crime': 1019,\n",
       " 'boss': 523,\n",
       " 'gary': 1833,\n",
       " 'merrill': 2771,\n",
       " 'whom': 4823,\n",
       " 'we': 4779,\n",
       " 'learn': 2509,\n",
       " 'up': 4640,\n",
       " 'ne': 2945,\n",
       " 'er': 1469,\n",
       " 'father': 1622,\n",
       " 'towner': 4479,\n",
       " 'stabbed': 4097,\n",
       " 'floating': 1717,\n",
       " 'crap': 1001,\n",
       " 'game': 1822,\n",
       " 'operated': 3085,\n",
       " 'trigger': 4518,\n",
       " 'roughs': 3723,\n",
       " 'witness': 4857,\n",
       " 'causing': 683,\n",
       " 'him': 2083,\n",
       " 'fatal': 1619,\n",
       " 'crack': 995,\n",
       " 'skull': 3988,\n",
       " 'exacerbated': 1505,\n",
       " 'steel': 4137,\n",
       " 'plate': 3282,\n",
       " 'installed': 2273,\n",
       " 'veteran': 4694,\n",
       " 'head': 2029,\n",
       " 'realizing': 3534,\n",
       " 'already': 171,\n",
       " 'dumps': 1344,\n",
       " 'river': 3687,\n",
       " 'after': 131,\n",
       " 'suspect': 4279,\n",
       " 'had': 1981,\n",
       " 'taken': 4315,\n",
       " 'powder': 3351,\n",
       " 'course': 985,\n",
       " 'far': 1604,\n",
       " 'corpse': 963,\n",
       " 'discovered': 1236,\n",
       " 'estranged': 1481,\n",
       " 'turns': 4542,\n",
       " 'evidence': 1501,\n",
       " 'starts': 4123,\n",
       " 'turn': 4539,\n",
       " 'toward': 4474,\n",
       " 'tom': 4454,\n",
       " 'tully': 4536,\n",
       " 'hack': 1979,\n",
       " 'driver': 1322,\n",
       " 'happened': 2005,\n",
       " 'cruising': 1031,\n",
       " 'same': 3764,\n",
       " 'mean': 2736,\n",
       " 'streets': 4181,\n",
       " 'night': 2979,\n",
       " 'ample': 195,\n",
       " 'reason': 3538,\n",
       " 'abusive': 71,\n",
       " 'son': 4043,\n",
       " 'law': 2496,\n",
       " 'dead': 1097,\n",
       " 'embittered': 1413,\n",
       " 'loner': 2598,\n",
       " 'finds': 1684,\n",
       " 'summons': 4249,\n",
       " 'nature': 2942,\n",
       " 'he': 2028,\n",
       " 'tries': 4517,\n",
       " 'exonerate': 1529,\n",
       " 'keeping': 2395,\n",
       " 'own': 3138,\n",
       " 'involvement': 2314,\n",
       " 'whole': 4822,\n",
       " 'sordid': 4050,\n",
       " 'secret': 3823,\n",
       " 'epigrammatic': 1464,\n",
       " 'ben': 440,\n",
       " 'hecht': 2045,\n",
       " 'pungency': 3460,\n",
       " 'dressing': 1316,\n",
       " 'superior': 4257,\n",
       " 'tells': 4354,\n",
       " 'bunged': 609,\n",
       " 'barrelhouse': 382,\n",
       " 'fag': 1575,\n",
       " 'spread': 4095,\n",
       " 'attention': 318,\n",
       " 'half': 1988,\n",
       " 'dozen': 1301,\n",
       " 'characters': 709,\n",
       " 'here': 2063,\n",
       " 'sole': 4031,\n",
       " 'focus': 1725,\n",
       " 'role': 3703,\n",
       " 'less': 2534,\n",
       " 'central': 691,\n",
       " 'spectral': 4075,\n",
       " 'may': 2730,\n",
       " 'excelled': 1512,\n",
       " 'performance': 3226,\n",
       " 'tight': 4426,\n",
       " 'lipped': 2565,\n",
       " 'taciturn': 4307,\n",
       " 'eloquent': 1406,\n",
       " 'face': 1568,\n",
       " 'silently': 3952,\n",
       " 'registering': 3572,\n",
       " 'anguish': 208,\n",
       " 'obstinacy': 3040,\n",
       " 'has': 2016,\n",
       " 'brought': 580,\n",
       " 'pent': 3215,\n",
       " 'sufferer': 4233,\n",
       " 'release': 3586,\n",
       " 'through': 4418,\n",
       " 'safety': 3754,\n",
       " 'valve': 4668,\n",
       " 'violence': 4715,\n",
       " 'lashes': 2478,\n",
       " 'against': 134,\n",
       " 'loyal': 2630,\n",
       " 'partner': 3175,\n",
       " 'bert': 445,\n",
       " 'freed': 1781,\n",
       " 'sure': 4266,\n",
       " 'swift': 4295,\n",
       " 'road': 3690,\n",
       " 'redemption': 3557,\n",
       " 'agency': 138,\n",
       " 'beautiful': 411,\n",
       " 'co': 800,\n",
       " 'star': 4112,\n",
       " 'style': 4210,\n",
       " 'sweetened': 4292,\n",
       " 'ending': 1430,\n",
       " 'undermine': 4575,\n",
       " 'story': 4163,\n",
       " 'corruption': 966,\n",
       " 'entanglements': 1453,\n",
       " 'describe': 1163,\n",
       " 'film': 1669,\n",
       " 'wants': 4754,\n",
       " 'tried': 4516,\n",
       " 'dismiss': 1244,\n",
       " 'quickly': 3484,\n",
       " 'because': 415,\n",
       " 'feeling': 1636,\n",
       " 'might': 2785,\n",
       " 'perfect': 3223,\n",
       " '12': 3,\n",
       " 'years': 4914,\n",
       " 'old': 3066,\n",
       " 'girl': 1875,\n",
       " 'nice': 2975,\n",
       " 'concept': 871,\n",
       " 'modern': 2836,\n",
       " 'version': 4691,\n",
       " 'beauty': 413,\n",
       " 'twist': 4548,\n",
       " 'rather': 3512,\n",
       " 'dreamy': 1314,\n",
       " 'sketches': 3983,\n",
       " 'young': 4925,\n",
       " 'boy': 535,\n",
       " 'relationship': 3581,\n",
       " 'single': 3972,\n",
       " 'working': 4884,\n",
       " 'mother': 2872,\n",
       " 'schoolmate': 3790,\n",
       " 'start': 4119,\n",
       " 'got': 1918,\n",
       " 'greedy': 1942,\n",
       " 'drama': 1306,\n",
       " 'thriller': 4415,\n",
       " 'possible': 3336,\n",
       " 'romantic': 3709,\n",
       " 'love': 2620,\n",
       " 'fairy': 1584,\n",
       " 'tale': 4318,\n",
       " 'under': 4569,\n",
       " 'sun': 4250,\n",
       " 'result': 3641,\n",
       " 'audience': 327,\n",
       " 'inadequate': 2208,\n",
       " 'example': 1509,\n",
       " 'risa': 3683,\n",
       " 'goto': 1920,\n",
       " 'finally': 1679,\n",
       " 'woken': 4861,\n",
       " 'yuki': 4931,\n",
       " 'kohara': 2446,\n",
       " 'kiss': 2430,\n",
       " 'instead': 2278,\n",
       " 'try': 4534,\n",
       " 'scary': 3780,\n",
       " 'order': 3096,\n",
       " 'make': 2668,\n",
       " 'afterwards': 132,\n",
       " 'cheap': 720,\n",
       " 'trick': 4514,\n",
       " 'ruin': 3733,\n",
       " 'anticipation': 224,\n",
       " 'emotion': 1418,\n",
       " 'build': 593,\n",
       " 'original': 3101,\n",
       " 'base': 385,\n",
       " 'known': 2445,\n",
       " 'work': 4881,\n",
       " 'comic': 834,\n",
       " 'book': 512,\n",
       " 'artist': 276,\n",
       " 'osamu': 3106,\n",
       " 'tezuka': 4373,\n",
       " 'famous': 1597,\n",
       " 'intriguing': 2303,\n",
       " 'intricate': 2302,\n",
       " 'stories': 4160,\n",
       " 'wonder': 4865,\n",
       " 'problems': 3405,\n",
       " 'exsist': 1552,\n",
       " 'occur': 3047,\n",
       " 'adaption': 104,\n",
       " 'illogical': 2182,\n",
       " 'someone': 4038,\n",
       " 'used': 4654,\n",
       " 'fussy': 1811,\n",
       " 'logic': 2593,\n",
       " 'japanese': 2339,\n",
       " 'instance': 2276,\n",
       " 'manage': 2677,\n",
       " 'get': 1864,\n",
       " 'hospital': 2126,\n",
       " 'instant': 2277,\n",
       " 'suppose': 4263,\n",
       " 'long': 2599,\n",
       " 'bus': 612,\n",
       " 'ride': 3672,\n",
       " 'run': 3738,\n",
       " 'tv': 4545,\n",
       " 'cameras': 636,\n",
       " 'saw': 3774,\n",
       " 'live': 2580,\n",
       " 'interview': 2300,\n",
       " 'television': 4351,\n",
       " 'scenes': 3785,\n",
       " 'directly': 1222,\n",
       " 'copied': 953,\n",
       " 'uncreative': 4567,\n",
       " 'seem': 3833,\n",
       " 'pointlessly': 3305,\n",
       " 'annoying': 218,\n",
       " 'ie': 2171,\n",
       " 'mouth': 2882,\n",
       " 'caugh': 680,\n",
       " 'roman': 3708,\n",
       " 'holiday': 2105,\n",
       " 'fails': 1578,\n",
       " 'enough': 1450,\n",
       " 'strangely': 4173,\n",
       " 'unintentional': 4601,\n",
       " 'ghost': 1867,\n",
       " 'nevertheless': 2968,\n",
       " 'credit': 1015,\n",
       " 'managed': 2678,\n",
       " 'caputured': 653,\n",
       " 'sentiment': 3856,\n",
       " 'teenager': 4346,\n",
       " 'come': 828,\n",
       " 'warning': 4763,\n",
       " 'label': 2455,\n",
       " 'said': 3755,\n",
       " 'suitable': 4243,\n",
       " 'person': 3240,\n",
       " '18': 7,\n",
       " 'age': 136,\n",
       " 'definitly': 1124,\n",
       " 'poster': 3340,\n",
       " 'promisingly': 3426,\n",
       " 'early': 1361,\n",
       " 'frank': 1776,\n",
       " 'morgan': 2862,\n",
       " 'advises': 123,\n",
       " 'cooper': 951,\n",
       " 'marriage': 2702,\n",
       " 'daughter': 1088,\n",
       " 'anita': 213,\n",
       " 'louise': 2619,\n",
       " 'playing': 3288,\n",
       " 'unabashed': 4561,\n",
       " 'gold': 1901,\n",
       " 'digger': 1208,\n",
       " 'loudly': 2618,\n",
       " 'complains': 857,\n",
       " 'perceived': 3221,\n",
       " 'penury': 3216,\n",
       " 'hands': 1997,\n",
       " 'family': 1596,\n",
       " 'including': 2217,\n",
       " 'am': 179,\n",
       " 'actors': 96,\n",
       " 'mind': 2796,\n",
       " 'treasure': 4504,\n",
       " 'legend': 2522,\n",
       " 'lovely': 2624,\n",
       " 'versatile': 4687,\n",
       " 'appreciated': 253,\n",
       " 'seldom': 3842,\n",
       " 'seen': 3837,\n",
       " 'leading': 2506,\n",
       " 'teresa': 4364,\n",
       " 'wright': 4900,\n",
       " 'blessed': 483,\n",
       " 'range': 3504,\n",
       " 'usually': 4659,\n",
       " 'delivers': 1138,\n",
       " 'heart': 2037,\n",
       " 'warming': 4761,\n",
       " 'performances': 3227,\n",
       " 'promising': 3425,\n",
       " 'opening': 3082,\n",
       " 'slides': 3995,\n",
       " 'downhill': 1297,\n",
       " 'found': 1768,\n",
       " 'humorous': 2147,\n",
       " 'burning': 610,\n",
       " 'home': 2108,\n",
       " 'laws': 2500,\n",
       " 'butler': 617,\n",
       " 'such': 4225,\n",
       " 'fastidious': 1617,\n",
       " 'smoking': 4014,\n",
       " 'household': 2133,\n",
       " 'blithely': 489,\n",
       " 'walk': 4737,\n",
       " 'allowing': 164,\n",
       " 'continue': 924,\n",
       " 'alternatively': 176,\n",
       " 'certainly': 694,\n",
       " 'supply': 4260,\n",
       " 'means': 2742,\n",
       " 'disposing': 1252,\n",
       " 'ill': 2177,\n",
       " 'timed': 4433,\n",
       " 'cigarette': 755,\n",
       " 'moreover': 2860,\n",
       " 'nobody': 2992,\n",
       " 'common': 843,\n",
       " 'sense': 3850,\n",
       " 'permit': 3237,\n",
       " 'himself': 2084,\n",
       " 'holding': 2102,\n",
       " 'lit': 2575,\n",
       " 'asking': 290,\n",
       " 'crushes': 1032,\n",
       " 'handkerchief': 1993,\n",
       " 'sticks': 4152,\n",
       " 'pocket': 3301,\n",
       " 'sequence': 3861,\n",
       " 'made': 2651,\n",
       " 'foolish': 1738,\n",
       " 'gauche': 1835,\n",
       " 'poor': 3321,\n",
       " 'contrivance': 934,\n",
       " 'conceived': 869,\n",
       " 'filmed': 1670,\n",
       " 'induces': 2237,\n",
       " 'ridicule': 3673,\n",
       " 'laughter': 2492,\n",
       " 'forced': 1743,\n",
       " 'medical': 2748,\n",
       " 'examination': 1508,\n",
       " 'equally': 1466,\n",
       " 'contrived': 935,\n",
       " 'lets': 2537,\n",
       " 'undergo': 4571,\n",
       " 'complete': 860,\n",
       " 'advised': 122,\n",
       " 'purpose': 3467,\n",
       " 'giving': 1881,\n",
       " 'consent': 902,\n",
       " 'removed': 3604,\n",
       " 'reality': 3530,\n",
       " 'absurd': 67,\n",
       " 'stealing': 4134,\n",
       " 'babies': 354,\n",
       " 'hospitals': 2127,\n",
       " 'serious': 3869,\n",
       " 'legal': 2521,\n",
       " 'offense': 3056,\n",
       " 'overly': 3132,\n",
       " 'neurotic': 2963,\n",
       " 'baby': 355,\n",
       " 'feeding': 1634,\n",
       " 'weight': 4792,\n",
       " 'struck': 4193,\n",
       " 'nerve': 2960,\n",
       " 'few': 1652,\n",
       " 'experienced': 1536,\n",
       " 'anxiety': 227,\n",
       " 'newborn': 2970,\n",
       " 'tedious': 4343,\n",
       " 'wardrobe': 4758,\n",
       " 'prop': 3431,\n",
       " 'departments': 1151,\n",
       " 'went': 4797,\n",
       " 'top': 4462,\n",
       " 'paradoxically': 3161,\n",
       " 'writer': 4903,\n",
       " 'sleep': 3991,\n",
       " 'lines': 2562,\n",
       " 'generate': 1848,\n",
       " 'humor': 2146,\n",
       " 'miss': 2819,\n",
       " 'cylinders': 1056,\n",
       " 'laughs': 2491,\n",
       " 'mile': 2789,\n",
       " 'minute': 2807,\n",
       " 'light': 2549,\n",
       " 'year': 4913,\n",
       " 'energy': 1434,\n",
       " 'camera': 635,\n",
       " 'totally': 4467,\n",
       " 'wasted': 4769,\n",
       " 'interests': 2293,\n",
       " 'respective': 3636,\n",
       " 'fathers': 1623,\n",
       " 'cooped': 950,\n",
       " 'room': 3714,\n",
       " 'together': 4449,\n",
       " 'probably': 3403,\n",
       " 'rich': 3668,\n",
       " 'vein': 4683,\n",
       " 'somewhere': 4042,\n",
       " 'mine': 2800,\n",
       " 'none': 2998,\n",
       " 'extracted': 1559,\n",
       " 'likable': 2552,\n",
       " 'hurt': 2155,\n",
       " 'predictably': 3365,\n",
       " 'gets': 1865,\n",
       " 'jilted': 2355,\n",
       " 'wedding': 4790,\n",
       " 'fate': 1621,\n",
       " 'loose': 2607,\n",
       " 'done': 1283,\n",
       " 'unsympathetic': 4631,\n",
       " 'unlike': 4612,\n",
       " 'gail': 1818,\n",
       " 'patrick': 3193,\n",
       " 'consequently': 903,\n",
       " 'expecting': 1534,\n",
       " 'perhaps': 3232,\n",
       " 'context': 923,\n",
       " 'happy': 2010,\n",
       " 'essentially': 1479,\n",
       " 'wiped': 4848,\n",
       " 'undermines': 4576,\n",
       " 'effect': 1377,\n",
       " 'kept': 2404,\n",
       " 'waiting': 4735,\n",
       " 'something': 4039,\n",
       " 'happen': 2004,\n",
       " 'witty': 4860,\n",
       " 'dialog': 1194,\n",
       " 'characteristic': 708,\n",
       " 'movies': 2889,\n",
       " 'era': 1470,\n",
       " 'delivered': 1137,\n",
       " 'slightly': 3998,\n",
       " 'drifter': 1318,\n",
       " 'mistaken': 2825,\n",
       " 'hit': 2097,\n",
       " 'man': 2676,\n",
       " 'small': 4006,\n",
       " 'wyoming': 4910,\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we need to call \"transform()\" to get a term-document matrix. Try it out and find out what it produces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Column sparse matrix of dtype 'int64'\n",
      "\twith 14095 stored elements and shape (4946, 100)>\n",
      "  Coords\tValues\n",
      "  (97, 0)\t1\n",
      "  (173, 0)\t1\n",
      "  (180, 0)\t1\n",
      "  (197, 0)\t2\n",
      "  (350, 0)\t1\n",
      "  (538, 0)\t6\n",
      "  (707, 0)\t1\n",
      "  (973, 0)\t1\n",
      "  (1198, 0)\t1\n",
      "  (1498, 0)\t1\n",
      "  (1807, 0)\t1\n",
      "  (1939, 0)\t2\n",
      "  (2050, 0)\t1\n",
      "  (2060, 0)\t1\n",
      "  (2207, 0)\t1\n",
      "  (2325, 0)\t2\n",
      "  (2359, 0)\t1\n",
      "  (2370, 0)\t1\n",
      "  (2490, 0)\t1\n",
      "  (2888, 0)\t2\n",
      "  (3285, 0)\t1\n",
      "  (3535, 0)\t3\n",
      "  (3828, 0)\t1\n",
      "  (3910, 0)\t2\n",
      "  (3930, 0)\t1\n",
      "  :\t:\n",
      "  (3749, 99)\t1\n",
      "  (3895, 99)\t1\n",
      "  (3933, 99)\t4\n",
      "  (3938, 99)\t2\n",
      "  (3949, 99)\t1\n",
      "  (3958, 99)\t2\n",
      "  (3962, 99)\t1\n",
      "  (3965, 99)\t1\n",
      "  (4045, 99)\t1\n",
      "  (4071, 99)\t1\n",
      "  (4153, 99)\t1\n",
      "  (4379, 99)\t7\n",
      "  (4380, 99)\t15\n",
      "  (4385, 99)\t1\n",
      "  (4400, 99)\t2\n",
      "  (4404, 99)\t3\n",
      "  (4407, 99)\t1\n",
      "  (4432, 99)\t1\n",
      "  (4593, 99)\t1\n",
      "  (4693, 99)\t4\n",
      "  (4765, 99)\t2\n",
      "  (4804, 99)\t1\n",
      "  (4853, 99)\t1\n",
      "  (4889, 99)\t1\n",
      "  (4924, 99)\t1\n",
      "(4946, 100)\n"
     ]
    }
   ],
   "source": [
    "term_doc_mat = vectorizer.transform(input_text).T  # transpose so that rows are terms\n",
    "print(term_doc_mat)\n",
    "print(term_doc_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DO 8:** Use the term-document matrix above to write a function that returns a term vector. Get the term vector for the word 'happy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# WRITE YOUR ANSWER HERE\n",
    "def get_term_vector(vectorizer, term_doc_mat, word):\n",
    "    index = vectorizer.vocabulary_[word]\n",
    "    term_vec = term_doc_mat[index].toarray()\n",
    "    \n",
    "    return term_vec.flatten()\n",
    "\n",
    "vector = get_term_vector(vectorizer, term_doc_mat, 'happy')\n",
    "print(vector.shape)\n",
    "print(vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DO 9:** What do the values in the vector mean? This representation is known as a 'bag of words' because it ignores the word order and document structure. Can you think of any disadvantages of representing documents as bags of words? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER = these are the number of times the chosen word (or other token type, such as punctuation mark or number) occured in each document in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Comparing Vectors with Cosine Similarity\n",
    "\n",
    "Vectors representations allow us to compare documents or terms by computing their similarity. This is useful for tasks such as clustering documents into topics, or finding documents that are similar to a 'query' document. \n",
    "In order to compute similarity or distance, we need to represent documents as numerical vectors. \n",
    "\n",
    "The most common way to compare vectors is to compute the cosine of the angles between them. This measures how much the vectors point in the same direction. It ignores their magnitude, which means that shorter documents with lower word counts can be directly compared to long documents with more words. \n",
    "\n",
    "Let's take a term from the IMDB dataset as a 'query' and compare it to two others using cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our first document\n",
    "query_vec = get_term_vector(vectorizer, term_doc_mat, 'happy')\n",
    "\n",
    "# get the second term\n",
    "term2_vec = get_term_vector(vectorizer, term_doc_mat, 'sad')\n",
    "\n",
    "# get a third term\n",
    "term3_vec = get_term_vector(vectorizer, term_doc_mat, 'enjoy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity is defined as:\n",
    "\n",
    "$$similarity<v_1, v_2> = \\frac{v_1 \\cdot v_2}{|| v_1 || \\cdot || v_2 ||}$$\n",
    "\n",
    "**TO-DO 9:** Complete the function below to computes cosine similarity between two vectors. Hint: use Numpy's dot function for the dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(vec1, vec2):   \n",
    "    ### WRITE YOUR OWN CODE HERE\n",
    "    dot_prod = np.dot(vec1, vec2)\n",
    "    normaliser = np.sum(vec1**2)**0.5 * np.sum(vec2**2)**0.5\n",
    "    return dot_prod / normaliser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DO 10:** Which term do you expect to have higher similarity to the query? Run the code below to use your cosine similarity function, and see if the results meet your expectations.\n",
    "\n",
    "ANSWER: -- The 'enjoy' should be more similar to 'happy' than 'sad'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the query and term2 is: 0.0\n",
      "The cosine similarity between the query and term3 is: 0.3651483716701107\n"
     ]
    }
   ],
   "source": [
    "cos_sim1 = cossim(query_vec, term2_vec)\n",
    "print(f'The cosine similarity between the query and term2 is: {cos_sim1}')\n",
    "\n",
    "cos_sim2 = cossim(query_vec, term3_vec)\n",
    "print(f'The cosine similarity between the query and term3 is: {cos_sim2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Bags of N-grams\n",
    "\n",
    "Our representations above were purely bag-of-words representations: they ignored word order and simply counted single tokens, or 'unigrams'. However, word order is important for understanding the meaning of a piece of text. What if we expand our bags of words to also count other _features_ that help us account for word order? Features are any attributes of the text that we can measure; a simple improvement is to count pairs of consecutive tokens, or _bigrams_, to capture phrases as well as individual words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thought': 19368,\n",
       " 'this': 19196,\n",
       " 'movie': 12080,\n",
       " 'was': 20830,\n",
       " 'really': 15090,\n",
       " 'great': 7778,\n",
       " 'helena': 8321,\n",
       " 'did': 5044,\n",
       " 'an': 785,\n",
       " 'amazing': 725,\n",
       " 'job': 10124,\n",
       " 'in': 9049,\n",
       " 'it': 9821,\n",
       " 'she': 16276,\n",
       " 'played': 14298,\n",
       " 'her': 8348,\n",
       " 'character': 3665,\n",
       " 'very': 20596,\n",
       " 'well': 21127,\n",
       " 'awesome': 2033,\n",
       " 'actress': 344,\n",
       " 'br': 2854,\n",
       " 'the': 18080,\n",
       " 'also': 667,\n",
       " 'funny': 7299,\n",
       " 'too': 19853,\n",
       " 'jokes': 10165,\n",
       " 'were': 21164,\n",
       " 'couldnt': 4436,\n",
       " 'stop': 17197,\n",
       " 'laughing': 10566,\n",
       " 'think': 19168,\n",
       " 'everyone': 6110,\n",
       " 'should': 16365,\n",
       " 'see': 15988,\n",
       " 'thought this': 19380,\n",
       " 'this movie': 19262,\n",
       " 'movie was': 12173,\n",
       " 'was really': 20921,\n",
       " 'really really': 15113,\n",
       " 'really great': 15101,\n",
       " 'great helena': 7800,\n",
       " 'helena did': 8322,\n",
       " 'did an': 5045,\n",
       " 'an amazing': 794,\n",
       " 'amazing job': 730,\n",
       " 'job in': 10128,\n",
       " 'in it': 9128,\n",
       " 'it thought': 9968,\n",
       " 'thought she': 19376,\n",
       " 'she played': 16293,\n",
       " 'played her': 14301,\n",
       " 'her character': 8360,\n",
       " 'character very': 3681,\n",
       " 'very well': 20633,\n",
       " 'well she': 21149,\n",
       " 'she an': 16278,\n",
       " 'an awesome': 806,\n",
       " 'awesome actress': 2034,\n",
       " 'actress br': 345,\n",
       " 'br br': 2872,\n",
       " 'br the': 2930,\n",
       " 'the movie': 18549,\n",
       " 'was also': 20835,\n",
       " 'also really': 683,\n",
       " 'really funny': 15098,\n",
       " 'funny too': 7311,\n",
       " 'too the': 19886,\n",
       " 'the jokes': 18457,\n",
       " 'jokes were': 10168,\n",
       " 'were great': 21180,\n",
       " 'great couldnt': 7791,\n",
       " 'couldnt stop': 4437,\n",
       " 'stop laughing': 17199,\n",
       " 'laughing br': 10567,\n",
       " 'br think': 2933,\n",
       " 'think everyone': 19173,\n",
       " 'everyone should': 6114,\n",
       " 'should see': 16374,\n",
       " 'see it': 15999,\n",
       " 'it br': 9848,\n",
       " 'dynasty': 5620,\n",
       " 'revisited': 15435,\n",
       " 'hawaii': 8182,\n",
       " 'full': 7285,\n",
       " 'of': 12943,\n",
       " 'clichs': 3923,\n",
       " 'highly': 8471,\n",
       " 'predictable': 14553,\n",
       " 'unrealistic': 20351,\n",
       " 'and': 855,\n",
       " 'sometimes': 16848,\n",
       " 'even': 6026,\n",
       " 'stupid': 17373,\n",
       " 'if': 8946,\n",
       " 'you': 22044,\n",
       " 'have': 8117,\n",
       " 'nothing': 12800,\n",
       " 'better': 2568,\n",
       " 'to': 19549,\n",
       " 'do': 5275,\n",
       " 'however': 8829,\n",
       " 'does': 5322,\n",
       " 'provide': 14774,\n",
       " '40': 103,\n",
       " 'minutes': 11812,\n",
       " 'simple': 16502,\n",
       " 'unpretensive': 20345,\n",
       " 'entertainment': 5923,\n",
       " 'endless': 5838,\n",
       " 'looks': 11073,\n",
       " 'at': 1865,\n",
       " 'male': 11347,\n",
       " 'female': 6541,\n",
       " 'muscles': 12287,\n",
       " 'good': 7649,\n",
       " 'photography': 14195,\n",
       " 'spectacular': 16957,\n",
       " 'hawaiian': 8184,\n",
       " 'scenery': 15842,\n",
       " 'on': 13322,\n",
       " 'other': 13656,\n",
       " 'hand': 7988,\n",
       " 'are': 1536,\n",
       " 'looking': 11066,\n",
       " 'for': 6970,\n",
       " 'anything': 1438,\n",
       " 'more': 11947,\n",
       " 'than': 17862,\n",
       " 'that': 17897,\n",
       " 'stay': 17112,\n",
       " 'away': 2014,\n",
       " 'oh': 13284,\n",
       " 'by': 3259,\n",
       " 'way': 21018,\n",
       " 'ever': 6074,\n",
       " 'worked': 21846,\n",
       " 'hotel': 8766,\n",
       " 'or': 13539,\n",
       " 'know': 10414,\n",
       " 'about': 153,\n",
       " 'running': 15661,\n",
       " 'one': 13393,\n",
       " 'two': 20152,\n",
       " 'options': 13537,\n",
       " 'will': 21536,\n",
       " 'feel': 6515,\n",
       " 'sick': 16452,\n",
       " 'every': 6091,\n",
       " 'sheer': 16303,\n",
       " 'stupidity': 17379,\n",
       " 'silliness': 16477,\n",
       " 'how': 8801,\n",
       " 'show': 16382,\n",
       " 'presents': 14594,\n",
       " 'business': 3155,\n",
       " 'look': 11047,\n",
       " 'as': 1687,\n",
       " 'science': 15886,\n",
       " 'fiction': 6585,\n",
       " 'comedy': 4046,\n",
       " 'lie': 10766,\n",
       " 'back': 2058,\n",
       " 'relax': 15249,\n",
       " 'laugh': 10552,\n",
       " 'dynasty revisited': 5621,\n",
       " 'revisited in': 15436,\n",
       " 'in hawaii': 9116,\n",
       " 'hawaii full': 8183,\n",
       " 'full of': 7286,\n",
       " 'of clichs': 12993,\n",
       " 'clichs highly': 3925,\n",
       " 'highly predictable': 8473,\n",
       " 'predictable unrealistic': 14558,\n",
       " 'unrealistic and': 20352,\n",
       " 'and sometimes': 1194,\n",
       " 'sometimes even': 16850,\n",
       " 'even stupid': 6052,\n",
       " 'stupid if': 17376,\n",
       " 'if you': 8971,\n",
       " 'you have': 22068,\n",
       " 'have nothing': 8150,\n",
       " 'nothing better': 12803,\n",
       " 'better to': 2580,\n",
       " 'to do': 19616,\n",
       " 'do however': 5283,\n",
       " 'however it': 8839,\n",
       " 'it does': 9866,\n",
       " 'does provide': 5339,\n",
       " 'provide 40': 14775,\n",
       " '40 minutes': 104,\n",
       " 'minutes of': 11816,\n",
       " 'of simple': 13169,\n",
       " 'simple unpretensive': 16508,\n",
       " 'unpretensive entertainment': 20346,\n",
       " 'entertainment endless': 5925,\n",
       " 'endless looks': 5840,\n",
       " 'looks at': 11075,\n",
       " 'at great': 1880,\n",
       " 'great male': 7802,\n",
       " 'male and': 11348,\n",
       " 'and female': 982,\n",
       " 'female muscles': 6543,\n",
       " 'muscles and': 12288,\n",
       " 'and very': 1264,\n",
       " 'very good': 20609,\n",
       " 'good photography': 7682,\n",
       " 'photography of': 14198,\n",
       " 'of the': 13194,\n",
       " 'the spectacular': 18756,\n",
       " 'spectacular hawaiian': 16958,\n",
       " 'hawaiian scenery': 8185,\n",
       " 'scenery on': 15844,\n",
       " 'on the': 13370,\n",
       " 'the other': 18593,\n",
       " 'other hand': 13667,\n",
       " 'hand if': 7989,\n",
       " 'you are': 22048,\n",
       " 'are looking': 1585,\n",
       " 'looking for': 11070,\n",
       " 'for anything': 6977,\n",
       " 'anything more': 1447,\n",
       " 'more than': 11982,\n",
       " 'than that': 17882,\n",
       " 'that stay': 18038,\n",
       " 'stay away': 17114,\n",
       " 'away br': 2018,\n",
       " 'br oh': 2915,\n",
       " 'oh and': 13285,\n",
       " 'and by': 898,\n",
       " 'by the': 3328,\n",
       " 'the way': 18859,\n",
       " 'way if': 21028,\n",
       " 'have ever': 8134,\n",
       " 'ever worked': 6090,\n",
       " 'worked in': 21848,\n",
       " 'in hotel': 9124,\n",
       " 'hotel or': 8770,\n",
       " 'or know': 13583,\n",
       " 'know anything': 10416,\n",
       " 'anything about': 1439,\n",
       " 'about running': 191,\n",
       " 'running one': 15663,\n",
       " 'one you': 13458,\n",
       " 'have two': 8170,\n",
       " 'two options': 20166,\n",
       " 'options you': 13538,\n",
       " 'you will': 22101,\n",
       " 'will feel': 21546,\n",
       " 'feel sick': 6524,\n",
       " 'sick every': 16454,\n",
       " 'every two': 6102,\n",
       " 'two minutes': 20163,\n",
       " 'minutes at': 11813,\n",
       " 'at the': 1898,\n",
       " 'the sheer': 18730,\n",
       " 'sheer stupidity': 16304,\n",
       " 'stupidity and': 17380,\n",
       " 'and silliness': 1182,\n",
       " 'silliness of': 16478,\n",
       " 'of how': 13067,\n",
       " 'how the': 8822,\n",
       " 'the show': 18734,\n",
       " 'show presents': 16398,\n",
       " 'presents hotel': 14596,\n",
       " 'hotel business': 8768,\n",
       " 'business or': 3159,\n",
       " 'or look': 13588,\n",
       " 'look at': 11048,\n",
       " 'at it': 1884,\n",
       " 'it as': 9840,\n",
       " 'as science': 1770,\n",
       " 'science fiction': 15887,\n",
       " 'fiction comedy': 6587,\n",
       " 'comedy as': 4048,\n",
       " 'as did': 1710,\n",
       " 'did lie': 5053,\n",
       " 'lie back': 10768,\n",
       " 'back relax': 2067,\n",
       " 'relax and': 15250,\n",
       " 'and laugh': 1067,\n",
       " 'laugh about': 10553,\n",
       " 'about it': 175,\n",
       " 'entire': 5931,\n",
       " 'weissmuller': 21124,\n",
       " 'tarzan': 17735,\n",
       " 'series': 16157,\n",
       " 'dvd': 5603,\n",
       " 'fully': 7287,\n",
       " 'restored': 15381,\n",
       " 'editions': 5662,\n",
       " 'never': 12490,\n",
       " 'tire': 19531,\n",
       " 'watching': 21004,\n",
       " 'them': 18937,\n",
       " 'my': 12321,\n",
       " 'personal': 14154,\n",
       " 'favorite': 6491,\n",
       " 'is': 9545,\n",
       " 'his': 8532,\n",
       " 'mate': 11494,\n",
       " 'due': 5568,\n",
       " 'entirely': 5940,\n",
       " 'almost': 635,\n",
       " 'maureen': 11515,\n",
       " 'sullivan': 17485,\n",
       " 'costume': 4410,\n",
       " 'occasional': 12919,\n",
       " 'flashes': 6868,\n",
       " 'genital': 7431,\n",
       " 'area': 1630,\n",
       " 'beneath': 2524,\n",
       " 'leather': 10657,\n",
       " 'flap': 6860,\n",
       " 'hanging': 8008,\n",
       " 'front': 7274,\n",
       " 'before': 2428,\n",
       " 'anyone': 1429,\n",
       " 'claims': 3872,\n",
       " 'wasn': 20960,\n",
       " 'what': 21226,\n",
       " 'like': 10806,\n",
       " 'let': 10731,\n",
       " 'me': 11549,\n",
       " 'say': 15781,\n",
       " 'watched': 20997,\n",
       " 'numerous': 12877,\n",
       " 'time': 19468,\n",
       " 'high': 8459,\n",
       " 'zoom': 22180,\n",
       " 'mode': 11876,\n",
       " 'trust': 20091,\n",
       " 'completely': 4141,\n",
       " 'naked': 12385,\n",
       " 'underneath': 20242,\n",
       " 'several': 16193,\n",
       " 'times': 19500,\n",
       " 'especially': 5990,\n",
       " 'during': 5591,\n",
       " 'lion': 10891,\n",
       " 'attack': 1916,\n",
       " 'end': 5806,\n",
       " 'careful': 3501,\n",
       " 'viewing': 20689,\n",
       " 'slow': 16623,\n",
       " 'motion': 12036,\n",
       " 'maximum': 11517,\n",
       " 'reveal': 15407,\n",
       " 'shaved': 16270,\n",
       " 'except': 6164,\n",
       " 'tiny': 19525,\n",
       " 'patch': 13973,\n",
       " 'dark': 4722,\n",
       " 'hair': 7965,\n",
       " 'covering': 4494,\n",
       " 'labia': 10467,\n",
       " 'there': 19017,\n",
       " 'no': 12616,\n",
       " 'mistake': 11854,\n",
       " 'all': 561,\n",
       " 'swimming': 17627,\n",
       " 'scene': 15823,\n",
       " 'being': 2471,\n",
       " 'body': 2744,\n",
       " 'double': 5436,\n",
       " 'skin': 16585,\n",
       " 'suit': 17472,\n",
       " 'yes': 22014,\n",
       " 'but': 3163,\n",
       " 'not': 12705,\n",
       " 'wearing': 21100,\n",
       " 'any': 1391,\n",
       " 'else': 5752,\n",
       " 'again': 473,\n",
       " 'shows': 16423,\n",
       " 'everything': 6116,\n",
       " 'those': 19329,\n",
       " 'who': 21420,\n",
       " 'want': 20794,\n",
       " 'now': 12833,\n",
       " 'controversy': 4334,\n",
       " 'out': 13717,\n",
       " 'move': 12061,\n",
       " 'actual': 349,\n",
       " 'script': 15935,\n",
       " 'written': 21965,\n",
       " 'tightly': 19460,\n",
       " 'action': 307,\n",
       " 'sequences': 16140,\n",
       " 'simply': 16511,\n",
       " 'although': 696,\n",
       " 'obviously': 12911,\n",
       " 'stuntman': 17368,\n",
       " 'riding': 15475,\n",
       " 'rhino': 15447,\n",
       " 'actually': 353,\n",
       " 'wrestles': 21942,\n",
       " 'big': 2610,\n",
       " 'use': 20474,\n",
       " 'background': 2078,\n",
       " 'shots': 16360,\n",
       " 'second': 15966,\n",
       " 'unit': 20310,\n",
       " 'stuff': 17361,\n",
       " 'from': 7217,\n",
       " 'africa': 439,\n",
       " 'blended': 2695,\n",
       " 'with': 21617,\n",
       " 'studio': 17358,\n",
       " 'us': 20459,\n",
       " 'locations': 11001,\n",
       " 'making': 11339,\n",
       " 'hard': 8044,\n",
       " 'tell': 17798,\n",
       " 'which': 21335,\n",
       " 'don': 5374,\n",
       " 'complain': 4123,\n",
       " 'much': 12220,\n",
       " 'though': 19352,\n",
       " 'remember': 15281,\n",
       " '90': 135,\n",
       " 'films': 6723,\n",
       " 'phony': 14193,\n",
       " 'anyway': 1456,\n",
       " 'so': 16686,\n",
       " 'just': 10199,\n",
       " 'enjoy': 5876,\n",
       " 'damned': 4676,\n",
       " 'thing': 19137,\n",
       " 'bowl': 2837,\n",
       " 'popcorn': 14460,\n",
       " 'some': 16779,\n",
       " 'cold': 3988,\n",
       " 'beer': 2424,\n",
       " 'fresh': 7182,\n",
       " 'pack': 13841,\n",
       " 'smokes': 16663,\n",
       " 'sexy': 16225,\n",
       " 'willing': 21571,\n",
       " 'girlfriend': 7524,\n",
       " 'wife': 21510,\n",
       " 'isn': 9806,\n",
       " 'line': 10882,\n",
       " 'either': 5707,\n",
       " 'lol': 11006,\n",
       " 'final': 6744,\n",
       " 'word': 21810,\n",
       " 'nudity': 12862,\n",
       " 'beginning': 2454,\n",
       " 'while': 21386,\n",
       " 'white': 21411,\n",
       " 'hunters': 8895,\n",
       " 'speaking': 16941,\n",
       " 'dialogue': 5032,\n",
       " 'keep': 10275,\n",
       " 'your': 22118,\n",
       " 'eyes': 6287,\n",
       " 'extras': 6269,\n",
       " 'nude': 12860,\n",
       " 'african': 441,\n",
       " 'girls': 7526,\n",
       " 'shot': 16349,\n",
       " 'location': 10999,\n",
       " 'behind': 2468,\n",
       " 'racist': 14922,\n",
       " 'standards': 17043,\n",
       " '1930': 34,\n",
       " 'until': 20375,\n",
       " '1960': 48,\n",
       " 'colored': 4020,\n",
       " 'people': 14041,\n",
       " 'portrayed': 14476,\n",
       " 'then': 18980,\n",
       " 'shaft': 16232,\n",
       " 'hadn': 7958,\n",
       " 'been': 2391,\n",
       " 'nor': 12687,\n",
       " 'would': 21905,\n",
       " 'audiences': 1959,\n",
       " 'accepted': 244,\n",
       " 'portrayals': 14474,\n",
       " 'history': 8650,\n",
       " 'safaris': 15695,\n",
       " 'natives': 12426,\n",
       " 'carrying': 3520,\n",
       " 'luggage': 11193,\n",
       " 'their': 18900,\n",
       " 'heads': 8274,\n",
       " 'die': 5083,\n",
       " 'heroic': 8440,\n",
       " 'death': 4806,\n",
       " 'trying': 20103,\n",
       " 'save': 15770,\n",
       " 'jane': 10058,\n",
       " 'matter': 11505,\n",
       " 'fact': 6310,\n",
       " 'gene': 7409,\n",
       " 'autry': 1988,\n",
       " 'treated': 20019,\n",
       " 'native': 12423,\n",
       " 'americans': 766,\n",
       " 'westerns': 21224,\n",
       " 'real': 15040,\n",
       " 'human': 8863,\n",
       " 'beings': 2500,\n",
       " 'hollywood': 8680,\n",
       " 'began': 2446,\n",
       " 'okay': 13291,\n",
       " 'have the': 8168,\n",
       " 'the entire': 18319,\n",
       " 'entire weissmuller': 5939,\n",
       " 'weissmuller tarzan': 21126,\n",
       " 'tarzan series': 17737,\n",
       " 'series on': 16162,\n",
       " 'on dvd': 13337,\n",
       " 'dvd fully': 5606,\n",
       " 'fully restored': 7290,\n",
       " 'restored editions': 15382,\n",
       " 'editions never': 5663,\n",
       " 'never tire': 12518,\n",
       " 'tire of': 19532,\n",
       " 'of watching': 13226,\n",
       " 'watching them': 21010,\n",
       " 'them my': 18954,\n",
       " 'my personal': 12348,\n",
       " 'personal favorite': 14155,\n",
       " 'favorite is': 6494,\n",
       " 'is tarzan': 9764,\n",
       " 'tarzan and': 17736,\n",
       " 'and his': 1026,\n",
       " 'his mate': 8594,\n",
       " 'mate due': 11495,\n",
       " 'due entirely': 5569,\n",
       " 'entirely well': 5945,\n",
       " 'well almost': 21129,\n",
       " 'almost entirely': 639,\n",
       " 'entirely to': 5944,\n",
       " 'to maureen': 19694,\n",
       " 'maureen sullivan': 11516,\n",
       " 'sullivan costume': 17487,\n",
       " 'costume and': 4411,\n",
       " 'and the': 1225,\n",
       " 'the occasional': 18581,\n",
       " 'occasional flashes': 12920,\n",
       " 'flashes of': 6869,\n",
       " 'of her': 13060,\n",
       " 'her genital': 8375,\n",
       " 'genital area': 7432,\n",
       " 'area beneath': 1631,\n",
       " 'beneath that': 2525,\n",
       " 'that leather': 17985,\n",
       " 'leather flap': 10658,\n",
       " 'flap hanging': 6861,\n",
       " 'hanging in': 8009,\n",
       " 'in front': 9104,\n",
       " 'front before': 7275,\n",
       " 'before anyone': 2430,\n",
       " 'anyone claims': 1432,\n",
       " 'claims that': 3873,\n",
       " 'that it': 17977,\n",
       " 'it wasn': 9980,\n",
       " 'wasn really': 20968,\n",
       " 'really her': 15105,\n",
       " 'her or': 8394,\n",
       " 'or it': 13582,\n",
       " 'really what': 15121,\n",
       " 'what it': 21248,\n",
       " 'it looks': 9907,\n",
       " 'looks like': 11080,\n",
       " 'like let': 10830,\n",
       " 'let me': 10734,\n",
       " 'me say': 11578,\n",
       " 'say that': 15793,\n",
       " 'that have': 17964,\n",
       " 'have watched': 8172,\n",
       " 'watched it': 20999,\n",
       " 'it numerous': 9922,\n",
       " 'numerous time': 12878,\n",
       " 'time in': 19483,\n",
       " 'in high': 9119,\n",
       " 'high zoom': 8464,\n",
       " 'zoom mode': 22181,\n",
       " 'mode and': 11877,\n",
       " 'and trust': 1248,\n",
       " 'trust me': 20092,\n",
       " 'me it': 11567,\n",
       " 'it is': 9897,\n",
       " 'is her': 9647,\n",
       " 'her and': 8353,\n",
       " 'and she': 1179,\n",
       " 'she is': 16286,\n",
       " 'is completely': 9597,\n",
       " 'completely naked': 4144,\n",
       " 'naked underneath': 12386,\n",
       " 'underneath that': 20243,\n",
       " 'that costume': 17931,\n",
       " 'costume several': 4413,\n",
       " 'several times': 16202,\n",
       " 'times especially': 19507,\n",
       " 'especially during': 5991,\n",
       " 'during the': 5597,\n",
       " 'the lion': 18491,\n",
       " 'lion attack': 10892,\n",
       " 'attack at': 1917,\n",
       " 'the end': 18313,\n",
       " 'end careful': 5808,\n",
       " 'careful viewing': 3503,\n",
       " 'viewing in': 20692,\n",
       " 'in slow': 9193,\n",
       " 'slow motion': 16627,\n",
       " 'motion and': 12037,\n",
       " 'and maximum': 1082,\n",
       " 'maximum zoom': 11518,\n",
       " 'zoom will': 22183,\n",
       " 'will reveal': 21559,\n",
       " 'reveal that': 15408,\n",
       " 'that she': 18029,\n",
       " 'she was': 16300,\n",
       " 'was shaved': 20929,\n",
       " 'shaved except': 16271,\n",
       " 'except for': 6167,\n",
       " 'for tiny': 7046,\n",
       " 'tiny patch': 19528,\n",
       " 'patch of': 13974,\n",
       " 'of dark': 13011,\n",
       " 'dark hair': 4726,\n",
       " 'hair covering': 7967,\n",
       " 'covering her': 4495,\n",
       " 'her labia': 8383,\n",
       " 'labia there': 10468,\n",
       " 'there is': 19027,\n",
       " 'is no': 9681,\n",
       " 'no mistake': 12634,\n",
       " 'mistake about': 11855,\n",
       " 'about that': 194,\n",
       " 'that at': 17910,\n",
       " 'at all': 1867,\n",
       " 'all as': 567,\n",
       " 'as to': 1789,\n",
       " 'to the': 19779,\n",
       " 'the swimming': 18786,\n",
       " 'swimming scene': 17629,\n",
       " 'scene being': 15828,\n",
       " 'being body': 2474,\n",
       " 'body double': 2745,\n",
       " 'double in': 5438,\n",
       " 'in skin': 9191,\n",
       " 'skin suit': 16586,\n",
       " 'suit yes': 17477,\n",
       " 'yes it': 22017,\n",
       " 'is double': 9613,\n",
       " 'double but': 5437,\n",
       " 'but she': 3228,\n",
       " 'is not': 9682,\n",
       " 'not wearing': 12785,\n",
       " 'wearing any': 21101,\n",
       " 'any skin': 1420,\n",
       " 'suit or': 17475,\n",
       " 'or anything': 13542,\n",
       " 'anything else': 1443,\n",
       " 'else again': 5753,\n",
       " 'again slow': 483,\n",
       " 'zoom shows': 22182,\n",
       " 'shows everything': 16426,\n",
       " 'everything to': 6119,\n",
       " 'to those': 19784,\n",
       " 'those who': 19350,\n",
       " 'who want': 21474,\n",
       " 'want to': 20797,\n",
       " 'to see': 19754,\n",
       " 'it now': 9921,\n",
       " 'now that': 12847,\n",
       " 'that controversy': 17929,\n",
       " 'controversy out': 4335,\n",
       " 'out of': 13736,\n",
       " 'way let': 21032,\n",
       " 'let move': 10735,\n",
       " 'move on': 12065,\n",
       " 'the actual': 18107,\n",
       " 'actual movie': 351,\n",
       " 'movie thought': 12166,\n",
       " 'thought the': 19378,\n",
       " 'the script': 18715,\n",
       " 'script was': 15942,\n",
       " 'really well': 15120,\n",
       " 'well thought': 21155,\n",
       " 'thought out': 19375,\n",
       " 'out and': 13720,\n",
       " 'and written': 1294,\n",
       " 'written tightly': 21969,\n",
       " 'tightly the': 19461,\n",
       " 'the action': 18104,\n",
       " 'action sequences': 315,\n",
       " 'sequences were': 16143,\n",
       " 'were simply': 21200,\n",
       " 'simply great': 16516,\n",
       " 'great although': 7782,\n",
       " 'although it': 698,\n",
       " 'is obviously': 9686,\n",
       " 'obviously stuntman': 12918,\n",
       " 'stuntman riding': 17369,\n",
       " 'riding the': 15476,\n",
       " 'the rhino': 18691,\n",
       " 'rhino weissmuller': 15448,\n",
       " 'weissmuller actually': 21125,\n",
       " 'actually wrestles': 366,\n",
       " 'wrestles the': 21943,\n",
       " 'the big': 18177,\n",
       " 'big male': 2623,\n",
       " 'male lion': 11349,\n",
       " 'lion the': 10894,\n",
       " 'the use': 18838,\n",
       " 'use of': 20479,\n",
       " 'of background': 12967,\n",
       " 'background shots': 2084,\n",
       " 'shots that': 16364,\n",
       " 'that were': 18068,\n",
       " 'were second': 21199,\n",
       " 'second unit': 15972,\n",
       " 'unit stuff': 20311,\n",
       " 'stuff from': 17363,\n",
       " 'from africa': 7219,\n",
       " 'africa is': 440,\n",
       " 'is very': 9783,\n",
       " 'well blended': 21133,\n",
       " 'blended with': 2696,\n",
       " 'with the': 21697,\n",
       " 'the studio': 18774,\n",
       " 'studio us': 17360,\n",
       " 'us locations': 20465,\n",
       " 'locations making': 11002,\n",
       " 'making it': 11341,\n",
       " 'it sometimes': 9957,\n",
       " 'sometimes hard': 16851,\n",
       " 'hard to': 8047,\n",
       " 'to tell': 19777,\n",
       " 'tell which': 17801,\n",
       " 'which is': 21354,\n",
       " 'is which': 9789,\n",
       " 'which don': 21347,\n",
       " 'don complain': 5379,\n",
       " 'complain too': 4125,\n",
       " 'too much': 19877,\n",
       " 'much though': 12247,\n",
       " 'though remember': 19361,\n",
       " 'remember that': 15286,\n",
       " 'that 90': 17899,\n",
       " '90 of': 136,\n",
       " 'of all': 12952,\n",
       " 'all films': 586,\n",
       " 'films is': 6734,\n",
       " 'is phony': 9700,\n",
       " 'phony anyway': 14194,\n",
       " 'anyway so': 1459,\n",
       " 'so just': 16717,\n",
       " 'just relax': 10240,\n",
       " 'and enjoy': 969,\n",
       " 'enjoy the': 5880,\n",
       " 'the damned': 18263,\n",
       " 'damned thing': 4677,\n",
       " 'thing with': 19153,\n",
       " 'with big': 21627,\n",
       " 'big bowl': 2612,\n",
       " 'bowl of': 2839,\n",
       " 'of popcorn': 13140,\n",
       " 'popcorn some': 14461,\n",
       " 'some cold': 16784,\n",
       " 'cold beer': 3989,\n",
       " 'beer and': 2425,\n",
       " 'and fresh': 993,\n",
       " 'fresh pack': 7185,\n",
       " 'pack of': 13842,\n",
       " 'of smokes': 13172,\n",
       " 'smokes sexy': 16664,\n",
       " 'sexy and': 16226,\n",
       " 'and willing': 1287,\n",
       " 'willing girlfriend': 21572,\n",
       " 'girlfriend wife': 7525,\n",
       " 'wife isn': 21515,\n",
       " 'isn out': 9812,\n",
       " 'of line': 13089,\n",
       " 'line either': 10884,\n",
       " 'either lol': 5710,\n",
       " 'lol oh': 11008,\n",
       " 'oh one': 13287,\n",
       " 'one final': 13410,\n",
       " 'final word': 6746,\n",
       " 'word about': 21811,\n",
       " 'about nudity': 182,\n",
       " 'nudity at': 12863,\n",
       " 'the very': 18845,\n",
       " 'very beginning': 20597,\n",
       " 'beginning while': 2459,\n",
       " 'while the': 21403,\n",
       " 'the white': 18865,\n",
       " 'white hunters': 21415,\n",
       " 'hunters are': 8897,\n",
       " 'are speaking': 1613,\n",
       " 'speaking dialogue': 16942,\n",
       " 'dialogue keep': 5037,\n",
       " 'keep your': 10282,\n",
       " 'your eyes': 22123,\n",
       " 'eyes on': 6292,\n",
       " 'the background': 18159,\n",
       " 'background extras': 2081,\n",
       " 'extras there': 6271,\n",
       " 'there are': 19020,\n",
       " 'are several': 1608,\n",
       " 'several good': 16196,\n",
       " 'good shots': 7685,\n",
       " 'shots of': 16363,\n",
       " 'of nude': 13120,\n",
       " 'nude african': 12861,\n",
       " 'african girls': 442,\n",
       " 'girls obviously': 7532,\n",
       " 'obviously shot': 12917,\n",
       " 'shot on': 16354,\n",
       " 'on location': 13354,\n",
       " 'location behind': 11000,\n",
       " 'behind them': 2470,\n",
       " 'them one': 18956,\n",
       " 'one more': 13427,\n",
       " 'more thing': 11984,\n",
       " 'thing the': 19148,\n",
       " 'movie is': 12120,\n",
       " 'not racist': 12764,\n",
       " 'racist by': 14924,\n",
       " 'the standards': 18762,\n",
       " 'standards of': 17045,\n",
       " 'the 1930': 18082,\n",
       " '1930 until': 37,\n",
       " 'until the': 20382,\n",
       " 'the 1960': 18083,\n",
       " '1960 that': 50,\n",
       " 'that the': 18046,\n",
       " 'way colored': 21022,\n",
       " 'colored people': 4021,\n",
       " 'people were': 14067,\n",
       " 'were thought': 21208,\n",
       " 'thought of': 19374,\n",
       " 'of and': 12959,\n",
       " 'and portrayed': 1131,\n",
       " 'portrayed back': 14477,\n",
       " 'back then': 2070,\n",
       " 'then shaft': 19002,\n",
       " 'shaft hadn': 16233,\n",
       " 'hadn even': 7960,\n",
       " 'even been': 6030,\n",
       " 'been thought': 2418,\n",
       " 'thought about': 19369,\n",
       " 'about at': 155,\n",
       " 'at that': 1897,\n",
       " 'that time': 18053,\n",
       " 'time nor': 19486,\n",
       " 'nor would': 12689,\n",
       " 'would audiences': 21910,\n",
       " 'audiences have': 1962,\n",
       " 'have accepted': 8119,\n",
       " 'accepted any': 245,\n",
       " 'any other': 1415,\n",
       " 'other portrayals': 13682,\n",
       " 'portrayals of': 14475,\n",
       " 'of them': 13196,\n",
       " 'them at': 18941,\n",
       " 'the time': 18800,\n",
       " 'in history': 9121,\n",
       " 'history safaris': 8654,\n",
       " 'safaris actually': 15696,\n",
       " 'actually did': 355,\n",
       " 'did use': 5062,\n",
       " 'use natives': 20478,\n",
       " 'natives carrying': 12427,\n",
       " 'carrying luggage': 3522,\n",
       " 'luggage on': 11194,\n",
       " 'on their': 13371,\n",
       " 'their heads': 18915,\n",
       " 'heads and': 8275,\n",
       " 'and tiny': 1238,\n",
       " 'tiny character': 19526,\n",
       " 'character did': 3671,\n",
       " 'did die': 5047,\n",
       " 'die heroic': 5084,\n",
       " 'heroic death': 8441,\n",
       " 'death trying': 4815,\n",
       " 'trying to': 20105,\n",
       " 'to save': 19750,\n",
       " 'save the': 15773,\n",
       " 'hunters and': 8896,\n",
       " 'and jane': 1048,\n",
       " 'jane as': 10059,\n",
       " 'as matter': 1750,\n",
       " 'matter of': 11508,\n",
       " 'of fact': 13031,\n",
       " 'fact it': 6314,\n",
       " 'wasn until': 20974,\n",
       " 'until gene': 20377,\n",
       " 'gene autry': 7410,\n",
       " 'autry treated': 1989,\n",
       " 'treated the': 20020,\n",
       " 'the native': 18561,\n",
       " 'native americans': 12424,\n",
       " 'americans and': 767,\n",
       " 'and colored': 921,\n",
       " 'people in': 14055,\n",
       " 'in his': 9120,\n",
       " 'his westerns': 8638,\n",
       " 'westerns like': 21225,\n",
       " 'like real': 10841,\n",
       " 'real human': 15052,\n",
       " 'human beings': 8865,\n",
       " 'beings that': 2501,\n",
       " 'that hollywood': 17969,\n",
       " 'hollywood began': 8682,\n",
       " 'began to': 2450,\n",
       " 'see that': 16003,\n",
       " 'it was': 9979,\n",
       " 'was okay': 20905,\n",
       " 'okay to': 13297,\n",
       " 'do so': 5291,\n",
       " 'wanted': 20798,\n",
       " 'read': 15029,\n",
       " 'comments': 4083,\n",
       " 'leaving': 10667,\n",
       " 'review': 15423,\n",
       " 'majority': 11292,\n",
       " 'definately': 4852,\n",
       " 'rules': 15650,\n",
       " 'aweful': 2031,\n",
       " 'acting': 288,\n",
       " 'non': 12673,\n",
       " 'realistic': 15069,\n",
       " 'animation': 1330,\n",
       " 'countless': 4444,\n",
       " 'errors': 5979,\n",
       " 'hoping': 8727,\n",
       " 'flaps': 6862,\n",
       " 'extended': 6259,\n",
       " 'stretch': 17306,\n",
       " 'imagination': 9004,\n",
       " 'can': 3400,\n",
       " 'extend': 6257,\n",
       " 'without': 21719,\n",
       " 'engines': 5861,\n",
       " 'landing': 10499,\n",
       " 'gear': 7397,\n",
       " 'cannot': 3457,\n",
       " 'be': 2221,\n",
       " 'lowered': 11182,\n",
       " 'unless': 20322,\n",
       " 'electricity': 5725,\n",
       " 'little': 10930,\n",
       " 'fan': 6396,\n",
       " 'going': 7618,\n",
       " 'sufficient': 17460,\n",
       " 'lower': 11179,\n",
       " 'quite': 14902,\n",
       " 'peculiar': 14015,\n",
       " 'when': 21274,\n",
       " 'they': 19073,\n",
       " 'landed': 10497,\n",
       " 'wheels': 21272,\n",
       " 'touched': 19926,\n",
       " 'down': 5446,\n",
       " 'nose': 12701,\n",
       " 'broke': 3048,\n",
       " 'off': 13238,\n",
       " 'thus': 19441,\n",
       " 'suspending': 17593,\n",
       " 'plane': 14271,\n",
       " 'both': 2809,\n",
       " 'tires': 19536,\n",
       " 'air': 525,\n",
       " 'captain': 3472,\n",
       " 'apply': 1506,\n",
       " 'left': 10679,\n",
       " 'right': 15477,\n",
       " 'brakes': 2959,\n",
       " 'weren': 21212,\n",
       " 'touching': 19932,\n",
       " 'ground': 7838,\n",
       " 'forget': 7084,\n",
       " 'spoilers': 16987,\n",
       " 'director': 5157,\n",
       " 'find': 6761,\n",
       " 'planes': 14278,\n",
       " 'attempting': 1925,\n",
       " 'sorry': 16901,\n",
       " 'technical': 17755,\n",
       " 'rant': 14958,\n",
       " 'give': 7535,\n",
       " '10': 0,\n",
       " 'wanted to': 20800,\n",
       " 'to read': 19736,\n",
       " 'read the': 15034,\n",
       " 'other comments': 13660,\n",
       " 'comments before': 4085,\n",
       " 'before leaving': 2436,\n",
       " 'leaving my': 10668,\n",
       " 'my review': 12351,\n",
       " 'review and': 15424,\n",
       " ...}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1,2))  # include bigrams as well as unigrams\n",
    "bigram_vectorizer.fit(input_text)  \n",
    "bigram_vectorizer.vocabulary_  # show the vocabulary of the bigram vectorizer, which includes both unigrams and bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a vectorizer that can produce representations including bigrams. Let's apply it to the text to get an expanded term-document matrix:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the bigram document-term matrix is:  (22190, 100)\n"
     ]
    }
   ],
   "source": [
    "bigram_doc_mat = bigram_vectorizer.transform(input_text).T\n",
    "print(\"The shape of the bigram document-term matrix is: \", bigram_doc_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL: \n",
    "\n",
    "This part aims to give you some more understanding of bigrams and n-grams in general, and shows you how to use the lemmatizer with the CountVectorizer class. It is not required to do this part, and we will revisit the use of n-grams and lemmatizers in the later lab on classifiers. \n",
    "\n",
    "The code below chooses a document that we can experiment with. \n",
    "\n",
    "**TO-DO 11:** Find the top three documents that are most similar to `selected_doc` when using vectors of bigrams+unigrams. Print them out. Hint: numpy contains useful functions such as argsort, for sorting a list or array. \n",
    "\n",
    "**TO-DO 12:** Repeat the process with the pure unigram bag of words representations. Does the list change? Can you see why it may be different? \n",
    "\n",
    "**TO-DO 13:** Experiment with other choices of `selected_doc` and increasing the length of the features bigrams to trigrams and other lengths of n-gram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynasty Revisited in Hawaii... Full of clichs, highly predictable, unrealistic and sometimes even stupid. If you have nothing better to do however, it does provide 40 minutes of simple, unpretensive entertainment, endless looks at great male and female muscles and very good photography of the spectacular Hawaiian scenery. On the other hand, If you are looking for anything more than that, stay away...<br /><br />Oh, and by the way, if you have ever worked in a Hotel or know anything about running one, you have two options: 1. You will feel sick every two minutes at the sheer stupidity and silliness of how the show presents Hotel Business or, 2. Look at it as science fiction comedy as I did, lie back, relax, and laugh about it!\n",
      "\n",
      "\n",
      "Document 40 with similarity score 0.4372419700686498: \n",
      "The recent boom of dating show on U. S. television screens has reached a fevered pitch since the first episode of \"The Bachelor.\" Unsuspecting audiences have since been subjected to countless clones and variations, including \"The Bachelorette\", \"Joe Millionaire\", \"For Love Or Money\", and the execrable \"Married By America.\" Hoping to cash in on this trend, and simultaneously tap and exploit a new demographic, Bravo has unleashed the disastrous \"Boy Meets Boy\" upon the world. And may they have mercy on us all.<br /><br />The premise is simple and is designed to be light-hearted: an eligible gay man is courted by a number of suitors, eliminated show by show until one is left, but there's a twist. Half of the men are actually straight. This is not much of a big deal, but the inherent viciousness of the scenario kicks in after hearing the pay-off: if, at the end of the show, the gay man picks a straight man in disguise, the straight man wins a cash prize. The gay man gets nothing, or at least nothing more than a few parting gifts, a pat on the back, and a hearty round of \"Aren't you embarrassed? Well, thanks for playing!\"<br /><br />Just the like the equally painful \"Queer Eye For The Straight Guy\" (another Bravo program), this show is another example of stereotypes run amok. What makes it even worse, though, is the fact that straight men are playing UP these stereotypes for cash. The producers of this show believe that all you have to do is put enough hair gel in a man's hair, dress up in Abercrombie & Fitch with a pair of designer sandals, strip him of all body hair and fat and voila! It's the gay equivalent to putting a white performer in blackface, and just as offensive to those of us -- like myself -- who are genuinely gay and don't dress/act like that. It implies that gays have no variance or chance for individuality, that they can't behave like real people, only like stereotypes. Never mind the fact that the bank of suitors is sorely lacking in any kind of diversity. All are gym-toned, most are white, and all look far too scrubbed and cleaned.<br /><br />This is another example of how, instead of fostering acceptance of gays as dynamic individuals capable of variance and change, Hollywood has again taken a stereotype and run with it all the way to the bank. I feel genuinely dirty watching this show, as show any gay man who sees this unabashed parade of soft-core pornography masquerading as legitimate television. 1 out of 10.\n",
      "\n",
      "\n",
      "Document 35 with similarity score 0.4531264015144125: \n",
      "What the movie The 60s really represents (to those of us who growled around in the belly of America in those times) is the turbulence and diversity of the decade. Despite the exaggerated, stereotyped characters, the genuineness of the issues remains clear.<br /><br />Not only were those radical times of change, but also very confusing times. Two basic things changed our world then: the 1964 Civil Rights Act, and the overwhelming influence of the media. Those two new freedoms began social changes that soon became institutionalized.<br /><br />From chaos came sensitivity, from disorder came values. Bear in mind however, that the bulk of Americans were not involved in this... they worked, they played, they watched the news... and slowly they became effected by the efforts and struggles of the minorities... the Civil Rights workers, the Political Activists, the Anti-War efforts, the War on Poverty....<br /><br />The representation of the power of the press and TV in particular, was well reflected, although the conflict between the general public's attitude and those seeking to change things was at best ignored... and at worst, misrepresented.. Middle class Americans weren't all standing around angrily holding baseball bats, or disowning their wayward daughters. They were confused too. Let us not forget how Folk Singers suddenly became Protest Singers, and how The Beatles began an onslaught that killed the Folk-Protest Movement. There are no Beatle songs in the movie, or even any mention of them.<br /><br />I think if you didn't live the decade, you might not have a sense of what the movie is about, the overall picture is a bit dim. At one point I held down a steady job while my sister lived at the Hog Farm Commune and went to Woodstock. At another point I was in Haight Asbury and in the Detroit Riots while she worked and played the housewife in Maine and Connecticut. Roles were constantly changing.<br /><br />The movie depicts three siblings of a middle class family. They represent the hippie child, the political activist, and the active military personnel. Dad represents the typical attitudes, and mom represents the voice of reason, tolerance, and sometimes compromise... for the sake of peace.<br /><br />The Black family comprises a minister and his son... disproportionately, I think. I assume the producers knew all the variables and had to settle on limitations, or else the film would have become a long, boring, documentary. Dad's message was that anger produces bitterness, and bitterness produces chaos. It was clearly a message directed to today's youth.<br /><br />We are looking at a unique solution to social problems, and also how issues divide us... The 60s were unusual in that way, and only the Roaring 20s compare. In other words, this movie has a moral after all. In the end, it is our Collective Individualism that survives. Put that in your oxymoron list.<br /><br />Everyone was a God, a Guru, or a free-spirited genius in the 60s. It was a time of magic and madness. No one will ever nail the 60s down right... it was too diverse (this movie is close). At least we can say we are not ashamed of it, that we learned and grew from it, and that for once, a generation shaped and changed America... for the better.\n",
      "\n",
      "\n",
      "Document 94 with similarity score 0.4555014868881578: \n",
      "haha! you have to just smile and smile if you actually made it all the way through this movie. it like says something about myself i guess. the movie itself was created i think as some sort of psychological test, or like some sort of drug, to take you to a place you have never been before. When Wittgenstein wrote his famous first philosophical piece the tractacus (sp?) he said it was meaningless and useless, but if you read it, after you were done, it would take you to a new level, like a ladder, and then you could throw away the work and see things with clarity and true understanding. this movie is the same i think.<br /><br />As a movie it is without a doubt, the worst movie i have seen in a long long time in such a unique way. first of all, this is snipes. i loved watching this guy kick ass in various movies. and i have suffered through a few weak ones. however, although you know the movie might suck, you would never suspect that it could be as bad as it actually was. which is the fun of it. i mean this is snipes. you know it might be good, but it will be alright, right? smile.<br /><br />so this thing on every level is pure boredom, pure unoriginality. the reference to the professional is both dead on and obvious, yet so poorly done as to be comical. there is not one character in this movie that is interesting, in the least. and to make the whole thing more surreal, they have a soundtrack that sort of sounds like parts to various Bourne identity type movies, only isn't quite right. in fact, although it seems close to action movie background music, it just so happens it is done in a manner that will grate on you fantastically.<br /><br />then all the scenes in the total pitch black, where honestly since the characters are so flat, you don't really care whats going to happen, but regardless, after it happens and someone is killed, you just say to yourself, was i supposed to see that? what else? how about scenes with blinding, obnoxious flashing at a strobe lights pace, for a period of time that is too long to bear. sure let's throw that in. how bout this though. when you are straining and your eyes cant handle it any longer, do some more of these in the dark kills where you really don't see what happened. and on top of that, lets face it you don't care. you were past bored way from the beginning.<br /><br />so i drifted in and out a couple times, but i caught almost all of this movie. and it becomes something you can watch, without something that engages your mind on any level, therefore, it becomes something you can effectively zone out with, and begin to think about your life, where its going, where its been, what we are as people.<br /><br />and that... that is the true magic of this film.\n",
      "\n",
      "\n",
      "Now for unigrams only: \n",
      "Document 35 with similarity score 0.5827346118371753: \n",
      "What the movie The 60s really represents (to those of us who growled around in the belly of America in those times) is the turbulence and diversity of the decade. Despite the exaggerated, stereotyped characters, the genuineness of the issues remains clear.<br /><br />Not only were those radical times of change, but also very confusing times. Two basic things changed our world then: the 1964 Civil Rights Act, and the overwhelming influence of the media. Those two new freedoms began social changes that soon became institutionalized.<br /><br />From chaos came sensitivity, from disorder came values. Bear in mind however, that the bulk of Americans were not involved in this... they worked, they played, they watched the news... and slowly they became effected by the efforts and struggles of the minorities... the Civil Rights workers, the Political Activists, the Anti-War efforts, the War on Poverty....<br /><br />The representation of the power of the press and TV in particular, was well reflected, although the conflict between the general public's attitude and those seeking to change things was at best ignored... and at worst, misrepresented.. Middle class Americans weren't all standing around angrily holding baseball bats, or disowning their wayward daughters. They were confused too. Let us not forget how Folk Singers suddenly became Protest Singers, and how The Beatles began an onslaught that killed the Folk-Protest Movement. There are no Beatle songs in the movie, or even any mention of them.<br /><br />I think if you didn't live the decade, you might not have a sense of what the movie is about, the overall picture is a bit dim. At one point I held down a steady job while my sister lived at the Hog Farm Commune and went to Woodstock. At another point I was in Haight Asbury and in the Detroit Riots while she worked and played the housewife in Maine and Connecticut. Roles were constantly changing.<br /><br />The movie depicts three siblings of a middle class family. They represent the hippie child, the political activist, and the active military personnel. Dad represents the typical attitudes, and mom represents the voice of reason, tolerance, and sometimes compromise... for the sake of peace.<br /><br />The Black family comprises a minister and his son... disproportionately, I think. I assume the producers knew all the variables and had to settle on limitations, or else the film would have become a long, boring, documentary. Dad's message was that anger produces bitterness, and bitterness produces chaos. It was clearly a message directed to today's youth.<br /><br />We are looking at a unique solution to social problems, and also how issues divide us... The 60s were unusual in that way, and only the Roaring 20s compare. In other words, this movie has a moral after all. In the end, it is our Collective Individualism that survives. Put that in your oxymoron list.<br /><br />Everyone was a God, a Guru, or a free-spirited genius in the 60s. It was a time of magic and madness. No one will ever nail the 60s down right... it was too diverse (this movie is close). At least we can say we are not ashamed of it, that we learned and grew from it, and that for once, a generation shaped and changed America... for the better.\n",
      "\n",
      "\n",
      "Document 76 with similarity score 0.5834675159208828: \n",
      "Miike makes a children's adventure film, not unlike The Neverending Story. It's actually one of my least favorite of the director's films. Even the worst Miike is better than a good many films, though, and The Great Yokai War has a lot in it that's worth recommending. It's at least as loud and obnoxious as most American kiddie flicks. I might think kids themselves would find a lot to like in it (the DVD includes an English dub), but, like all of Miike's films, it can tend to move very slowly. That means you've got kind of a weird unevenness, where sometimes there's a loud action sequence and the next scene will drag on forever as characters converse. The story itself isn't very good, either, and Miike's perpetual flaw of incoherency rears its ugly head. Most of what I liked came from the technical side of things. This has to be Miike's most expensive movie, and it looks fantastic. \"Yokai\" are Japanese spirits, and they come in all different, fantastical forms, and the costume designers, special effects crew, and everyone else involved in the designs just did an outstanding job. I've seen the 1968 film this one is supposedly based on (Yokai Monsters: Spook Warfare), and the cheesy rubber-suit monsters you can find there have been transformed into more believable entities using state-of-the-art makeup and special effects. I especially liked the look of one of the bad guys (or girls, in this case), Agi, who sports dark eye shadow, a tight, white outfit, a white beehive hairdo and a whip. She's played, incidentally, by Chiaki Kuriyama, whom you might remember as Lucy Liu's teenage henchgirl in Kill Bill: Vol. 1. The hero of the film is played by Ryunosuke Kamiki, who provided voices for Miyazaki's Spirited Away and Howl's Moving Castle.\n",
      "\n",
      "\n",
      "Document 94 with similarity score 0.5977002796413386: \n",
      "haha! you have to just smile and smile if you actually made it all the way through this movie. it like says something about myself i guess. the movie itself was created i think as some sort of psychological test, or like some sort of drug, to take you to a place you have never been before. When Wittgenstein wrote his famous first philosophical piece the tractacus (sp?) he said it was meaningless and useless, but if you read it, after you were done, it would take you to a new level, like a ladder, and then you could throw away the work and see things with clarity and true understanding. this movie is the same i think.<br /><br />As a movie it is without a doubt, the worst movie i have seen in a long long time in such a unique way. first of all, this is snipes. i loved watching this guy kick ass in various movies. and i have suffered through a few weak ones. however, although you know the movie might suck, you would never suspect that it could be as bad as it actually was. which is the fun of it. i mean this is snipes. you know it might be good, but it will be alright, right? smile.<br /><br />so this thing on every level is pure boredom, pure unoriginality. the reference to the professional is both dead on and obvious, yet so poorly done as to be comical. there is not one character in this movie that is interesting, in the least. and to make the whole thing more surreal, they have a soundtrack that sort of sounds like parts to various Bourne identity type movies, only isn't quite right. in fact, although it seems close to action movie background music, it just so happens it is done in a manner that will grate on you fantastically.<br /><br />then all the scenes in the total pitch black, where honestly since the characters are so flat, you don't really care whats going to happen, but regardless, after it happens and someone is killed, you just say to yourself, was i supposed to see that? what else? how about scenes with blinding, obnoxious flashing at a strobe lights pace, for a period of time that is too long to bear. sure let's throw that in. how bout this though. when you are straining and your eyes cant handle it any longer, do some more of these in the dark kills where you really don't see what happened. and on top of that, lets face it you don't care. you were past bored way from the beginning.<br /><br />so i drifted in and out a couple times, but i caught almost all of this movie. and it becomes something you can watch, without something that engages your mind on any level, therefore, it becomes something you can effectively zone out with, and begin to think about your life, where its going, where its been, what we are as people.<br /><br />and that... that is the true magic of this film.\n",
      "\n",
      "\n",
      "Now for different sizes of n-grams: \n",
      "Document 40 with similarity score 0.35510940249622597: \n",
      "The recent boom of dating show on U. S. television screens has reached a fevered pitch since the first episode of \"The Bachelor.\" Unsuspecting audiences have since been subjected to countless clones and variations, including \"The Bachelorette\", \"Joe Millionaire\", \"For Love Or Money\", and the execrable \"Married By America.\" Hoping to cash in on this trend, and simultaneously tap and exploit a new demographic, Bravo has unleashed the disastrous \"Boy Meets Boy\" upon the world. And may they have mercy on us all.<br /><br />The premise is simple and is designed to be light-hearted: an eligible gay man is courted by a number of suitors, eliminated show by show until one is left, but there's a twist. Half of the men are actually straight. This is not much of a big deal, but the inherent viciousness of the scenario kicks in after hearing the pay-off: if, at the end of the show, the gay man picks a straight man in disguise, the straight man wins a cash prize. The gay man gets nothing, or at least nothing more than a few parting gifts, a pat on the back, and a hearty round of \"Aren't you embarrassed? Well, thanks for playing!\"<br /><br />Just the like the equally painful \"Queer Eye For The Straight Guy\" (another Bravo program), this show is another example of stereotypes run amok. What makes it even worse, though, is the fact that straight men are playing UP these stereotypes for cash. The producers of this show believe that all you have to do is put enough hair gel in a man's hair, dress up in Abercrombie & Fitch with a pair of designer sandals, strip him of all body hair and fat and voila! It's the gay equivalent to putting a white performer in blackface, and just as offensive to those of us -- like myself -- who are genuinely gay and don't dress/act like that. It implies that gays have no variance or chance for individuality, that they can't behave like real people, only like stereotypes. Never mind the fact that the bank of suitors is sorely lacking in any kind of diversity. All are gym-toned, most are white, and all look far too scrubbed and cleaned.<br /><br />This is another example of how, instead of fostering acceptance of gays as dynamic individuals capable of variance and change, Hollywood has again taken a stereotype and run with it all the way to the bank. I feel genuinely dirty watching this show, as show any gay man who sees this unabashed parade of soft-core pornography masquerading as legitimate television. 1 out of 10.\n",
      "\n",
      "\n",
      "Document 94 with similarity score 0.37045336104509696: \n",
      "haha! you have to just smile and smile if you actually made it all the way through this movie. it like says something about myself i guess. the movie itself was created i think as some sort of psychological test, or like some sort of drug, to take you to a place you have never been before. When Wittgenstein wrote his famous first philosophical piece the tractacus (sp?) he said it was meaningless and useless, but if you read it, after you were done, it would take you to a new level, like a ladder, and then you could throw away the work and see things with clarity and true understanding. this movie is the same i think.<br /><br />As a movie it is without a doubt, the worst movie i have seen in a long long time in such a unique way. first of all, this is snipes. i loved watching this guy kick ass in various movies. and i have suffered through a few weak ones. however, although you know the movie might suck, you would never suspect that it could be as bad as it actually was. which is the fun of it. i mean this is snipes. you know it might be good, but it will be alright, right? smile.<br /><br />so this thing on every level is pure boredom, pure unoriginality. the reference to the professional is both dead on and obvious, yet so poorly done as to be comical. there is not one character in this movie that is interesting, in the least. and to make the whole thing more surreal, they have a soundtrack that sort of sounds like parts to various Bourne identity type movies, only isn't quite right. in fact, although it seems close to action movie background music, it just so happens it is done in a manner that will grate on you fantastically.<br /><br />then all the scenes in the total pitch black, where honestly since the characters are so flat, you don't really care whats going to happen, but regardless, after it happens and someone is killed, you just say to yourself, was i supposed to see that? what else? how about scenes with blinding, obnoxious flashing at a strobe lights pace, for a period of time that is too long to bear. sure let's throw that in. how bout this though. when you are straining and your eyes cant handle it any longer, do some more of these in the dark kills where you really don't see what happened. and on top of that, lets face it you don't care. you were past bored way from the beginning.<br /><br />so i drifted in and out a couple times, but i caught almost all of this movie. and it becomes something you can watch, without something that engages your mind on any level, therefore, it becomes something you can effectively zone out with, and begin to think about your life, where its going, where its been, what we are as people.<br /><br />and that... that is the true magic of this film.\n",
      "\n",
      "\n",
      "Document 35 with similarity score 0.3756598037047414: \n",
      "What the movie The 60s really represents (to those of us who growled around in the belly of America in those times) is the turbulence and diversity of the decade. Despite the exaggerated, stereotyped characters, the genuineness of the issues remains clear.<br /><br />Not only were those radical times of change, but also very confusing times. Two basic things changed our world then: the 1964 Civil Rights Act, and the overwhelming influence of the media. Those two new freedoms began social changes that soon became institutionalized.<br /><br />From chaos came sensitivity, from disorder came values. Bear in mind however, that the bulk of Americans were not involved in this... they worked, they played, they watched the news... and slowly they became effected by the efforts and struggles of the minorities... the Civil Rights workers, the Political Activists, the Anti-War efforts, the War on Poverty....<br /><br />The representation of the power of the press and TV in particular, was well reflected, although the conflict between the general public's attitude and those seeking to change things was at best ignored... and at worst, misrepresented.. Middle class Americans weren't all standing around angrily holding baseball bats, or disowning their wayward daughters. They were confused too. Let us not forget how Folk Singers suddenly became Protest Singers, and how The Beatles began an onslaught that killed the Folk-Protest Movement. There are no Beatle songs in the movie, or even any mention of them.<br /><br />I think if you didn't live the decade, you might not have a sense of what the movie is about, the overall picture is a bit dim. At one point I held down a steady job while my sister lived at the Hog Farm Commune and went to Woodstock. At another point I was in Haight Asbury and in the Detroit Riots while she worked and played the housewife in Maine and Connecticut. Roles were constantly changing.<br /><br />The movie depicts three siblings of a middle class family. They represent the hippie child, the political activist, and the active military personnel. Dad represents the typical attitudes, and mom represents the voice of reason, tolerance, and sometimes compromise... for the sake of peace.<br /><br />The Black family comprises a minister and his son... disproportionately, I think. I assume the producers knew all the variables and had to settle on limitations, or else the film would have become a long, boring, documentary. Dad's message was that anger produces bitterness, and bitterness produces chaos. It was clearly a message directed to today's youth.<br /><br />We are looking at a unique solution to social problems, and also how issues divide us... The 60s were unusual in that way, and only the Roaring 20s compare. In other words, this movie has a moral after all. In the end, it is our Collective Individualism that survives. Put that in your oxymoron list.<br /><br />Everyone was a God, a Guru, or a free-spirited genius in the 60s. It was a time of magic and madness. No one will ever nail the 60s down right... it was too diverse (this movie is close). At least we can say we are not ashamed of it, that we learned and grew from it, and that for once, a generation shaped and changed America... for the better.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_doc = 1\n",
    "scores = []\n",
    "\n",
    "print(input_text[selected_doc])  # print the document we're using as our query\n",
    "print(\"\\n\")\n",
    "\n",
    "### WRITE YOUR OWN CODE HERE \n",
    "for i in range(len(input_text)):\n",
    "    scores.append(cossim(bigram_doc_mat[:, selected_doc].toarray().flatten(), bigram_doc_mat[:, i].toarray().flatten()))\n",
    "\n",
    "most_sim = np.argsort(scores)[-4:-1]\n",
    "\n",
    "for doc in most_sim:\n",
    "    print(f\"Document {doc} with similarity score {scores[doc]}: \")\n",
    "    print(input_text[doc])\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Now for unigrams only: \")\n",
    "scores = []\n",
    "for i in range(len(input_text)):\n",
    "    scores.append(cossim(term_doc_mat[:, selected_doc].toarray().flatten(), term_doc_mat[:, i].toarray().flatten()))\n",
    "\n",
    "most_sim = np.argsort(scores)[-4:-1]\n",
    "\n",
    "for doc in most_sim:\n",
    "    print(f\"Document {doc} with similarity score {scores[doc]}: \")\n",
    "    print(input_text[doc])\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Now for different sizes of n-grams: \")\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(3,3))  # include bigrams as well as unigrams\n",
    "ngram_vectorizer.fit(input_text)  \n",
    "ngram_doc_mat = ngram_vectorizer.transform(input_text).T\n",
    "scores = []\n",
    "for i in range(len(input_text)):\n",
    "    scores.append(cossim(ngram_doc_mat[:, selected_doc].toarray().flatten(), ngram_doc_mat[:, i].toarray().flatten()))\n",
    "\n",
    "most_sim = np.argsort(scores)[-4:-1]\n",
    "\n",
    "for doc in most_sim:\n",
    "    print(f\"Document {doc} with similarity score {scores[doc]}: \")\n",
    "    print(input_text[doc])\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary size is probably getting very large, now that we are using bigrams and other n-grams. \n",
    "\n",
    "To apply lemmatization, we have to go back to the CountVectorizer and define a new tokenizer class that will carry out the extra step of lemmatization. The code below shows how to apply lemmatization with the CountVectorizer class to reduce the vocabulary size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thought', 'this', 'movie', 'was', 'really', 'great', 'helena', 'did', 'an', 'amazing', 'job', 'in', 'it', 'she', 'played', 'her', 'character', 'very', 'well', 'awesome', 'actress', 'br', 'the', 'also', 'funny', 'too', 'jokes', 'were', 'couldnt', 'stop', 'laughing', 'think', 'everyone', 'should', 'see', 'dynasty', 'revisited', 'hawaii', 'full', 'of', 'clichs', 'highly', 'predictable', 'unrealistic', 'and', 'sometimes', 'even', 'stupid', 'if', 'you', 'have', 'nothing', 'better', 'to', 'do', 'however', 'does', 'provide', '40', 'minutes', 'simple', 'unpretensive', 'entertainment', 'endless', 'looks', 'at', 'male', 'female', 'muscles', 'good', 'photography', 'spectacular', 'hawaiian', 'scenery', 'on', 'other', 'hand', 'are', 'looking', 'for', 'anything', 'more', 'than', 'that', 'stay', 'away', 'oh', 'by', 'way', 'ever', 'worked', 'hotel', 'or', 'know', 'about', 'running', 'one', 'two', 'options', 'will', 'feel', 'sick', 'every', 'sheer', 'stupidity', 'silliness', 'how', 'show', 'presents', 'business', 'look', 'as', 'science', 'fiction', 'comedy', 'lie', 'back', 'relax', 'laugh', 'entire', 'weissmuller', 'tarzan', 'series', 'dvd', 'fully', 'restored', 'editions', 'never', 'tire', 'watching', 'them', 'my', 'personal', 'favorite', 'is', 'his', 'mate', 'due', 'entirely', 'almost', 'maureen', 'sullivan', 'costume', 'occasional', 'flashes', 'genital', 'area', 'beneath', 'leather', 'flap', 'hanging', 'front', 'before', 'anyone', 'claims', 'wasn', 'what', 'like', 'let', 'me', 'say', 'watched', 'numerous', 'time', 'high', 'zoom', 'mode', 'trust', 'completely', 'naked', 'underneath', 'several', 'times', 'especially', 'during', 'lion', 'attack', 'end', 'careful', 'viewing', 'slow', 'motion', 'maximum', 'reveal', 'shaved', 'except', 'tiny', 'patch', 'dark', 'hair', 'covering', 'labia', 'there', 'no', 'mistake', 'all', 'swimming', 'scene', 'being', 'body', 'double', 'skin', 'suit', 'yes', 'but', 'not', 'wearing', 'any', 'else', 'again', 'shows', 'everything', 'those', 'who', 'want', 'now', 'controversy', 'out', 'move', 'actual', 'script', 'written', 'tightly', 'action', 'sequences', 'simply', 'although', 'obviously', 'stuntman', 'riding', 'rhino', 'actually', 'wrestles', 'big', 'use', 'background', 'shots', 'second', 'unit', 'stuff', 'from', 'africa', 'blended', 'with', 'studio', 'us', 'locations', 'making', 'hard', 'tell', 'which', 'don', 'complain', 'much', 'though', 'remember', '90', 'films', 'phony', 'anyway', 'so', 'just', 'enjoy', 'damned', 'thing', 'bowl', 'popcorn', 'some', 'cold', 'beer', 'fresh', 'pack', 'smokes', 'sexy', 'willing', 'girlfriend', 'wife', 'isn', 'line', 'either', 'lol', 'final', 'word', 'nudity', 'beginning', 'while', 'white', 'hunters', 'speaking', 'dialogue', 'keep', 'your', 'eyes', 'extras', 'nude', 'african', 'girls', 'shot', 'location', 'behind', 'racist', 'standards', '1930', 'until', '1960', 'colored', 'people', 'portrayed', 'then', 'shaft', 'hadn', 'been', 'nor', 'would', 'audiences', 'accepted', 'portrayals', 'history', 'safaris', 'natives', 'carrying', 'luggage', 'their', 'heads', 'die', 'heroic', 'death', 'trying', 'save', 'jane', 'matter', 'fact', 'gene', 'autry', 'treated', 'native', 'americans', 'westerns', 'real', 'human', 'beings', 'hollywood', 'began', 'okay', 'wanted', 'read', 'comments', 'leaving', 'review', 'majority', 'definately', 'rules', 'aweful', 'acting', 'non', 'realistic', 'animation', 'countless', 'errors', 'hoping', 'flaps', 'extended', 'stretch', 'imagination', 'can', 'extend', 'without', 'engines', 'landing', 'gear', 'cannot', 'be', 'lowered', 'unless', 'electricity', 'little', 'fan', 'going', 'sufficient', 'lower', 'quite', 'peculiar', 'when', 'they', 'landed', 'wheels', 'touched', 'down', 'nose', 'broke', 'off', 'thus', 'suspending', 'plane', 'both', 'tires', 'air', 'captain', 'apply', 'left', 'right', 'brakes', 'weren', 'touching', 'ground', 'forget', 'spoilers', 'director', 'find', 'planes', 'attempting', 'sorry', 'technical', 'rant', 'give', '10', 'where', 'sidewalk', 'ends', 'otto', 'preminger', 'reunites', 'dana', 'andrews', 'tierney', 'surely', 'hopes', 'recapturing', 'magic', 'laura', 're', 'wildly', 'dissimilar', 'set', 'different', 'strata', 'new', 'york', 'mention', 'opposite', 'poles', 'noir', 'universe', 'fine', 'mist', 'gothic', 'hovers', 'over', 'upscale', 'manhattan', 'its', 'erotic', 'obsession', 'faint', 'whiff', 'necrophilia', 'pure', 'urban', 'soot', 'grit', 'befouling', 'town', 'basement', 'apartments', 'steam', 'rooms', 'parking', 'garages', 'bit', 'revered', 'forerunner', 'dyed', 'wool', 'contrast', 'clutch', '1944', 'french', 'first', 'dubbed', 'still', 'sophisticated', 'murder', 'mystery', 'daylight', 'enters', 'only', 'temporary', 'sufferance', 'joseph', 'lashelle', 'makes', 'most', 'alleys', 'brownstones', 'docks', 'el', 'quintessential', 'city', 'specifically', 'apple', 'others', 'bumper', 'crop', '1950', 'side', 'street', 'sleeping', 'tattooed', 'stranger', 'edge', 'doom', 'opens', 'police', 'detective', 'carpet', 'brutal', 'ways', 'particularly', 'vendetta', 'towards', 'crime', 'boss', 'gary', 'merrill', 'whom', 'we', 'learn', 'up', 'ne', 'er', 'father', 'towner', 'stabbed', 'floating', 'crap', 'game', 'operated', 'trigger', 'roughs', 'witness', 'causing', 'him', 'fatal', 'crack', 'skull', 'exacerbated', 'steel', 'plate', 'installed', 'veteran', 'head', 'realizing', 'already', 'dumps', 'river', 'after', 'suspect', 'had', 'taken', 'powder', 'course', 'far', 'corpse', 'discovered', 'estranged', 'turns', 'evidence', 'starts', 'turn', 'toward', 'tom', 'tully', 'hack', 'driver', 'happened', 'cruising', 'same', 'mean', 'streets', 'night', 'ample', 'reason', 'abusive', 'son', 'law', 'dead', 'embittered', 'loner', 'finds', 'summons', 'nature', 'he', 'tries', 'exonerate', 'keeping', 'own', 'involvement', 'whole', 'sordid', 'secret', 'epigrammatic', 'ben', 'hecht', 'pungency', 'dressing', 'superior', 'tells', 'bunged', 'barrelhouse', 'fag', 'spread', 'attention', 'half', 'dozen', 'characters', 'here', 'sole', 'focus', 'role', 'less', 'central', 'spectral', 'may', 'excelled', 'performance', 'tight', 'lipped', 'taciturn', 'eloquent', 'face', 'silently', 'registering', 'anguish', 'obstinacy', 'has', 'brought', 'pent', 'sufferer', 'release', 'through', 'safety', 'valve', 'violence', 'lashes', 'against', 'loyal', 'partner', 'bert', 'freed', 'sure', 'swift', 'road', 'redemption', 'agency', 'beautiful', 'co', 'star', 'style', 'sweetened', 'ending', 'undermine', 'story', 'corruption', 'entanglements', 'describe', 'film', 'wants', 'tried', 'dismiss', 'quickly', 'because', 'feeling', 'might', 'perfect', '12', 'years', 'old', 'girl', 'nice', 'concept', 'modern', 'version', 'beauty', 'twist', 'rather', 'dreamy', 'sketches', 'young', 'boy', 'relationship', 'single', 'working', 'mother', 'schoolmate', 'start', 'got', 'greedy', 'drama', 'thriller', 'possible', 'romantic', 'love', 'fairy', 'tale', 'under', 'sun', 'result', 'audience', 'inadequate', 'example', 'risa', 'goto', 'finally', 'woken', 'yuki', 'kohara', 'kiss', 'instead', 'try', 'scary', 'order', 'make', 'afterwards', 'cheap', 'trick', 'ruin', 'anticipation', 'emotion', 'build', 'original', 'base', 'known', 'work', 'comic', 'book', 'artist', 'osamu', 'tezuka', 'famous', 'intriguing', 'intricate', 'stories', 'wonder', 'problems', 'exsist', 'occur', 'adaption', 'illogical', 'someone', 'used', 'fussy', 'logic', 'japanese', 'instance', 'manage', 'get', 'hospital', 'instant', 'suppose', 'long', 'bus', 'ride', 'run', 'tv', 'cameras', 'saw', 'live', 'interview', 'television', 'scenes', 'directly', 'copied', 'uncreative', 'seem', 'pointlessly', 'annoying', 'ie', 'mouth', 'caugh', 'roman', 'holiday', 'fails', 'enough', 'strangely', 'unintentional', 'ghost', 'nevertheless', 'credit', 'managed', 'caputured', 'sentiment', 'teenager', 'come', 'warning', 'label', 'said', 'suitable', 'person', '18', 'age', 'definitly', 'poster', 'promisingly', 'early', 'frank', 'morgan', 'advises', 'cooper', 'marriage', 'daughter', 'anita', 'louise', 'playing', 'unabashed', 'gold', 'digger', 'loudly', 'complains', 'perceived', 'penury', 'hands', 'family', 'including', 'am', 'actors', 'mind', 'treasure', 'legend', 'lovely', 'versatile', 'appreciated', 'seldom', 'seen', 'leading', 'teresa', 'wright', 'blessed', 'range', 'usually', 'delivers', 'heart', 'warming', 'performances', 'promising', 'opening', 'slides', 'downhill', 'found', 'humorous', 'burning', 'home', 'laws', 'butler', 'such', 'fastidious', 'smoking', 'household', 'blithely', 'walk', 'allowing', 'continue', 'alternatively', 'certainly', 'supply', 'means', 'disposing', 'ill', 'timed', 'cigarette', 'moreover', 'nobody', 'common', 'sense', 'permit', 'himself', 'holding', 'lit', 'asking', 'crushes', 'handkerchief', 'sticks', 'pocket', 'sequence', 'made', 'foolish', 'gauche', 'poor', 'contrivance', 'conceived', 'filmed', 'induces', 'ridicule', 'laughter', 'forced', 'medical', 'examination', 'equally', 'contrived', 'lets', 'undergo', 'complete', 'advised', 'purpose', 'giving', 'consent', 'removed', 'reality', 'absurd', 'stealing', 'babies', 'hospitals', 'serious', 'legal', 'offense', 'overly', 'neurotic', 'baby', 'feeding', 'weight', 'struck', 'nerve', 'few', 'experienced', 'anxiety', 'newborn', 'tedious', 'wardrobe', 'prop', 'departments', 'went', 'top', 'paradoxically', 'writer', 'sleep', 'lines', 'generate', 'humor', 'miss', 'cylinders', 'laughs', 'mile', 'minute', 'light', 'year', 'energy', 'camera', 'totally', 'wasted', 'interests', 'respective', 'fathers', 'cooped', 'room', 'together', 'probably', 'rich', 'vein', 'somewhere', 'mine', 'none', 'extracted', 'likable', 'hurt', 'predictably', 'gets', 'jilted', 'wedding', 'fate', 'loose', 'done', 'unsympathetic', 'unlike', 'gail', 'patrick', 'consequently', 'expecting', 'perhaps', 'context', 'happy', 'essentially', 'wiped', 'undermines', 'effect', 'kept', 'waiting', 'something', 'happen', 'witty', 'dialog', 'characteristic', 'movies', 'era', 'delivered', 'slightly', 'drifter', 'mistaken', 'hit', 'man', 'small', 'wyoming', 'kinds', 'complications', 'cage', 'perfectly', 'cast', 'unlucky', 'schmuck', 'quick', 'buck', 'finding', 'escape', 'title', 'hopper', 'best', 'psycho', 'lyle', 'dallas', 'walsh', 'crooked', 'sheriff', 'boyle', 'femme', 'fatale', 'round', 'brothers', 'john', 'rick', 'dahl', 'contains', 'delicious', 'twists', 'direction', 'creates', 'terrific', 'neo', 'atmosphere', 'entertaining', 'sucks', 'viewer', 'assuming', 'won', 'straight', 'video', 'void', 'costs', 'bored', 'executed', 'last', 'afi', '20', 'remaining', 'didn', 'care', 'anymore', 'plot', 'insulting', 'awkward', 'spot', 'goof', 'into', 'shattered', 'window', 'fired', 'breaks', 'things', 'bad', 'indicator', 'unfortunately', 'll', 'spare', 'details', 'sub', 'par', 'manner', 'assed', 'michael', 'madsen', 'disappointing', 'rape', 'christ', 'shut', 'take', 'lot', 'reviews', 'books', 'frankly', 'unappealing', 'pick', 'vastly', 'overrated', 'shakespeare', 'king', 'james', 'english', 'appealed', 'fair', 'share', 'latter', 'ronald', 'colman', 'othello', 'points', 'include', 'thanks', 'print', 'decent', 'cinematography', 'slim', 'attractive', 'shelly', 'winters', 'overall', 'boring', 'repetition', 'watch', 'besides', 'nut', 'cases', 'kudos', 'demonstrating', 'despite', 'interesting', 'premise', 'sniper', 'tighter', 'sharper', 'directing', 'could', 'electrifying', 'plods', 'along', 'tension', 'pretty', 'recycles', 'footage', 'credits', 'criminally', 'insane', 'poorly', 'lack', 'proper', 'lighting', 'sound', 'nearly', 'inaudible', 'glitches', 'picture', 'rolling', 'sequels', 'basically', 'repeats', 'ethel', 'kills', 'everybody', 'shares', 'living', 'space', 'often', 'reasons', 'having', 'getting', 'food', 'least', 'extra', 'includes', 'satan', 'black', 'doesn', 'nurse', 'adventures', 'buckaroo', 'banzai', 'trouble', 'china', 'conan', 'barbarian', 'horrible', 'certain', 'coolness', 'self', 'deprecating', 'cult', 'sensations', 'golden', 'child', 'plain', 'itself', 'unworkable', 'moments', 'eddy', 'murphy', 'flip', 'attitude', 'deflates', 'danger', 'special', 'effects', 'silly', 'damage', 'mystic', 'secrets', 'tibetan', 'buddhism', 'lampooned', 'drawn', 'upon', 'compel', 'stake', 'faced', 'why', 'fans', 'help', 'themselves', 'joke', 'shower', 'keeps', 'within', 'many', 'takes', 'place', 'bathhouse', 'denizens', 'supplying', 'pathos', 'emotional', 'touches', 'friendship', 'between', 'proprietor', 'retarded', 'deep', 'moving', 'older', 'brother', 'world', 'seems', 'unforced', 'persuasive', 'meandering', 'surprises', 'ironies', 'call', 'neighborliness', 'relations', 'conflicts', 'performers', 'pull', 'believe', 'aired', 'yesterday', 'decided', 'check', 'bruce', 'timm', 'paul', 'dini', 'dtv', 'projects', 'related', '1992', 'batman', 'animated', 'jeff', 'matsuda', 'came', 'imagined', 'centers', 'around', 'appearance', 'vigilante', 'batwoman', 'feels', 'need', 'extreme', 'methods', 'meantime', 'pengiun', 'ruphert', 'thorn', 'secretly', 'carlton', 'duquesne', 'troubles', 'another', 'villain', 'later', 'revealed', 'weapons', 'smuggling', 'operation', 'put', 'bounty', 'question', 'mysterious', 'solve', 'penguin', 'latest', 'fairly', 'complex', 'tone', 'plus', 'redesign', 'mob', 'seeing', 'comics', 'previous', 'designs', 'borrowed', 'elements', 'tim', 'burton', 'vision', 'pengium', 'sewer', 'rat', 'circus', 'freak', 'subplot', 'carried', 'derail', 'forever', 'voice', 'standard', 'quality', 'these', 'direct', 'mask', 'phantasm', 'took', 'route', 'kevin', 'conroy', 'shines', 'wayne', 'short', '80', 'manages', 'storyline', 'minor', 'bucket', 'loads', 'downsides', 'nightwing', 'nowhere', 'barbara', 'gordon', 'click', 'couple', 'referenced', 'drake', 'aka', 'robin', 'design', 'post', 'btas', 'kinda', 'fat', 'built', 'bulked', 'individual', 'model', 'blue', 'clark', 'kent', 'true', 'alike', 'downside', 'rupert', 'throne', 'explanation', 'deal', 'safe', 'goons', 'cut', 'hang', 'penguim', 'gun', 'count', 'happens', 'surprised', 'worth', 'rental', 'holds', 'bar', 'cruel', 'offensive', 'offended', 'riot', 'wrong', 'worest', 'since', 'open', 'water', 'date', 'wont', 'box', 'office', 'potential', 'fell', 'development', 'upside', 'boobs', 'myself', 'go', 'postal', 'hence', 'add', 'excellent', 'rks', 'indian', 'directors', 'ab', 'akshay', 'given', 'yet', 'bhoomika', 'unexpected', 'hype', 'filmfare', 'awards', 'nominations', 'considering', 'khakee', 'khakkee', 'definitely', 'cant', 'wait', 'next', 'always', 'waqt', 'acted', 'fashion', 'future', 'once', 'cinema', 'comes', 'sholay', 'changes', 'perceives', 'den', 'hopefully', 'rgv', 'ki', 'aag', 'low', 'broken', 'ram', 'gopal', 'varma', 'melting', 'pot', 'talent', 'create', 'dish', 'stale', 'smell', 'distance', 'classic', 'assassinate', 'unforgivable', 'called', 'folklore', 'merely', 'defining', 'distinctively', 'lived', 'mess', 'badly', 'contest', 'worst', 'realism', 'element', 'missing', 'providing', 'bunch', 'parading', 'seemingly', 'unrelated', 'events', 'ridiculous', 'waste', 'vote', 'wake', 'failure', 'conjure', 'categorized', 'four', 'teenage', 'growing', 'california', 'jeanie', 'jodie', 'foster', 'level', 'headed', 'house', 'lives', 'divorced', 'sally', 'kellerman', 'annie', 'cherie', 'currie', 'addicted', 'drugs', 'alcohol', 'boys', 'beaten', 'madge', 'marilyn', 'kagan', 'overprotective', 'parents', 'deirde', 'kandice', 'stroh', 'thinks', 'mature', 'rest', 've', 'plenty', 'difference', 'accurate', 'graduated', 'school', '1980', 'clothes', 'attitudes', 'main', 'song', 'radio', 'donna', 'summer', 'harder', 'teen', 'understand', 'relate', 'knew', 'dated', 'captures', 'counts', 'scott', 'baio', 'friend', 'realistically', 'essential', 'deserved', 'rating', 'drug', 'swearing', 'teens', 'zp', 'deeply', 'youth', 'dream', 'represented', 'hippie', 'movement', 'college', 'debate', 'states', 'cultural', 'situation', 'gives', 'birth', 'explosion', 'daria', 'imagines', 'represents', 'fall', 'social', 'structures', 'therefore', 'huge', 'transformation', 'society', 'suffering', 'mark', 'anticipates', 'sees', 'easily', 'understood', 'life', '60', '70', 'driving', 'force', 'profound', 'explorations', 'change', 'significant', 'intended', 'bring', 'sexuality', 'closet', 'desert', 'represent', 'orgy', 'sexual', 'men', 'women', 'absolute', 'freedom', 'perform', 'hipotetic', 'hide', 'couples', 'throw', 'sand', 'each', 'magnificent', 'depicted', 'impossibility', 'hiding', 'basic', 'instinct', 'repression', 'control', 'outbursts', 'method', 'applies', 'students', 'suffers', 'hipocresy', 'clear', 'gain', 'access', 'skipping', 'fake', 'controls', 'policeman', 'professor', 'detained', 'part', 'interested', 'uninterested', 'presenting', 'flying', 'symbol', 'inner', 'wish', 'coming', 'returning', 'segun', 'difficulties', 'free', 'bonds', 'depicts', 'winning', 'point', 'view', 'woman', 'husband', 'passed', 'accident', 'barely', 'settles', 'shortly', 'loses', 'kidnapping', 'lead', 'following', 'plots', 'normal', 'depressed', 'struggle', 'kill', 'herself', 'severe', 'fights', 'god', 'trusts', 'forgive', 'killer', 'deals', 'issue', 'perspective', 'lots', 'grass', 'clouds', 'views', 'third', 'party', 'eye', 'perceive', 'explain', 'wouldn', 'everywhere', 'guy', 'clown', 'shamelessly', 'hangs', 'our', 'heroine', 'combination', 'crying', 'throwing', 'smiling', 'talking', 'stupidly', 'balance', 'emotions', 'absurdly', 'recommend', 'become', 'blockbuster', 'dear', 'sucked', 'originality', 'admire', 'bright', 'eg', 'environment', 'darker', '1970', 'horror', 'flick', '2006', 'scared', 'heavy', 'asian', 'total', 'rip', 'tagalog', 'screamed', 'conformity', 'copy', 'ring', 'improvise', 'door', '50', 'listed', 'website', 'thankfully', 'buy', 'package', 'truly', 'looked', 'ugly', 'printed', 'ultimate', 'vampire', 'marketing', 'campaign', 'expensive', 'begins', 'surprise', 'chased', 'zombie', 'creatures', 'reminded', 'attempt', 'ten', 'vhs', 'system', 'worse', 'gave', 'promo', 'shirts', 'kind', 'cool', 'dis', 'splatter', 'generally', 'braindead', 'dollar', 'budget', 'curse', 'east', 'separate', 'rolled', 'reviewers', 'picked', 'mentions', 'featured', 'enjoying', 'abruptly', 'stopped', 'appeared', 'middle', 'replaced', 'inane', 'unbelievable', 'seemed', 'rearranging', 'cleaning', 'apartment', 'wow', 'forward', 'day', 'wong', 'kar', 'wai', 'austin', 'novels', 'pride', 'prejudice', 'sensibility', 'mansfield', 'park', 'couldn', 'stand', 'emma', 'chapters', 'maybe', 'paltrows', 'se7en', 'interest', 'dunno', 'costumes', 'dancing', 'clumsy', 'compared', 'colin', 'firth', 'jennifer', 'ehle', 'knightly', 'bloody', 'gorgeous', 'patchy', 'ewan', 'mcgregor', 'liked', 'singing', 'wonderfully', 'urbane', 'coleman', 'cased', 'literally', 'comical', 'remains', 'spite', 'handsome', 'clever', 'step', 'ahead', 'wandering', 'anna', 'lee', 'based', 'play', 'brings', 'qualities', 'farce', 'supporting', 'name', 'absolutely', 'fantastic', 'mr', 'sean', 'connery', 'gable', 'stays', 'multi', 'talents', 'further', 'lost', 'horizon', 'buff', 'must', 'generous', 'ilk', 'portrayal', 'madmen', 'century', 'bizarre', 'species', 'antics', 'outrageous', 'fictionalized', 'napoleon', 'historical', 'figure', 'fascination', 'chickens', 'beating', 'scriptwriter', 'insanity', 'mental', 'illness', 'wonderful', 'flew', 'cuckoo', 'nest', 'illnesses', 'believable', 'state', 'guys', 'smart', 'calculating', 'shouldn', 'pat', 'morita', 'loveable', 'interpretation', 'stereotype', 'jay', 'leno', 'yell', 'laughed', 'throughout', 'account', 'mvie', 'tokyo', 'drinking', 'close', 'shazbot', 'embarrassing', 'list', '100', 'embarrassment', 'failed', 'comeback', 'christopher', 'lloyd', 'daniels', '101', 'dalmatians', 'remake', 'juicy', 'begin', 'promoting', 'purple', 'rose', 'theatre', 'disnefluff', 'reminder', 'wallace', 'shawn', 'disney', 'jet', 'li', 'bob', 'hoskins', 'unleashed', 'ray', 'walston', 'martian', 'cameo', 'died', 'lupus', 'coincidence', 'awful', 'seriously', 'damn', 'farting', 'voiced', 'degree', 'knight', 'newman', 'ha', 'whew', 'joker', 'wrap', 'moment', 'silence', 'franchise', 'agonizing', 'prayer', 'travesty', 'adaptation', 'mork', 'mindy', 'starring', 'allen', 'deciding', 'kiddie', 'toon', 'adult', 'caused', 'strange', 'mix', 'violent', 'duck', 'hardly', 'important', 'unmoving', 'transfer', 'orwell', 'spoiler', 'revolution', 'haven', 'learned', 'benjamin', 'gangster', 'sam', 'mendes', 'directed', 'showing', 'camaraderie', 'brilliant', 'hanks', 'jude', 'daniel', 'craig', 'casting', 'zenith', 'soundtrack', 'apt', 'totality', 'protect', 'underrated', 'liking', 'react', 'viscerally', 'unlikable', 'compelling', 'disorganized', 'rob', 'lowe', 'wore', 'dangly', 'earring', 'eyeliner', 'break', '1980s', '80s', 'garish', 'hyperbole', 'pumps', 'fist', 'fade', 'hate', 'enjoyed', 'catching', 'late', 'creepy', 'evil', 'decorations', 'weired', 'furniture', 'rent', 'tales', 'concerning', 'resident', 'meets', 'notice', 'lake', 'pond', 'sweet', 'birds', 'fool', 'peter', 'cushing', 'jack', 'crimson', 'altar', '68', 'chloe', 'franks', 'reid', 'exciting', 'loves', 'witchcraft', 'dazzling', 'seventeen', 'dance', 'george', 'gershwin', '1928', 'orchestral', 'piece', 'american', 'paris', 'indisputable', 'masterwork', 'choreographed', 'precision', 'unparalleled', 'flair', 'kelly', 'vibrant', 'color', 'music', 'poppingly', 'startling', 'inspired', 'selected', 'master', 'artists', 'dufy', 'de', 'la', 'concorde', 'manet', 'flower', 'market', 'utrillo', 'rousseau', 'vincent', 'van', 'gogh', 'opera', 'toulouse', 'lautrec', 'moulin', 'rouge', 'wears', 'bodysuit', '97', 'precede', 'finale', 'charms', '1951', 'oscar', 'musical', 'vincente', 'minnelli', 'screenwriter', 'alan', 'lerner', 'fashioned', 'surprisingly', 'slight', 'focused', 'jerry', 'mulligan', 'former', 'remained', 'wwii', 'painter', 'braggadocio', 'athletic', 'concurrently', 'ingratiating', 'irritating', 'screen', 'personality', 'oeuvre', 'carefree', 'triangle', 'milo', 'roberts', 'proclaimed', 'art', 'patron', 'predator', 'crowded', 'montmartre', 'nightclub', 'unapologetically', 'falls', 'lise', 'fiance', 'henri', 'professional', 'entertainer', 'pal', 'adam', 'concert', 'pianist', 'ensue', 'inevitable', 'songs', 'performed', 'imitated', 'swooningly', 'faux', 'seine', 'hazy', 'yellow', 'fog', 'lights', 'leslie', 'caron', 'circle', 'transcendent', 'approach', 'tentatively', 'synchronize', 'beautifully', 'clinch', 'elegantly', 'succinctly', 'shown', 'falling', 'rhythm', 'spotlight', 'nimble', 'tap', 'agreeable', 'embraceable', 'danced', 'impressively', 'five', 'montage', 'map', 'description', 'designed', 'versatility', 'similar', 'vera', 'ellen', 'showed', 'considerable', 'skills', 'sailor', 'described', 'faceted', 'turnstiles', 'nineteen', 'dances', 'superbly', 'handles', 'unformed', 'charm', 'bloom', 'glamorous', 'nina', 'foch', 'plays', 'manipulative', 'levant', 'sardonic', 'performing', 'elegant', 'stairway', 'paradise', 'gutary', 'agreeably', 'lose', 'mgm', 'worthwhile', '2000', 'pristine', 'terms', 'astonished', 'voted', 'write', 'superb', 'mastroianni', 'loren', 'narrated', 'humanity', 'slowly', 'developing', 'outsiders', 'contrasted', 'simultaneously', 'continuously', 'ongoing', 'inhumane', 'marching', 'pace', 'fascist', 'announcer', 'colleague', 'adherents', 'argue', 'anti', 'message', 'clearly', 'destroy', '60s', 'growled', 'belly', 'america', 'turbulence', 'diversity', 'decade', 'exaggerated', 'stereotyped', 'genuineness', 'issues', 'radical', 'confusing', 'changed', '1964', 'civil', 'rights', 'act', 'overwhelming', 'influence', 'media', 'freedoms', 'soon', 'became', 'institutionalized', 'chaos', 'sensitivity', 'disorder', 'values', 'bear', 'bulk', 'involved', 'news', 'effected', 'efforts', 'struggles', 'minorities', 'workers', 'political', 'activists', 'war', 'poverty', 'representation', 'power', 'press', 'particular', 'reflected', 'conflict', 'general', 'public', 'seeking', 'ignored', 'misrepresented', 'class', 'standing', 'angrily', 'baseball', 'bats', 'disowning', 'wayward', 'daughters', 'confused', 'folk', 'singers', 'suddenly', 'protest', 'beatles', 'onslaught', 'killed', 'beatle', 'dim', 'held', 'steady', 'sister', 'hog', 'farm', 'commune', 'woodstock', 'haight', 'asbury', 'detroit', 'riots', 'housewife', 'maine', 'connecticut', 'roles', 'constantly', 'changing', 'three', 'siblings', 'activist', 'active', 'military', 'personnel', 'dad', 'typical', 'mom', 'tolerance', 'compromise', 'sake', 'peace', 'comprises', 'minister', 'disproportionately', 'assume', 'producers', 'variables', 'settle', 'limitations', 'documentary', 'anger', 'produces', 'bitterness', 'today', 'unique', 'solution', 'divide', 'unusual', 'roaring', '20s', 'compare', 'words', 'moral', 'collective', 'individualism', 'survives', 'oxymoron', 'guru', 'spirited', 'genius', 'madness', 'nail', 'diverse', 'ashamed', 'grew', 'generation', 'shaped', 'existed', 'blade', 'trinity', 'messing', 'board', 'user', 'wes', 'craven', 'research', 'checked', 'scores', 'imdb', 'rottentomatoes', 'dracula', 'ascension', 'search', 'sequel', 'noticed', 'boards', 'strong', 'contradiction', 'recap', 'expectations', 'type', 'needs', 'form', 'opinion', 'knowing', 'started', 'ignore', 'fx', 'compensated', 'impressed', 'jason', 'london', 'roy', 'schieder', 'geez', 'cheesy', 'fricken', 'laughable', 'audio', 'synch', 'recording', 'vampires', 'luke', 'prevent', 'wanting', 'purposely', 'infected', 'nope', 'slasher', 'flicks', 'noise', 'hears', 'towel', 'blinked', 'wild', 'angry', 'trilogy', 'cliff', 'hangar', '3rd', 'installment', 'legacy', 'value', 'candidate', 'presence', 'tolerated', 'kid', 'tragedy', 'endeavor', 'greatest', 'diminishes', 'fast', 'terrible', 'janine', 'turner', 'soul', 'actor', 'intents', 'purposes', 'yourself', 'please', 'hurts', 'jamie', 'foxx', 'supposed', 'confidence', 'identity', 'whatsoever', 'immediately', 'idols', 'denzel', 'washington', 'martin', 'lawrence', 'imitate', 'problem', 'uneven', 'parts', 'somewhat', 'macho', 'goes', 'touch', 'contributes', 'sell', 'personally', 'dull', 'community', 'somebody', 'launch', 'super', 'stardom', 'cheadle', 'pathetic', 'remixes', 'steer', 'seconds', 'gloomy', 'crafted', 'mood', 'established', 'present', 'rain', 'confirmed', 'suspicions', 'misplaced', 'claiming', 'largely', 'stormy', 'vancouver', 'oppressive', 'outdoors', 'complement', 'olmos', 'recent', 'boom', 'dating', 'screens', 'reached', 'fevered', 'pitch', 'episode', 'bachelor', 'unsuspecting', 'subjected', 'clones', 'variations', 'bachelorette', 'joe', 'millionaire', 'money', 'execrable', 'married', 'cash', 'trend', 'exploit', 'demographic', 'bravo', 'disastrous', 'mercy', 'hearted', 'eligible', 'gay', 'courted', 'number', 'suitors', 'eliminated', 'inherent', 'viciousness', 'scenario', 'kicks', 'hearing', 'pay', 'picks', 'disguise', 'wins', 'prize', 'parting', 'gifts', 'hearty', 'aren', 'embarrassed', 'painful', 'queer', 'program', 'stereotypes', 'amok', 'gel', 'dress', 'abercrombie', 'fitch', 'pair', 'designer', 'sandals', 'strip', 'voila', 'equivalent', 'putting', 'performer', 'blackface', 'genuinely', 'implies', 'gays', 'variance', 'chance', 'individuality', 'behave', 'bank', 'sorely', 'lacking', 'gym', 'toned', 'scrubbed', 'cleaned', 'fostering', 'acceptance', 'dynamic', 'individuals', 'capable', 'dirty', 'parade', 'soft', 'core', 'pornography', 'masquerading', 'legitimate', 'contrary', 'offers', 'spice', 'tasteless', 'appears', 'theatrical', 'mechanical', 'staged', 'reminiscent', 'pakistani', 'available', 'mannerisms', 'screaming', 'shouting', 'doing', 'odd', 'lift', 'boeing', 'abraham', 'natural', 'misfit', 'morality', 'factor', 'aside', 'trite', 'kumar', 'paresh', 'rawal', 'stalwarts', 'vain', 'contrasting', 'sadly', 'brainless', 'buxomed', 'bimbettes', '3bs', 'talk', 'scream', 'major', 'hole', 'protagonist', 'pretending', 'sex', 'hundreds', 'dramabaazi', 'digest', 'flesh', 'tempting', 'promos', 'initial', 'situational', 'taste', 'gone', 'corrupted', 'demented', 'extent', 'connecting', 'sadistic', 'weird', 'maddening', 'frustrations', 'senseless', 'puerto', 'rico', 'shamefully', 'admit', 'pr', 'shootings', 'killings', 'shoot', 'anytime', 'anywhere', 'innocent', 'addition', 'justice', 'longer', 'moved', 'truth', 'rightness', 'ladrones', 'mentirosos', 'deplorable', 'facts', 'portrays', 'manipulating', 'courtrooms', 'children', 'dying', 'ricardo', 'poli', 'award', 'brave', 'friendly', 'country', 'nightmare', 'recently', 'copper', 'wing', 'competition', 'phoenix', 'festival', 'heck', 'service', 'redundant', 'blew', 'hurray', 'takahisa', 'zeze', 'gackt', 'disagree', 'sho', 'kei', 'taro', 'yamamoto', 'battle', 'royale', 'hyde', 'worship', 'loved', 'killing', 'preferred', 'aloof', 'hom', 'wang', 'pretend', 'studded', 'paved', 'collaborations', 'heard', 'orenji', 'taiyou', 'spelling', 'lasts', 'nine', 'length', 'sci', 'fi', 'futuristic', 'crew', 'repetitive', 'paraphrasing', 'conspiracy', 'theories', 'extant', '1979', 'jfk', 'assassination', 'grafted', 'vaguely', 'incoherent', 'fictitious', 'president', 'kegan', 'sterling', 'hayden', 'eli', 'wallach', 'asked', 'luridly', 'huston', 'bridges', 'anthony', 'perkins', 'acquit', 'justify', 'hour', 'price', 'purchase', 'definite', 'resounding', 'dud', 'recommended', 'sort', 'informed', 'altered', 'uplifted', 'positive', 'mystical', 'predisposed', 'poo', 'pooing', 'dealing', 'metaphysical', 'physical', 'boundaries', 'existence', 'presentation', 'decide', 'accordingly', 'content', 'mildly', 'informative', 'peptides', 'addiction', 'cellular', 'receptors', 'unifying', 'rambled', 'topics', 'unify', 'cohere', 'tie', 'conclude', 'able', 'ships', 'columbus', 'told', 'authorities', '1492', 'scientific', 'visual', 'cognition', 'gorilla', 'visit', 'lab', 'university', 'illinois', 'site', 'convincing', 'unsupported', 'mumbo', 'jumbo', 'hear', 'annoyed', 'credentials', 'presented', 'bottom', 'spoke', 'initially', 'matlin', 'disjointed', 'intrusive', 'downright', 'polish', 'ludicrous', 'sophomoric', 'pollack', 'usage', 'member', 'group', 'uses', 'pejorative', 'term', 'refer', 'case', 'pole', 'ethnic', 'listen', 'bigoted', 'conversation', 'betcha', 'unprovocked', 'unmitigated', 'abysmal', 'elaine', 'hendrix', 'reading', 'marlee', 'walking', 'baffled', 'material', 'portraying', 'disillusioned', 'drugged', 'prone', 'malcontent', 'clap', 'trap', 'success', 'korean', 'unusal', 'fighting', 'thinking', 'childish', 'sheets', 'newspaper', 'suggested', 'lurid', 'drive', 'claude', 'brook', 'americanization', 'claudio', 'international', 'horrors', 'chances', 'chopped', 'theatres', 'sheet', 'gem', 'collection', 'gerard', 'philipe', 'leaps', 'sly', 'swashbuckling', 'sword', 'fencing', 'knockabout', 'charmingly', 'loopy', 'storytelling', 'impossible', 'resist', 'gina', 'lollobrigida', 'affection', 'fiji', 'islands', 'unscrupulous', 'owner', 'valalola', 'resort', 'primal', 'invites', 'investors', 'guests', 'compound', 'composed', 'zoo', 'aiming', 'partners', 'discoveries', 'smalltime', 'thieves', 'puts', 'virus', 'security', 'participate', 'scavenger', 'hunt', 'attractions', 'sabretoothes', 'prehistoric', 'developed', 'dna', 'fossils', 'hosts', 'guards', 'pleasure', 'incredibly', 'lame', 'sabretooth', 'pleasant', 'jurassik', 'situations', 'winner', 'guard', 'explains', 'bulimic', 'brazil', 'ataque', 'dente', 'sabre', 'henry', 'fonda', 'brilliantly', 'believed', 'lincoln', 'fooler', 'led', 'surface', 'bumpkin', 'confrontation', 'lynch', 'court', 'proceedings', 'exterior', 'posturings', 'command', 'grasp', 'aspect', 'telling', 'timing', 'trial', 'gift', 'lady', 'eve', '1940', 'ford', 'hill', 'tremendous', 'storm', 'symbolic', 'insight', 'thoroughly', 'dick', 'tracy', 'persona', 'product', 'technology', 'craft', 'imagery', 'filled', 'kick', 'rendition', 'pastel', 'colors', 'larger', 'rendered', 'painstakingly', 'authentic', 'meant', 'madonna', 'cd', 'featuring', 'listened', 'musically', 'tuned', 'finest', 'steffen', 'screws', 'infidelity', 'untimely', 'childbirth', 'entices', 'red', 'castle', 'offering', 'bundles', 'weekend', 'ancestral', 'pile', 'nekkid', 'proceeds', 'flog', 'bull', 'whip', 'blonde', 'hottie', 'gladys', 'marina', 'malfatti', 'decides', 'murderous', 'wedded', 'bliss', 'iffy', 'becomes', 'increasingly', 'fragile', 'evelyn', 'appear', 'outside', 'spate', 'gruesome', 'murders', 'grounds', 'groovy', '70s', 'euro', 'tasty', 'various', 'undress', 'spooky', 'retreats', 'misty', 'graveyards', 'penchant', 'drop', 'babes', 'cracking', 'bods', 'vicious', 'victim', 'bashed', 'rock', 'entrails', 'eaten', 'foxes', 'normally', 'checklist', 'guarantee', 'grave', 'starters', 'convoluted', 'herrings', 'crazy', 'developments', 'suspects', 'galore', 'discover', 'plotting', 'paws', 'wealth', 'hero', 'hurting', 'secondly', 'emilio', 'maraglia', 'torpid', 'stylish', 'molasses', 'bits', 'possibly', 'giallo', 'poisonous', 'snake', 'bite', 'choices', 'weapon', 'aunt', 'agatha', 'crippled', 'relative', 'hiring', 'identical', 'curly', 'blondes', 'maids', 'england', 'mentioning', 'pounds', 'uniform', 'unlikelihood', 'bag', 'sulphuric', 'acid', 'laying', 'pool', 'genre', 'expect', 'jonathan', 'demme', 'directorial', 'debut', 'roger', 'corman', 'legendary', 'exploitation', 'outfit', 'pictures', 'rates', 'chicks', 'chains', 'grindhouse', 'classics', 'grace', 'celluloid', 'beauteous', 'russ', 'meyer', 'starlet', 'eric', 'vixen', 'beyond', 'valley', 'dolls', 'gavin', 'robust', 'brassy', 'resilient', 'fish', 'persevere', 'grimy', 'hellish', 'penitentiary', 'fabulous', 'steele', 'deliciously', 'wicked', 'sexually', 'frustrated', 'warden', 'steamy', 'striptease', 'inmates', 'dilly', 'longtime', 'roberta', 'arousers', 'unholy', 'rollers', 'collins', 'hilariously', 'raunchy', 'endearing', 'cheerfully', 'foul', 'mouthed', 'kleptomaniac', 'felon', 'gut', 'busting', 'pinnochio', 'lynda', 'crystin', 'sinclaire', 'tobe', 'hooper', 'alive', 'curtis', 'harrington', 'ruby', 'lively', 'uninhibited', 'wildcat', 'alice', 'cuddly', 'cheryl', 'rainbeaux', 'smith', 'reprise', 'frightened', 'lemora', 'supernatural', 'deliver', 'expected', 'amount', 'coarse', 'language', 'typically', 'crass', 'sexist', 'mindless', 'filth', 'effectively', 'explores', 'cruelly', 'strongly', 'asserts', 'pro', 'feminist', 'notion', 'overcome', 'obstacles', 'band', 'bravely', 'misogynistic', 'oppressors', 'mighty', 'zesty', 'confidant', 'glorious', 'abundance', 'astutely', 'observed', 'incidental', 'delightful', 'engagingly', 'quirky', 'behavior', 'furthermore', 'tak', 'fujimoto', 'cale', 'marvelously', 'dolorous', 'oddball', 'blues', 'score', 'mack', 'uproariously', 'rubber', 'monster', 'creature', 'feature', 'howler', 'track', 'moonbeast', 'sidesplitting', 'jerky', 'cop', 'car', 'stolen', 'trio', 'prison', 'escapees', 'stops', 'gas', 'station', 'bathroom', 'rousing', 'immensely', 'enjoyable', 'caged', 'heat', 'qualifies', 'richard', 'dix', 'retire', 'duane', 'ted', 'nichols', 'named', 'dupres', 'barkley', 'lenore', 'aubert', 'days', 'judge', 'pouring', 'return', 'inside', 'hood', 'automobile', 'engine', 'event', 'happening', 'realize', 'surrounds', 'missed', 'countryside', 'jokers', 'sounds', 'aware', 'possess', 'neither', 'drunk', 'excuse', 'decaying', 'slit', 'wrists', 'collect', 'mould', 'shape', 'disc', 'player', 'produce', 'trumpery', 'breasts', 'effort', 'slick', 'cover', 'dupe', 'renters', 'store', 'grab', 'dye', 'friends', 'neighborhood', 'growling', 'attacking', 'congratulations', 'distribution', 'company', 'displayed', 'filmmakers', 'avoid', 'masochist', 'amused', 'exuberant', 'warners', 'overlooked', 'remembered', 'official', 'theme', 'tinseltown', 'hooray', 'whiting', 'johnny', 'mercer', 'gems', 'charming', 'silhouetted', 'moonlight', 'lesson', 'powell', 'detail', 'misadventures', 'eight', 'ball', 'befalls', 'edgar', 'kennedy', 'celebrates', 'glamour', 'punctures', 'mileage', 'pompous', 'ego', 'maniacal', 'duplicitous', 'executives', 'gaggle', 'comedians', 'allyn', 'joslyn', 'crafty', 'agent', 'healy', 'manager', 'fritz', 'feld', 'excitable', 'restaurant', 'glenda', 'farrell', 'mona', 'marshall', 'sarcastic', 'gal', 'friday', 'mabel', 'todd', 'goofy', 'hugh', 'herbert', 'goofier', 'mentioned', 'pseudo', 'wind', 'questionable', 'delights', 'notably', 'benny', 'goodman', 'quartet', 'teddy', 'wilson', 'lionel', 'hampton', 'incredible', 'jazz', 'combo', 'otherwise', 'considered', '1975', 'buford', 'pusser', 'bo', 'svenson', 'askew', 'mobster', 'pinky', 'dobson', 'bed', 'ambushed', 'sunday', 'morning', 'recovers', 'revenge', 'successes', 'bother', 'leave', 'weasel', 'stars', 'narcissistic', 'garbage', 'boomer', 'technically', 'idealistic', 'youths', 'marx', 'draft', 'cards', 'prolonging', 'destroyed', 'tens', 'thousands', 'grade', 'moronic', 'fools', 'destructive', 'excercise', 'importance', 'kids', 'comment', 'comedies', 'lemmon', 'walter', 'matthau', 'wording', 'neil', 'simon', 'digital', 'cable', 'menu', 'deserves', 'hundred', 'updated', 'reach', 'ones', 'ambitious', 'sitting', 'tired', 'correction', 'win', 'academy', 'gigi', '1958', 'misinformation', 'west', '1962', '1965', 'novel', 'stage', 'production', 'flows', 'nancy', 'bringing', 'oliver', 'bridge', 'subtle', 'bumble', 'mrs', 'governors', 'underscore', 'dodger', 'ron', 'moody', 'playful', 'fagin', 'shani', 'wallis', 'strongest', 'distressed', 'numbers', 'concider', 'choreography', 'musicals', 'everyday', 'chores', 'jobs', 'meat', 'regular', 'rare', 'jan', 'kounen', 'dobermann', 'mostly', 'editing', 'cutting', 'added', 'benkei', 'petrified', 'spinning', 'forgot', 'flood', 'mediocrity', 'duel', 'earlier', 'handling', 'shanao', 'masked', 'resembled', 'asano', 'tadanobu', 'fight', 'ups', 'clashes', 'angle', 'produced', '1995', 'bullet', 'train', 'ninja', 'hunted', 'village', 'raid', 'tribute', 'paid', 'confronted', 'demonstrations', 'innocence', 'oppressed', 'authoritative', 'armed', 'branch', 'government', 'unwilling', 'socialists', 'communists', 'minority', 'versions', 'gto', 'salary', 'kintaro', 'examples', 'speak', 'praise', 'worthy', 'translation', 'encounter', 'popular', 'detached', 'contemporary', 'themes', '138', 'techniques', 'cares', 'interpret', 'sasaki', 'hirohisa', 'lips', 'unpleasant', 'among', 'target', 'foreign', 'festivals', 'faster', 'fame', 'works', 'fest', 'introduce', 'countries', 'gojoe', 'sakura', 'killers', 'outta', '1987', 'martial', 'arts', 'coolest', 'aged', 'chuck', 'connors', 'golf', 'beach', 'clad', 'ninjas', 'sneak', 'intent', 'hitting', 'reaches', 'naw', 'spoil', 'misfortune', 'thank', 'nonsense', 'videotape', 'bulb', 'caucasian', 'heroes', 'trained', 'training', 'briskly', 'plentiful', 'overdone', 'chuckles', 'paulsen', 'hatchet', 'cry', 'comparisons', 'underdeveloped', 'adventure', 'provides', 'luxurious', 'mountaineer', 'quincy', 'jared', 'rushton', '13', 'brian', 'roebson', 'crashes', 'deserted', 'mountain', 'terrain', 'stranded', 'defend', 'obvious', 'fifteen', 'introduction', 'namely', 'consumes', 'roughing', 'contain', 'yukon', 'landscape', 'encounters', 'brisk', 'cub', 'dilemmas', 'initiate', 'enjoyment', 'connection', 'briefly', 'passage', 'primitive', 'improved', 'using', 'tools', 'etc', 'survival', 'ordinary', 'passes', 'stuck', 'translated', 'rescue', 'seeks', 'created', 'rocky', 'explained', 'brief', 'intermittent', 'minimal', 'flashbacks', 'singer', 'jefferson', 'starship', 'chime', 'sara', 'draw', 'implications', 'guess', 'fill', 'gaps', 'narrative', 'necessary', 'whether', 'flaws', 'stupor', 'purely', 'nostalgia', 'nicolas', 'roeg', 'variable', 'insignificance', 'foremost', 'adapted', 'stageplay', 'wordy', 'bound', 'pays', 'underlying', 'overtly', 'adjust', 'juxtaposition', 'reversals', 'protagonists', 'einstein', 'mccarthy', 'munroe', 'dimaggio', 'wracked', 'guilt', 'hiroshima', 'fancies', 'simplicity', 'liaison', 'munro', 'bimbo', 'craves', 'intellectual', 'credence', 'senator', 'height', 'witch', 'hunting', 'powers', 'impotent', 'sleazebag', 'insecure', 'celebrity', 'obsessed', 'seeds', 'destruction', 'troubled', 'abused', 'past', 'gradually', 'postwar', 'icons', 'mores', 'obsessions', 'happiness', 'theory', 'relativity', 'proposed', 'unified', 'field', 'indeed', 'cosmos', 'aspirations', 'interactions', 'insignificant', 'aspects', 'quantum', 'affect', 'applied', 'monroe', 'principle', 'neutron', 'bomb', 'naming', 'anachronism', 'per', 'se', 'references', 'accessible', 'knowledgeable', 'au', 'fait', '50s', 'occurrences', 'cults', '21st', 'screenplay', 'extremely', 'opaque', 'pretentious', 'ultimately', 'prosper', 'setting', 'wartime', 'zealand', 'subject', 'sisters', 'relationships', 'soldiers', 'bearing', 'illegitimate', 'seven', 'marines', 'murdered', 'pow', 'zealander', 'unforgettable', 'graziano', 'joan', 'fontaine', 'jean', 'simmons', 'bothered', 'televised', 'chvez', 'coup', 'genuine', 'venezuela', 'april', '2002', 'narration', 'accompanying', 'suggestive', 'criticism', 'expressed', 'hugo', 'biased', 'saint', 'fortunately', 'additional', 'information', 'internet', 'nowadays', 'difficult', 'urgent', 'investigation', 'chavez', 'european', 'corporations', 'financed', 'blatant', 'falsehoods', 'lists', 'unintended', 'falsifications', 'string', 'google', 'document', 'registration', 'findings', 'counterweight', 'advice', 'conclusion', 'kim', 'bartley', 'donnacha', 'knowingly', 'propaganda', 'rarely', 'witnessed', 'gratuitous', 'constructive', 'hopeless', 'swamp', 'strands', 'promise', 'stature', 'robert', 'duvall', 'downey', 'jr', 'deployed', 'coffee', 'stained', 'lens', 'grisham', 'merit', 'discovers', 'depths', 'motivated', 'incoherence', 'lecherous', 'commentary', 'aesthetic', 'balanced', 'appreciative', 'egregious', 'disaster', 'bilious', 'occupy', 'trash', 'walt', 'cinderella', 'familiar', 'embellishes', 'suspense', 'retaining', 'appealing', 'storybook', 'emanates', 'delectable', 'conventionally', 'highlight', 'captivating', 'godmother', 'transforms', 'pumpkin', 'majestic', 'coach', 'rags', 'gown', 'david', 'al', 'hoffman', 'livingston', 'bibbidi', 'bobbidi', 'boo', 'enhance', 'thrilling', 'melodrama', 'concerns', 'anxieties', 'titular', 'animal', 'stepmother', 'dreadful', 'cat', 'lucifer', 'formidable', 'menace', 'threatens', 'dreams', 'mice', 'viewers', 'nicely', 'serene', 'sweetness', 'segments', 'personalities', 'remarkably', 'realized', 'bunched', 'prank', 'phone', 'calls', 'halloween', 'knife', 'hilarious', 'pulled', 'refreshing', 'yorkers', 'six', 'degrees', 'separation', 'cleverly', 'intertwines', 'bridget', 'moynahan', 'hernandez', 'stunning', 'adorable', 'caseman', 'wardrobes', 'exquisite', 'intelligent', 'drones', 'doth', 'sounded', 'author', 'convince', 'sites', 'profane', 'literature', 'writings', 'period', 'connected', 'bible', 'lend', 'accuracy', 'contained', 'skew', 'data', 'prove', 'customs', 'definitions', 'german', 'root', 'translations', 'italics', 'translators', 'dropped', 'verse', 'spaces', 'punctuation', 'paragraphs', 'numeric', 'verses', 'above', 'godisnowhere', 'letters', 'meanings', 'biblical', 'researchers', 'lexicon', 'assist', 'arabic', 'greek', 'hebrew', 'depending', 'scripture', 'originally', 'note', 'exists', 'exist', 'listening', 'qualified', 'almighty', 'soapbox', 'bless', 'maegi', 'zorro', 'serials', 'serial', 'mexico', 'nation', 'counting', 'republic', 'solvent', 'del', 'oro', 'stirring', 'indians', 'reed', 'hadley', 'cuts', 'dashing', 'selection', 'scraps', 'reused', 'moves', 'tyrone', 'swashbucklers', 'miracles', 'progresses', 'intense', 'survive', 'alone', 'amazon', 'crash', 'survivor', 'losing', 'dramatic', 'perils', 'endure', 'unreal', 'actualy', 'unspeakable', 'animals', 'snakes', 'reptiles', 'enormous', 'forests', 'wildlife', 'insects', 'dangers', 'follow', 'remembering', 'stream', 'eventually', 'swim', 'dangerous', 'waters', 'injured', 'drink', 'canoe', 'realizes', 'fearing', 'passengers', 'heartwarming', 'airplane', 'maintained', 'injuries', 'remarkable', 'whereas', 'perished', 'horrific', 'wilds', 'miike', 'neverending', 'yokai', 'recommending', 'loud', 'obnoxious', 'dub', 'tend', 'unevenness', 'drag', 'converse', 'perpetual', 'flaw', 'incoherency', 'rears', 'spirits', 'fantastical', 'forms', 'designers', 'outstanding', '1968', 'supposedly', 'monsters', 'spook', 'warfare', 'transformed', 'entities', 'makeup', 'agi', 'sports', 'shadow', 'beehive', 'hairdo', 'incidentally', 'chiaki', 'kuriyama', 'lucy', 'liu', 'henchgirl', 'bill', 'vol', 'ryunosuke', 'kamiki', 'provided', 'voices', 'miyazaki', 'howl', 'zombi', 'needless', 'similarities', 'dan', 'bannon', 'intentionally', 'scientist', 'hysterical', 'subpar', 'sloppy', 'fun', 'refrigerator', 'severed', 'somehow', 'flies', 'fridge', 'ineptly', 'latching', 'onto', 'neck', 'ability', 'float', 'defies', 'physics', 'idiotic', 'gotten', 'favor', 'sucker', 'exactly', 'writers', 'greatly', 'reminds', 'sliding', 'doors', 'focusing', 'random', 'repeatedly', 'helps', 'cute', 'bald', 'talks', 'omnipotent', 'clock', 'tower', 'hudsucker', 'proxy', 'jacket', 'audrey', 'tautou', 'capitalize', 'amelie', 'higher', 'uninteresting', 'tightened', 'subplots', 'panic', 'sneaky', 'figured', 'bromell', 'builds', 'quietly', 'devastating', 'enacted', 'william', 'macy', 'donald', 'sutherland', 'neve', 'campbell', 'tracey', 'ullman', 'ritter', 'dorfman', 'unscripted', 'thoughts', 'rewarding', 'cq', 'choose', 'theater', 'student', 'intro', 'filmmaking', 'critic', 'audacity', 'godard', 'le', 'mpris', 'contempt', 'coppola', 'idea', 'artsy', 'kitsch', 'carries', 'expression', 'awe', 'shock', 'schwartzman', 'flamboyant', 'depardieu', 'alright', 'spoof', 'italy', 'picking', 'dropping', 'guessing', 'filming', 'objects', 'tagged', 'artistic', 'funniest', 'sent', 'screening', 'edited', 'whatever', 'curious', 'parody', 'lil', 'romy', 'cousin', 'videos', 'godfathers', 'daddy', 'superfighters', 'blood', 'stunts', 'lau', 'ching', 'wan', 'hk', 'germany', 'uncut', 'difficulty', 'understanding', 'symbolism', 'goldfishes', 'thai', 'culture', 'meanders', 'unsatisfying', 'felt', 'imaginary', 'chaotic', 'pang', 'achieve', 'previously', 'worthless', 'island', 'jesus', 'fit', 'islanders', 'resse', 'witherspoon', 'stylised', 'hong', 'kong', 'triad', 'gangs', 'election', 'leader', 'chairman', 'elected', 'ancient', 'traditions', 'candidates', 'position', 'bribes', 'record', 'race', 'tense', 'expertly', 'expansive', 'revealing', 'glory', 'godfather', 'seat', 'wincing', 'subtitled', 'volume', 'instalments', 'deeper', 'murky', 'triads', 'feuding', 'underhand', 'victor', 'mclaglen', 'leads', 'rough', 'laces', 'stevens', 'refuse', 'offered', 'monument', 'stagecoach', 'cary', 'grant', 'douglas', 'fairbanks', 'sergeants', 'army', 'buddy', 'gang', 'breaking', 'engaged', 'marry', 'pals', 'aided', 'abetted', 'regimental', 'beastie', 'gunga', 'din', 'jaffe', 'rudyard', 'kipling', 'poem', 'served', 'inspiration', 'rko', 'barracks', 'british', 'raj', 'overshadow', 'makers', 'assumption', 'india', 'increments', 'local', 'rulers', 'weak', 'mogul', 'emperor', '19th', 'ruled', 'outright', 'rule', 'depended', 'troops', 'rise', 'rank', 'corporal', 'considerably', 'status', 'rebels', 'hindu', 'moslem', 'strains', 'religion', 'christian', 'sects', 'strangling', 'strangled', 'liberators', 'organized', 'independence', 'congress', 'slice', 'trek', 'prime', 'directive', 'cockney', 'suited', 'eduard', 'ciannelli', 'strangler', 'fire', 'passion', 'blows', 'exhorting', 'temple', 'progressively', 'darkens', 'teeth', 'ghoulish', 'haunting', 'frightening', 'effective', 'nineteenth', 'assumptions', 'justifying', 'gandhi', 'chart', 'evolved', 'formula', 'entangled', 'cops', 'gangsters', 'fleeting', 'snicker', 'inducing', 'danielle', 'harris', 'typecasting', 'rebellious', 'afraid', 'weakest', 'primarily', 'leaden', 'bland', 'engage', 'alistair', 'sim', 'infinitely', 'scrooge', 'meanest', 'saying', 'conviction', 'undergoes', 'metamorphosis', 'similarly', 'unconvincing', 'match', 'muppets', 'knobs', 'broomsticks', 'thousand', 'tears', 'joy', 'reiterate', '27', 'copies', 'favourite', 'portobello', 'practice', 'recordings', 'drums', 'guitar', 'forming', 'hope', 'liz', 'appalling', 'fathom', 'notable', 'exceptions', 'penelope', 'keith', 'joanna', 'lumley', 'diana', 'scripts', 'average', 'sets', 'nancherrow', 'bizarrely', 'dower', 'uk', 'presumably', 'doubt', 'recreated', 'ceylon', 'appallingly', 'condemn', 'edward', 'britain', 'blinded', 'commits', 'suicide', 'loveday', 'gus', 'sensible', 'farmer', 'tear', 'besotted', 'passionately', 'prepared', 'complaint', 'mudge', 'shallow', 'unfaithful', 'devoted', 'jess', 'psychologically', 'disturbed', 'biddy', 'justification', 'occupied', 'fear', 'whilst', 'mortimer', 'utterly', 'display', 'occasions', 'delightfully', 'nettlebed', 'mundane', 'limit', 'prevents', 'continuing', 'image', 'rosamunde', 'pilcher', 'approved', 'grotesque', 'perversion', 'purchased', 'minded', 'happily', 'stayed', 'baptist', 'mormon', 'superficially', 'mocked', 'mixed', 'wanna', 'concentration', 'teaches', 'modest', 'conservative', 'evening', 'haunted', 'lara', 'flynn', 'twin', 'peaks', 'apparently', 'staring', 'gosselaar', 'architect', 'pours', 'col', 'walker', 'ferguson', 'appropriately', 'wooden', 'pie', 'charlotte', 'stephen', 'amell', 'involve', 'vibe', 'neighbors', 'unable', 'ominous', 'amityville', 'hell', 'closest', 'paints', 'depiction', 'occurs', 'dry', 'joined', 'forces', 'bart', 'sibrel', 'bases', 'says', 'mistakenly', 'nasa', 'astronauts', 'faking', 'trip', 'moon', 'employing', 'tricks', 'earth', 'orbit', 'editors', 'raw', 'finished', 'slipshod', 'backstage', 'large', '30', 'telecast', 'reel', 'millions', 'hidden', 'vaults', 'conspiratorial', 'spells', 'testing', 'hacked', 'zapruder', 'clips', 'chose', 'distant', 'eclipsed', 'frames', 'forth', 'destroying', 'claim', 'mattes', 'transparencies', 'placed', 'spacecraft', 'windows', 'illusion', 'faraway', 'relies', 'innuendo', 'inexpert', 'misleading', 'selective', 'quotation', 'manipulate', 'accepting', 'shred', 'listings', 'yahoo', 'advertised', 'closer', 'falk', 'reiser', 'mad', 'spouse', 'swept', 'heartfelt', 'sappy', 'emoted', 'junk', 'limited', 'shared', 'haha', 'smile', 'psychological', 'test', 'wittgenstein', 'wrote', 'philosophical', 'tractacus', 'sp', 'meaningless', 'useless', 'ladder', 'clarity', 'snipes', 'ass', 'suffered', 'suck', 'boredom', 'unoriginality', 'reference', 'surreal', 'bourne', 'grate', 'fantastically', 'honestly', 'flat', 'whats', 'regardless', 'blinding', 'flashing', 'strobe', 'bout', 'straining', 'handle', 'drifted', 'caught', 'engages', 'zone', 'understandable', '74th', 'annual', 'magical', 'woody', 'shunned', 'aggrandizing', 'pointless', 'attended', 'coveted', 'mourning', 'loss', 'collapse', 'trade', 'cities', 'ladies', 'gentleman', 'erupted', 'ovation', 'industry', 'applause', 'avoids', 'wit', 'highlights', 'oscars', 'joked', 'panicked', 'pawn', 'shop', 'ages', 'retrieving', 'nominated', 'calling', 'apologise', 'disclosed', 'lifelong', 'aversion', 'tux', 'backdrop', 'hamlet', 'branagh', 'yelling', 'celebrities', 'billy', 'crystal', 'williams', 'charlton', 'heston', 'ambiguities', 'resolved', 'speaks', 'vast', 'inclined', 'reputation', 'archaic', 'battles', 'kings', 'nobles', 'incest', 'schemes', 'ghosts', 'overacting', 'forcing', 'detract', 'complaining', 'rome', 'medieval', 'denmark', 'anachronisms', 'cannons', 'julius', 'caesar', 'chimneys', 'invented', 'iv', 'machiavelli', 'born', 'objection', 'danish', 'plato', 'busey', 'unknown', 'boot', 'tough', 'mercenary', 'framed', 'powerful', 'cuban', 'lord', 'steve', 'bauer', 'scarface', 'speaksman', 'expert', 'climax', 'ironic', 'sidekick', 'finish', 'nu', 'misrepresentation', 'canadian', 'disservice', 'mounted', 'pierre', 'berton', 'noted', 'historian', 'raised', 'dawson', 'definitive', 'klondike', 'rush', '1896', '1899', 'express', 'exasperation', 'untamed', 'frontier', 'subdued', 'guns', 'continued', 'cowboy', 'herd', 'beef', 'cattle', 'geographical', 'impossibilities', 'incongruity', 'lawlessness', 'stewart', 'brennan', 'border', 'shack', 'empty', 'constable', 'asks', 'pelly', 'chilkats', 'replies', 'patrols', 'twenty', 'square', 'miles', 'months', 'territory', 'north', 'northwest', 'stationed', 'strike', 'controlled', 'brooked', 'collected', 'duties', 'wails', 'arrivals', 'arbitrary', 'navigation', 'turned', 'supplies', 'laid', 'strictly', 'punishable', 'wood', 'plump', 'arrested', 'stern', 'risqu', 'suggestively', 'tights', 'gunbelt', 'unthinkable', 'notorious', 'tombstone', 'hip', 'disarmed', 'ejected', 'saloon', 'heinous', 'lamb', 'protested', 'discovering', 'taking', 'resistance', 'revolvers', 'confiscated', 'auctioned', 'souvenirs', 'mantelpiece', '1898', 'stampede', 'skagway', 'lawless', 'soapy', 'denver', 'gannon', 'cross', 'equipment', 'frogmarched', 'sergeant', 'lone', 'mountie', 'fifty', 'wilderness', 'pour', 'yourselves', 'swear', 'marshal', 'leaves', 'astonishing', 'suggestion', 'tin', 'sworn', 'townspeople', 'jurisprudence', 'naturally', 'jimmy', 'fits', 'reluctant', 'shooting', 'pins', 'bully', 'blast', 'western', 'anybody', 'passing', 'knowledge', 'rational', 'belief', 'excerpt', 'canada', 'sad', 'specially', 'consider', 'simpsons', 'merits', 'adequate', 'sigfried', 'mission', 'appreciation', 'shame']\n"
     ]
    }
   ],
   "source": [
    "class LemmaTokenizer(object):  # this 'tokenizer' will also do additional preprocessing steps, namely, lemmatize verbs and adjectives\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wnl = nltk.WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, docs):\n",
    "        return [self.wnl.lemmatize(self.wnl.lemmatize(tok, pos='v'), pos='a') for tok in nltk.word_tokenize(docs)]\n",
    "    \n",
    "lemm_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), ngram_range=(1,2), token_pattern=None)  # include bigrams as well as unigrams\n",
    "\n",
    "lemm_vectorizer.fit(input_text)\n",
    "lemm_term_doc_mat = lemm_vectorizer.transform(input_text).T\n",
    "\n",
    "# Print out some of the features in the vocabulary:\n",
    "print(list(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4946\n",
      "Size of term document matrix with lemmatization: (22142, 100)\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocabulary size: {len(vectorizer.vocabulary_)}')\n",
    "print(f'Size of term document matrix with lemmatization: {lemm_term_doc_mat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DO 14:** Run the code below and compare with your previous results. Print out the vocabulary to see how the lemmatizer has changed the results. You can also experiment with the 'pos' parameter to lemmatise different categories of word (verbs, adjectives, nouns). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now for unigrams and bigrams with lemmatisation: \n",
      "Document 35 with similarity score 0.5922753813024627: \n",
      "What the movie The 60s really represents (to those of us who growled around in the belly of America in those times) is the turbulence and diversity of the decade. Despite the exaggerated, stereotyped characters, the genuineness of the issues remains clear.<br /><br />Not only were those radical times of change, but also very confusing times. Two basic things changed our world then: the 1964 Civil Rights Act, and the overwhelming influence of the media. Those two new freedoms began social changes that soon became institutionalized.<br /><br />From chaos came sensitivity, from disorder came values. Bear in mind however, that the bulk of Americans were not involved in this... they worked, they played, they watched the news... and slowly they became effected by the efforts and struggles of the minorities... the Civil Rights workers, the Political Activists, the Anti-War efforts, the War on Poverty....<br /><br />The representation of the power of the press and TV in particular, was well reflected, although the conflict between the general public's attitude and those seeking to change things was at best ignored... and at worst, misrepresented.. Middle class Americans weren't all standing around angrily holding baseball bats, or disowning their wayward daughters. They were confused too. Let us not forget how Folk Singers suddenly became Protest Singers, and how The Beatles began an onslaught that killed the Folk-Protest Movement. There are no Beatle songs in the movie, or even any mention of them.<br /><br />I think if you didn't live the decade, you might not have a sense of what the movie is about, the overall picture is a bit dim. At one point I held down a steady job while my sister lived at the Hog Farm Commune and went to Woodstock. At another point I was in Haight Asbury and in the Detroit Riots while she worked and played the housewife in Maine and Connecticut. Roles were constantly changing.<br /><br />The movie depicts three siblings of a middle class family. They represent the hippie child, the political activist, and the active military personnel. Dad represents the typical attitudes, and mom represents the voice of reason, tolerance, and sometimes compromise... for the sake of peace.<br /><br />The Black family comprises a minister and his son... disproportionately, I think. I assume the producers knew all the variables and had to settle on limitations, or else the film would have become a long, boring, documentary. Dad's message was that anger produces bitterness, and bitterness produces chaos. It was clearly a message directed to today's youth.<br /><br />We are looking at a unique solution to social problems, and also how issues divide us... The 60s were unusual in that way, and only the Roaring 20s compare. In other words, this movie has a moral after all. In the end, it is our Collective Individualism that survives. Put that in your oxymoron list.<br /><br />Everyone was a God, a Guru, or a free-spirited genius in the 60s. It was a time of magic and madness. No one will ever nail the 60s down right... it was too diverse (this movie is close). At least we can say we are not ashamed of it, that we learned and grew from it, and that for once, a generation shaped and changed America... for the better.\n",
      "\n",
      "\n",
      "Document 65 with similarity score 0.5970982567917089: \n",
      "I had never read Gary Paulsen's novel, Hatchet, for which 'A Cry in the Wild' is the adaptation of, so I can't make any comparisons to the book. I will, however, say that as a film on its own, adaptation or no adaptation, it was an underdeveloped adventure that provides no major explanation of its few characters.<br /><br />Think of 'A Cry in the Wild' as a less luxurious, teenage mountaineer (was Quincy, California the only place this was filmed?) version of 'Cast Away.' Jared Rushton is 13-year-old Brian Roebson, a kid headed on a small plane to visit his father, until the craft crashes over some deserted mountain terrain, leaving the kid stranded for quite a while and having to defend himself.<br /><br />There are basically three parts to the film. The obvious being the ten or fifteen minute introduction of the characters, namely Brian and his mom. <br /><br />The next third of the movie (which really consumes nearly all of the film) is that of Brian \"roughing it.\" These scenes contain no particularly amazing action, nothing spectacular other than lots of beautiful cinematography of a beautiful Yukon landscape. Nothing to put you on edge, no real encounters (except a brisk confrontation with a cub), and no major dilemmas to initiate some sort of enjoyment or connection with the character on the screen. You might even feel briefly bored with the passage of time as we witness Brian dealing with his situation through first, primitive means, and then more improved ones (using tools, etc) for his survival. It is more like the ordinary time that passes if you were actually stuck in the situation, and that is pretty much about it. In other words, they put no meat on the Paulsen's words when they translated them into a visual media.<br /><br />And, of course, the third part of the movie is his rescue.<br /><br />There is a subplot that continuously seeks to make itself known during this time, however. Some conflict between Brian and his parents that created a rocky, awkward relationship between them. However, for the most part, it is only explained in brief, intermittent, minimal dialog flashbacks that look more like a back story for a music video. Any minute, the singer from Jefferson Starship, should chime in an start singing 'Sara.' Other than what the viewer can draw from the implications, or guess for his own need to fill the gaps in the narrative, we get a very underdeveloped back story which was probably necessary to enjoy at least part of this film and create a connection to the characters, whether or not it really had anything to do with Brian's survival adventure in the third part of the movie. These are the flaws in the narrative that through the viewer into a stupor as he struggles to find out what the heck those people there on the screen are doing and, for me, almost done to the point of screaming at the television to say something and tell me more! <br /><br />It certainly was not, for me, a good adventure tale. But, for fans of Jared Rushton, it was one of the last few movies he made. So, watch it purely for nostalgia, if nothing else.\n",
      "\n",
      "\n",
      "Document 94 with similarity score 0.6018621247740135: \n",
      "haha! you have to just smile and smile if you actually made it all the way through this movie. it like says something about myself i guess. the movie itself was created i think as some sort of psychological test, or like some sort of drug, to take you to a place you have never been before. When Wittgenstein wrote his famous first philosophical piece the tractacus (sp?) he said it was meaningless and useless, but if you read it, after you were done, it would take you to a new level, like a ladder, and then you could throw away the work and see things with clarity and true understanding. this movie is the same i think.<br /><br />As a movie it is without a doubt, the worst movie i have seen in a long long time in such a unique way. first of all, this is snipes. i loved watching this guy kick ass in various movies. and i have suffered through a few weak ones. however, although you know the movie might suck, you would never suspect that it could be as bad as it actually was. which is the fun of it. i mean this is snipes. you know it might be good, but it will be alright, right? smile.<br /><br />so this thing on every level is pure boredom, pure unoriginality. the reference to the professional is both dead on and obvious, yet so poorly done as to be comical. there is not one character in this movie that is interesting, in the least. and to make the whole thing more surreal, they have a soundtrack that sort of sounds like parts to various Bourne identity type movies, only isn't quite right. in fact, although it seems close to action movie background music, it just so happens it is done in a manner that will grate on you fantastically.<br /><br />then all the scenes in the total pitch black, where honestly since the characters are so flat, you don't really care whats going to happen, but regardless, after it happens and someone is killed, you just say to yourself, was i supposed to see that? what else? how about scenes with blinding, obnoxious flashing at a strobe lights pace, for a period of time that is too long to bear. sure let's throw that in. how bout this though. when you are straining and your eyes cant handle it any longer, do some more of these in the dark kills where you really don't see what happened. and on top of that, lets face it you don't care. you were past bored way from the beginning.<br /><br />so i drifted in and out a couple times, but i caught almost all of this movie. and it becomes something you can watch, without something that engages your mind on any level, therefore, it becomes something you can effectively zone out with, and begin to think about your life, where its going, where its been, what we are as people.<br /><br />and that... that is the true magic of this film.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### WRITE YOUR OWN CODE HERE\n",
    "print(\"Now for unigrams and bigrams with lemmatisation: \")\n",
    "scores = []\n",
    "for i in range(len(input_text)):\n",
    "    scores.append(cossim(lemm_term_doc_mat[:, selected_doc].toarray().flatten(), lemm_term_doc_mat[:, i].toarray().flatten()))\n",
    "\n",
    "most_sim = np.argsort(scores)[-4:-1]\n",
    "\n",
    "for doc in most_sim:\n",
    "    print(f\"Document {doc} with similarity score {scores[doc]}: \")\n",
    "    print(input_text[doc])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
